@startuml collect
title <color red><size:30>Spark collect</size></color>
SparkContext -> SparkContext: collect
SparkContext -> SparkContext: runJob (compute partitions, clean ClosureFunction)
SparkContext -> DAGScheduler: runJob
DAGScheduler -> DAGScheduler: submitJob
DAGScheduler -> JobWaiter: <color red>create JobWaiter receive result</color>
DAGScheduler -> DAGScheduler: eventProcessLoop
DAGScheduler -> DAGScheduler: handleJobSubmitted
DAGScheduler -> DAGScheduler: createResultStage
DAGScheduler -> DAGScheduler: submitStage
DAGScheduler -> DAGScheduler: submitMissingTasks
DAGScheduler -> TaskScheduler: submitTasks
TaskScheduler -> CoarseGrainedSchedulerBackend: reviveOffers
CoarseGrainedSchedulerBackend -> DriverEndpoint: receive
DriverEndpoint -> DriverEndpoint: makeOffers
DriverEndpoint -> DriverEndpoint: launchTasks
DriverEndpoint -> ExecutorBackend: receive
ExecutorBackend -> Executor: launchTask
Executor -> DriverEndpoint: receive
DriverEndpoint -> TaskSchedulerImpl: statusUpdate
TaskSchedulerImpl -> TaskResultGetter: enqueueSuccessfulTask
TaskResultGetter -> TaskSchedulerImpl: handleSuccessfulTask
TaskSchedulerImpl -> TaskSetManager: handleSuccessfulTask
TaskSetManager -> TaskSchedulerImpl: taskEnded
TaskSchedulerImpl -> DAGScheduler: handleTaskCompletion
DAGScheduler -> JobWaiter: taskSucceeded
JobWaiter -> SparkContext: <color red>put results to collback function</color>
@enduml