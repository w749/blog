<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Spark源码-collect流程"><meta name="keywords" content="Spark"><meta name="author" content="WangXun"><meta name="copyright" content="WangXun"><title>Spark源码-collect流程 | Wake</title><link rel="shortcut icon" href="/img/favicon-blank.svg"><link rel="stylesheet" href="/css/index.css?version=1.9.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"HSM2EINL2X","apiKey":"6f1478b12150efd917d5ecfcddfb8b8b","indexName":"wangxun","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '6.0.0'
} </script><meta name="generator" content="Hexo 6.0.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#SparkContext-collect"><span class="toc-number">1.</span> <span class="toc-text">SparkContext.collect</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SparkContext-runJob-T-U-ClassTag-rdd-RDD-T-func-Iterator-T-x3D-gt-U"><span class="toc-number">2.</span> <span class="toc-text">SparkContext.runJob[T, U: ClassTag](rdd: RDD[T], func: Iterator[T] &#x3D;&gt; U)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SparkContext-runJob-T-U-ClassTag-rdd-RDD-T-func-Iterator-T-x3D-gt-U-partitions-Seq-Int"><span class="toc-number">3.</span> <span class="toc-text">SparkContext.runJob[T, U: ClassTag](rdd: RDD[T],func: Iterator[T] &#x3D;&gt; U,partitions: Seq[Int])</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SparkContext-runJob-T-U-ClassTag-rdd-RDD-T-func-TaskContext-Iterator-T-x3D-gt-U-partitions-Seq-Int-resultHandler-Int-U-x3D-gt-Unit"><span class="toc-number">4.</span> <span class="toc-text">SparkContext.runJob[T, U: ClassTag](rdd: RDD[T],func: (TaskContext, Iterator[T]) &#x3D;&gt; U,partitions: Seq[Int],resultHandler: (Int, U) &#x3D;&gt; Unit)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#doCheckpoint"><span class="toc-number">4.1.</span> <span class="toc-text">doCheckpoint</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DAGScheduler-runJob"><span class="toc-number">5.</span> <span class="toc-text">DAGScheduler.runJob</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DAGScheduler-submitJob"><span class="toc-number">6.</span> <span class="toc-text">DAGScheduler.submitJob</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DAGScheduler-eventProcessLoop"><span class="toc-number">7.</span> <span class="toc-text">DAGScheduler.eventProcessLoop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DAGScheduler-handleJobSubmitted"><span class="toc-number">8.</span> <span class="toc-text">DAGScheduler.handleJobSubmitted</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DAGScheduler-createResultStage"><span class="toc-number">8.1.</span> <span class="toc-text">DAGScheduler.createResultStage</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DAGScheduler-submitStage"><span class="toc-number">9.</span> <span class="toc-text">DAGScheduler.submitStage</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DAGScheduler-submitMissingTasks"><span class="toc-number">10.</span> <span class="toc-text">DAGScheduler.submitMissingTasks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TaskScheduler-submitTasks"><span class="toc-number">11.</span> <span class="toc-text">TaskScheduler.submitTasks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CoarseGrainedSchedulerBackend-reviveOffers"><span class="toc-number">12.</span> <span class="toc-text">CoarseGrainedSchedulerBackend.reviveOffers</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DriverEndpoint-receive-gt-ReviveOffers-gt-makeOffers"><span class="toc-number">13.</span> <span class="toc-text">DriverEndpoint.receive-&gt;ReviveOffers-&gt;makeOffers</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DriverEndpoint-launchTasks"><span class="toc-number">14.</span> <span class="toc-text">DriverEndpoint.launchTasks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ExecutorBackend-receive"><span class="toc-number">15.</span> <span class="toc-text">ExecutorBackend.receive</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Executor-launchTask"><span class="toc-number">16.</span> <span class="toc-text">Executor.launchTask</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DriverEndpoint-receive-gt-StatusUpdate"><span class="toc-number">17.</span> <span class="toc-text">DriverEndpoint.receive-&gt;StatusUpdate</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.jpg"></div><div class="author-info__name text-center">WangXun</div><div class="author-info__description text-center"></div><div class="follow-button"><a target="_blank" rel="noopener" href="https://github.com/w749">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">71</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">20</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">6</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/top-img.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Wake</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">Spark源码-collect流程</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2022-10-18</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Software/">Software</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">4k</span><span class="post-meta__separator">|</span><span>Reading time: 19 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>Spark collect操作流程刨析，从代码中理解Spark执行流程</p>
<span id="more"></span>

<p>没有通过debug而是以collect为入口向下点，中间有几次RPC调用，了解基础的Netty即可找到它实际的调用方法。Spark版本为3.1.2</p>
<div align=center><img src="collect.png"></div>

<h2 id="SparkContext-collect"><a href="#SparkContext-collect" class="headerlink" title="SparkContext.collect"></a>SparkContext.collect</h2><p>点进collect方法，它调用了sc的重载方法runJob，需要传入两个参数分别是当前rdd和一个处理函数，这个处理函数将运行在每个partition对数据进行处理</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collect</span></span>(): <span class="type">Array</span>[<span class="type">T</span>] = withScope &#123;</span><br><span class="line">  <span class="keyword">val</span> results = sc.runJob(<span class="keyword">this</span>, (iter: <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; iter.toArray)</span><br><span class="line">  <span class="type">Array</span>.concat(results: _*)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="SparkContext-runJob-T-U-ClassTag-rdd-RDD-T-func-Iterator-T-x3D-gt-U"><a href="#SparkContext-runJob-T-U-ClassTag-rdd-RDD-T-func-Iterator-T-x3D-gt-U" class="headerlink" title="SparkContext.runJob[T, U: ClassTag](rdd: RDD[T], func: Iterator[T] &#x3D;&gt; U)"></a>SparkContext.runJob[T, U: ClassTag](rdd: RDD[T], func: Iterator[T] &#x3D;&gt; U)</h2><p>点击runJob函数它继续调用自身的重载方法，第三个参数partitions表示处理函数作用在所有的partition，并不是所有的函数都会作用在所有的partition，例如first</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], func: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">U</span>): <span class="type">Array</span>[<span class="type">U</span>] = &#123;</span><br><span class="line">  runJob(rdd, func, <span class="number">0</span> until rdd.partitions.length)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="SparkContext-runJob-T-U-ClassTag-rdd-RDD-T-func-Iterator-T-x3D-gt-U-partitions-Seq-Int"><a href="#SparkContext-runJob-T-U-ClassTag-rdd-RDD-T-func-Iterator-T-x3D-gt-U-partitions-Seq-Int" class="headerlink" title="SparkContext.runJob[T, U: ClassTag](rdd: RDD[T],func: Iterator[T] &#x3D;&gt; U,partitions: Seq[Int])"></a>SparkContext.runJob[T, U: ClassTag](rdd: RDD[T],func: Iterator[T] &#x3D;&gt; U,partitions: Seq[Int])</h2><p>继续点runJob会调用clean函数对处理函数进行闭包清理，有关闭包清理查看另一篇文章 <a href="">ClosureCleaner</a></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>]): <span class="type">Array</span>[<span class="type">U</span>] = &#123;</span><br><span class="line">  <span class="keyword">val</span> cleanedFunc = clean(func)</span><br><span class="line">  runJob(rdd, (ctx: <span class="type">TaskContext</span>, it: <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; cleanedFunc(it), partitions)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="SparkContext-runJob-T-U-ClassTag-rdd-RDD-T-func-TaskContext-Iterator-T-x3D-gt-U-partitions-Seq-Int-resultHandler-Int-U-x3D-gt-Unit"><a href="#SparkContext-runJob-T-U-ClassTag-rdd-RDD-T-func-TaskContext-Iterator-T-x3D-gt-U-partitions-Seq-Int-resultHandler-Int-U-x3D-gt-Unit" class="headerlink" title="SparkContext.runJob[T, U: ClassTag](rdd: RDD[T],func: (TaskContext, Iterator[T]) &#x3D;&gt; U,partitions: Seq[Int],resultHandler: (Int, U) &#x3D;&gt; Unit)"></a>SparkContext.runJob[T, U: ClassTag](rdd: RDD[T],func: (TaskContext, Iterator[T]) &#x3D;&gt; U,partitions: Seq[Int],resultHandler: (Int, U) &#x3D;&gt; Unit)</h2><p>继续点两次runJob会到一个比较重要的函数，它几乎是所有action的入口函数</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">    <span class="comment">// resultHandler是一个回调函数，用来生成每一个结果</span></span><br><span class="line">    resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (stopped.get()) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">&quot;SparkContext has been shutdown&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 标识调用当前方法的代码位置，例如在web界面看到的stage标识，分为短标识和长标识，短标识代表你写的代码中的具体位置和方法，长标识代表代码的调用路径</span></span><br><span class="line">  <span class="keyword">val</span> callSite = getCallSite</span><br><span class="line">  <span class="keyword">val</span> cleanedFunc = clean(func)</span><br><span class="line">  logInfo(<span class="string">&quot;Starting job: &quot;</span> + callSite.shortForm)</span><br><span class="line">  <span class="keyword">if</span> (conf.getBoolean(<span class="string">&quot;spark.logLineage&quot;</span>, <span class="literal">false</span>)) &#123;</span><br><span class="line">    logInfo(<span class="string">&quot;RDD&#x27;s recursive dependencies:\n&quot;</span> + rdd.toDebugString)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 在给定的rdd上运行action函数，并将结果放入resultHandler中</span></span><br><span class="line">  dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)</span><br><span class="line">  <span class="comment">// 进度标识，不重要</span></span><br><span class="line">  progressBar.foreach(_.finishAll())</span><br><span class="line">  rdd.doCheckpoint()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="doCheckpoint"><a href="#doCheckpoint" class="headerlink" title="doCheckpoint"></a>doCheckpoint</h3><h2 id="DAGScheduler-runJob"><a href="#DAGScheduler-runJob" class="headerlink" title="DAGScheduler.runJob"></a>DAGScheduler.runJob</h2><p>向DAGScheduler提交一个action作业并等待作业完成后打印失败或成功日志</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> start = <span class="type">System</span>.nanoTime</span><br><span class="line">  <span class="comment">// 向DAGScheduler提交一个action作业，重要入口</span></span><br><span class="line">  <span class="keyword">val</span> waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)</span><br><span class="line">  <span class="comment">// 等待作业执行完成</span></span><br><span class="line">  <span class="type">ThreadUtils</span>.awaitReady(waiter.completionFuture, <span class="type">Duration</span>.<span class="type">Inf</span>)</span><br><span class="line">  <span class="comment">// 作业成功打印日志，失败则打印错误</span></span><br><span class="line">  waiter.completionFuture.value.get <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> scala.util.<span class="type">Success</span>(_) =&gt;</span><br><span class="line">      logInfo(<span class="string">&quot;Job %d finished: %s, took %f s&quot;</span>.format</span><br><span class="line">        (waiter.jobId, callSite.shortForm, (<span class="type">System</span>.nanoTime - start) / <span class="number">1e9</span>))</span><br><span class="line">    <span class="keyword">case</span> scala.util.<span class="type">Failure</span>(exception) =&gt;</span><br><span class="line">      logInfo(<span class="string">&quot;Job %d failed: %s, took %f s&quot;</span>.format</span><br><span class="line">        (waiter.jobId, callSite.shortForm, (<span class="type">System</span>.nanoTime - start) / <span class="number">1e9</span>))</span><br><span class="line">      <span class="comment">// SPARK-8644: Include user stack trace in exceptions coming from DAGScheduler.</span></span><br><span class="line">      <span class="keyword">val</span> callerStackTrace = <span class="type">Thread</span>.currentThread().getStackTrace.tail</span><br><span class="line">      exception.setStackTrace(exception.getStackTrace ++ callerStackTrace)</span><br><span class="line">      <span class="keyword">throw</span> exception</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="DAGScheduler-submitJob"><a href="#DAGScheduler-submitJob" class="headerlink" title="DAGScheduler.submitJob"></a>DAGScheduler.submitJob</h2><p>先对partitions进行处理，然后将作业JobSubmitted放入eventProcessLoop</p>
<p>SparkListenerJobStart继承自SparkListenerEvent，它有许多子类用来监控不同事件的运行状态，详情查看另一篇文章 <a href="">SparkListenerEvent</a></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">submitJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>): <span class="type">JobWaiter</span>[<span class="type">U</span>] = &#123;</span><br><span class="line">  <span class="comment">// 如果存在给定的partition大于分区长度或者小于0则抛出异常</span></span><br><span class="line">  <span class="keyword">val</span> maxPartitions = rdd.partitions.length</span><br><span class="line">  partitions.find(p =&gt; p &gt;= maxPartitions || p &lt; <span class="number">0</span>).foreach &#123; p =&gt;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(</span><br><span class="line">      <span class="string">&quot;Attempting to access a non-existent partition: &quot;</span> + p + <span class="string">&quot;. &quot;</span> +</span><br><span class="line">        <span class="string">&quot;Total number of partitions: &quot;</span> + maxPartitions)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 提交一次作业可以有多个job，给每个job分配递增ID</span></span><br><span class="line">  <span class="keyword">val</span> jobId = nextJobId.getAndIncrement()</span><br><span class="line">  <span class="comment">// 处理partitions为空的情况，没有分区供你处理，直接标识任务开始任务结束</span></span><br><span class="line">  <span class="keyword">if</span> (partitions.isEmpty) &#123;</span><br><span class="line">    <span class="keyword">val</span> clonedProperties = <span class="type">Utils</span>.cloneProperties(properties)</span><br><span class="line">    <span class="keyword">if</span> (sc.getLocalProperty(<span class="type">SparkContext</span>.<span class="type">SPARK_JOB_DESCRIPTION</span>) == <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="comment">// 标识调用的代码位置</span></span><br><span class="line">      clonedProperties.setProperty(<span class="type">SparkContext</span>.<span class="type">SPARK_JOB_DESCRIPTION</span>, callSite.shortForm)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">val</span> time = clock.getTimeMillis()</span><br><span class="line">    listenerBus.post(</span><br><span class="line">      <span class="type">SparkListenerJobStart</span>(jobId, time, <span class="type">Seq</span>.empty, clonedProperties))</span><br><span class="line">    listenerBus.post(</span><br><span class="line">      <span class="type">SparkListenerJobEnd</span>(jobId, time, <span class="type">JobSucceeded</span>))</span><br><span class="line">    <span class="comment">// Return immediately if the job is running 0 tasks</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">JobWaiter</span>[<span class="type">U</span>](<span class="keyword">this</span>, jobId, <span class="number">0</span>, resultHandler)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  assert(partitions.nonEmpty)</span><br><span class="line">  <span class="keyword">val</span> func2 = func.asInstanceOf[(<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _]</span><br><span class="line">  <span class="keyword">val</span> waiter = <span class="keyword">new</span> <span class="type">JobWaiter</span>[<span class="type">U</span>](<span class="keyword">this</span>, jobId, partitions.size, resultHandler)</span><br><span class="line">  <span class="comment">// 将作业JobSubmitted放入eventProcessLoop，着重介绍DAGSchedulerEventProcessLoop</span></span><br><span class="line">  eventProcessLoop.post(<span class="type">JobSubmitted</span>(</span><br><span class="line">    jobId, rdd, func2, partitions.toArray, callSite, waiter,</span><br><span class="line">    <span class="type">Utils</span>.cloneProperties(properties)))</span><br><span class="line">  waiter</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="DAGScheduler-eventProcessLoop"><a href="#DAGScheduler-eventProcessLoop" class="headerlink" title="DAGScheduler.eventProcessLoop"></a>DAGScheduler.eventProcessLoop</h2><p>DAGSchedulerEventProcessLoop继承自EventLoop，它提供了一个onReceive用来执行提交给它的事件，包括作业提交JobSubmitted、作业取消JobCancelled、map stage提交MapStageSubmitted等事件，它们统一继承自DAGSchedulerEvent</p>
<p>关于EventLoop它是一个事件循环，用于接收来自调用者（提交任务）的事件并处理事件线程中的所有事件。它将启动一个独占事件线程来处理所有事件，有兴趣的可以看一下源码，实现并不复杂</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[scheduler] <span class="class"><span class="keyword">class</span> <span class="title">DAGSchedulerEventProcessLoop</span>(<span class="params">dagScheduler: <span class="type">DAGScheduler</span></span>)</span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">EventLoop</span>[<span class="type">DAGSchedulerEvent</span>](<span class="string">&quot;dag-scheduler-event-loop&quot;</span>) <span class="keyword">with</span> <span class="type">Logging</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> timer = dagScheduler.metricsSource.messageProcessingTimer</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 从事件队列轮询事件时在事件线程中调用</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onReceive</span></span>(event: <span class="type">DAGSchedulerEvent</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> timerContext = timer.time()</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      doOnReceive(event)</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      timerContext.stop()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doOnReceive</span></span>(event: <span class="type">DAGSchedulerEvent</span>): <span class="type">Unit</span> = event <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">JobSubmitted</span>(jobId, rdd, func, partitions, callSite, listener, properties) =&gt;</span><br><span class="line">      dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> <span class="type">MapStageSubmitted</span>(jobId, dependency, callSite, listener, properties) =&gt;</span><br><span class="line">      dagScheduler.handleMapStageSubmitted(jobId, dependency, callSite, listener, properties)</span><br><span class="line">    <span class="comment">// 后面还有许多</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onError</span></span>(e: <span class="type">Throwable</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    logError(<span class="string">&quot;DAGSchedulerEventProcessLoop failed; shutting down SparkContext&quot;</span>, e)</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      dagScheduler.doCancelAllJobs()</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> t: <span class="type">Throwable</span> =&gt; logError(<span class="string">&quot;DAGScheduler failed to cancel all jobs.&quot;</span>, t)</span><br><span class="line">    &#125;</span><br><span class="line">    dagScheduler.sc.stopInNewThread()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStop</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// Cancel any active jobs in postStop hook</span></span><br><span class="line">    dagScheduler.cleanUpAfterSchedulerStop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="DAGScheduler-handleJobSubmitted"><a href="#DAGScheduler-handleJobSubmitted" class="headerlink" title="DAGScheduler.handleJobSubmitted"></a>DAGScheduler.handleJobSubmitted</h2><p>提交一个job的操作，该函数中主要获取到了父级依赖，父级stage和ResultStage，标识job运行并提交ResultStage</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">handleJobSubmitted</span></span>(jobId: <span class="type">Int</span>,</span><br><span class="line">    finalRDD: <span class="type">RDD</span>[_],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</span><br><span class="line">    partitions: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    listener: <span class="type">JobListener</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">var</span> finalStage: <span class="type">ResultStage</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 获取ResultStage，每碰到一个action算子就产生一个ResultStage</span></span><br><span class="line">    finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">BarrierJobSlotsNumberCheckFailed</span> =&gt;</span><br><span class="line">      <span class="keyword">val</span> numCheckFailures = barrierJobIdToNumTasksCheckFailures.compute(jobId,</span><br><span class="line">        (_: <span class="type">Int</span>, value: <span class="type">Int</span>) =&gt; value + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">      logWarning(<span class="string">s&quot;Barrier stage in job <span class="subst">$jobId</span> requires <span class="subst">$&#123;e.requiredConcurrentTasks&#125;</span> slots, &quot;</span> +</span><br><span class="line">        <span class="string">s&quot;but only <span class="subst">$&#123;e.maxConcurrentTasks&#125;</span> are available. &quot;</span> +</span><br><span class="line">        <span class="string">s&quot;Will retry up to <span class="subst">$&#123;maxFailureNumTasksCheck - numCheckFailures + 1&#125;</span> more times&quot;</span>)</span><br><span class="line">      <span class="comment">// 未达到最大失败次数时在一个新的线程中重新提交该任务</span></span><br><span class="line">      <span class="keyword">if</span> (numCheckFailures &lt;= maxFailureNumTasksCheck) &#123;</span><br><span class="line">        messageScheduler.schedule(</span><br><span class="line">          <span class="keyword">new</span> <span class="type">Runnable</span> &#123;</span><br><span class="line">            <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = eventProcessLoop.post(<span class="type">JobSubmitted</span>(jobId, finalRDD, func,</span><br><span class="line">              partitions, callSite, listener, properties))</span><br><span class="line">          &#125;,</span><br><span class="line">          timeIntervalNumTasksCheck,</span><br><span class="line">          <span class="type">TimeUnit</span>.<span class="type">SECONDS</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        barrierJobIdToNumTasksCheckFailures.remove(jobId)</span><br><span class="line">        listener.jobFailed(e)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">      logWarning(<span class="string">&quot;Creating new stage failed due to exception - job: &quot;</span> + jobId, e)</span><br><span class="line">      listener.jobFailed(e)</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Job submitted, clear internal data.</span></span><br><span class="line">  barrierJobIdToNumTasksCheckFailures.remove(jobId)</span><br><span class="line">  <span class="comment">// 新建一个ActiveJob，每一个action算子是一个job</span></span><br><span class="line">  <span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">ActiveJob</span>(jobId, finalStage, callSite, listener, properties)</span><br><span class="line">  clearCacheLocs()</span><br><span class="line">  logInfo(<span class="string">&quot;Got job %s (%s) with %d output partitions&quot;</span>.format(</span><br><span class="line">    job.jobId, callSite.shortForm, partitions.length))</span><br><span class="line">  logInfo(<span class="string">&quot;Final stage: &quot;</span> + finalStage + <span class="string">&quot; (&quot;</span> + finalStage.name + <span class="string">&quot;)&quot;</span>)</span><br><span class="line">  logInfo(<span class="string">&quot;Parents of final stage: &quot;</span> + finalStage.parents)</span><br><span class="line">  logInfo(<span class="string">&quot;Missing parents: &quot;</span> + getMissingParentStages(finalStage))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> jobSubmissionTime = clock.getTimeMillis()</span><br><span class="line">  <span class="comment">// 将此ActiveJob放入jobIdToActiveJob和activeJobs</span></span><br><span class="line">  jobIdToActiveJob(jobId) = job</span><br><span class="line">  activeJobs += job</span><br><span class="line">  <span class="comment">// 将ActiveJob绑定到ResultStage</span></span><br><span class="line">  finalStage.setActiveJob(job)</span><br><span class="line">  <span class="keyword">val</span> stageIds = jobIdToStageIds(jobId).toArray</span><br><span class="line">  <span class="keyword">val</span> stageInfos = stageIds.flatMap(id =&gt; stageIdToStage.get(id).map(_.latestInfo))</span><br><span class="line">  listenerBus.post(</span><br><span class="line">    <span class="type">SparkListenerJobStart</span>(job.jobId, jobSubmissionTime, stageInfos,</span><br><span class="line">      <span class="type">Utils</span>.cloneProperties(properties)))</span><br><span class="line">  <span class="comment">// 提交ResultStage</span></span><br><span class="line">  submitStage(finalStage)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="DAGScheduler-createResultStage"><a href="#DAGScheduler-createResultStage" class="headerlink" title="DAGScheduler.createResultStage"></a>DAGScheduler.createResultStage</h3><p>ResultStage继承自Stage，Stage有两个子类分别是ResultStage和ShuffleMapStage，ShuffleMapStage存在于两个shuffle依赖之间，而ResultStage则是整个job的最后一个依赖</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createResultStage</span></span>(</span><br><span class="line">    rdd: <span class="type">RDD</span>[_],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</span><br><span class="line">    partitions: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">    jobId: <span class="type">Int</span>,</span><br><span class="line">    callSite: <span class="type">CallSite</span>): <span class="type">ResultStage</span> = &#123;</span><br><span class="line">  <span class="comment">// 返回给定rdd的直接父级的shuffle依赖以及与此stage的rdd关联的ResourceProfiles（ResourceProfile支持对指定Stage的资源如内存、磁盘等进行干预）</span></span><br><span class="line">  <span class="keyword">val</span> (shuffleDeps, resourceProfiles) = getShuffleDependenciesAndResourceProfiles(rdd)</span><br><span class="line">  <span class="keyword">val</span> resourceProfile = mergeResourceProfilesForStage(resourceProfiles)</span><br><span class="line">  checkBarrierStageWithDynamicAllocation(rdd)</span><br><span class="line">  checkBarrierStageWithNumSlots(rdd, resourceProfile)</span><br><span class="line">  checkBarrierStageWithRDDChainPattern(rdd, partitions.toSet.size)</span><br><span class="line">  <span class="comment">// 根据当前rdd的父级shuffle依赖获取或者创建它的ShuffleMapStage</span></span><br><span class="line">  <span class="keyword">val</span> parents = getOrCreateParentStages(shuffleDeps, jobId)</span><br><span class="line">  <span class="comment">// stageId在同一个job中递增</span></span><br><span class="line">  <span class="keyword">val</span> id = nextStageId.getAndIncrement()</span><br><span class="line">  <span class="keyword">val</span> stage = <span class="keyword">new</span> <span class="type">ResultStage</span>(id, rdd, func, partitions, parents, jobId,</span><br><span class="line">    callSite, resourceProfile.id)</span><br><span class="line">  stageIdToStage(id) = stage  <span class="comment">// 更新stageId和stage的map</span></span><br><span class="line">  updateJobIdStageIdMaps(jobId, stage)  <span class="comment">// 更新jobId和stageId的map</span></span><br><span class="line">  stage</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="DAGScheduler-submitStage"><a href="#DAGScheduler-submitStage" class="headerlink" title="DAGScheduler.submitStage"></a>DAGScheduler.submitStage</h2><p>提交当前ResultStage，但首先提交它的父级未提交的ShuffleMapStage，这个方法会从ResultStage向上迭代寻找父级ShuffleMapStage并从最开始向后提交stage</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitStage</span></span>(stage: <span class="type">Stage</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 找到最早创建该stage的jobId</span></span><br><span class="line">  <span class="keyword">val</span> jobId = activeJobForStage(stage)</span><br><span class="line">  <span class="keyword">if</span> (jobId.isDefined) &#123;</span><br><span class="line">    logDebug(<span class="string">s&quot;submitStage(<span class="subst">$stage</span> (name=<span class="subst">$&#123;stage.name&#125;</span>;&quot;</span> +</span><br><span class="line">      <span class="string">s&quot;jobs=<span class="subst">$&#123;stage.jobIds.toSeq.sorted.mkString(&quot;,&quot;)&#125;</span>))&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123;</span><br><span class="line">      <span class="comment">// 寻找它的父级未提交的ShuffleMapStage</span></span><br><span class="line">      <span class="keyword">val</span> missing = getMissingParentStages(stage).sortBy(_.id)</span><br><span class="line">      logDebug(<span class="string">&quot;missing: &quot;</span> + missing)</span><br><span class="line">      <span class="keyword">if</span> (missing.isEmpty) &#123;</span><br><span class="line">        logInfo(<span class="string">&quot;Submitting &quot;</span> + stage + <span class="string">&quot; (&quot;</span> + stage.rdd + <span class="string">&quot;), which has no missing parents&quot;</span>)</span><br><span class="line">        <span class="comment">// 如果没找到则代表已经找到起始的ShuffleMapStage，从起始stage开始提交</span></span><br><span class="line">        submitMissingTasks(stage, jobId.get)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 如果找到了则将遍历继续寻找父级ShuffleMapStage的ShuffleMapStage</span></span><br><span class="line">        <span class="keyword">for</span> (parent &lt;- missing) &#123;</span><br><span class="line">          submitStage(parent)</span><br><span class="line">        &#125;</span><br><span class="line">        waitingStages += stage</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    abortStage(stage, <span class="string">&quot;No active job for stage &quot;</span> + stage.id, <span class="type">None</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="DAGScheduler-submitMissingTasks"><a href="#DAGScheduler-submitMissingTasks" class="headerlink" title="DAGScheduler.submitMissingTasks"></a>DAGScheduler.submitMissingTasks</h2><p>查找stage对应的需要运行的taskID和位置等信息，由TaskScheduler提交并运行</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitMissingTasks</span></span>(stage: <span class="type">Stage</span>, jobId: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 返回需要计算的taskID</span></span><br><span class="line">  <span class="keyword">val</span> partitionsToCompute: <span class="type">Seq</span>[<span class="type">Int</span>] = stage.findMissingPartitions()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 省略</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取taskID对应的运行位置</span></span><br><span class="line">  <span class="keyword">val</span> taskIdToLocations: <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Seq</span>[<span class="type">TaskLocation</span>]] = <span class="keyword">try</span> &#123;</span><br><span class="line">    stage <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt; (id, getPreferredLocs(stage.rdd, id))&#125;.toMap</span><br><span class="line">      <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">          <span class="keyword">val</span> p = s.partitions(id)</span><br><span class="line">          (id, getPreferredLocs(stage.rdd, p))</span><br><span class="line">        &#125;.toMap</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">      stage.makeNewStageAttempt(partitionsToCompute.size)</span><br><span class="line">      listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo,</span><br><span class="line">        <span class="type">Utils</span>.cloneProperties(properties)))</span><br><span class="line">      abortStage(stage, <span class="string">s&quot;Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;Utils.exceptionString(e)&#125;</span>&quot;</span>, <span class="type">Some</span>(e))</span><br><span class="line">      runningStages -= stage</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 创建一个新的StageInfo并将_latestInfo指向最新的StageInfo</span></span><br><span class="line">  stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 更新stage从DAGScheduler提交到TaskScheduler的时间并标识该stage一提交</span></span><br><span class="line">  <span class="keyword">if</span> (partitionsToCompute.nonEmpty) &#123;</span><br><span class="line">    stage.latestInfo.submissionTime = <span class="type">Some</span>(clock.getTimeMillis())</span><br><span class="line">  &#125;</span><br><span class="line">  listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo,</span><br><span class="line">    <span class="type">Utils</span>.cloneProperties(properties)))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将stage序列化并作为广播变量</span></span><br><span class="line">  <span class="keyword">var</span> taskBinary: <span class="type">Broadcast</span>[<span class="type">Array</span>[<span class="type">Byte</span>]] = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">var</span> partitions: <span class="type">Array</span>[<span class="type">Partition</span>] = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> taskBinaryBytes: <span class="type">Array</span>[<span class="type">Byte</span>] = <span class="literal">null</span></span><br><span class="line">    <span class="type">RDDCheckpointData</span>.synchronized &#123;</span><br><span class="line">      taskBinaryBytes = stage <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">          <span class="type">JavaUtils</span>.bufferToArray(</span><br><span class="line">            closureSerializer.serialize((stage.rdd, stage.shuffleDep): <span class="type">AnyRef</span>))</span><br><span class="line">        <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">          <span class="type">JavaUtils</span>.bufferToArray(closureSerializer.serialize((stage.rdd, stage.func): <span class="type">AnyRef</span>))</span><br><span class="line">      &#125;</span><br><span class="line">      partitions = stage.rdd.partitions</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (taskBinaryBytes.length &gt; <span class="type">TaskSetManager</span>.<span class="type">TASK_SIZE_TO_WARN_KIB</span> * <span class="number">1024</span>) &#123;</span><br><span class="line">      logWarning(<span class="string">s&quot;Broadcasting large task binary with size &quot;</span> +</span><br><span class="line">        <span class="string">s&quot;<span class="subst">$&#123;Utils.bytesToString(taskBinaryBytes.length)&#125;</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将taskBinaryBytes广播出去</span></span><br><span class="line">    taskBinary = sc.broadcast(taskBinaryBytes)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">NotSerializableException</span> =&gt;</span><br><span class="line">    <span class="comment">// 省略</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 创建对应的ShuffleMapTask或者ResultTask，它们是Task的子类，对应ShuffleMapStage和ResultStage。一个Stage可以有多个task并行处理</span></span><br><span class="line">  <span class="keyword">val</span> tasks: <span class="type">Seq</span>[<span class="type">Task</span>[_]] = <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> serializedTaskMetrics = closureSerializer.serialize(stage.latestInfo.taskMetrics).array()</span><br><span class="line">    stage <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">        stage.pendingPartitions.clear()</span><br><span class="line">        <span class="comment">// 根据需要运行的taskId创建多个task</span></span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">          <span class="keyword">val</span> part = partitions(id)</span><br><span class="line">          stage.pendingPartitions += id</span><br><span class="line">          <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptNumber,</span><br><span class="line">            taskBinary, part, locs, properties, serializedTaskMetrics, <span class="type">Option</span>(jobId),</span><br><span class="line">            <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId, stage.rdd.isBarrier())</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">          <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</span><br><span class="line">          <span class="keyword">val</span> part = partitions(p)</span><br><span class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">          <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptNumber,</span><br><span class="line">            taskBinary, part, locs, id, properties, serializedTaskMetrics,</span><br><span class="line">            <span class="type">Option</span>(jobId), <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId,</span><br><span class="line">            stage.rdd.isBarrier())</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">      abortStage(stage, <span class="string">s&quot;Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;Utils.exceptionString(e)&#125;</span>&quot;</span>, <span class="type">Some</span>(e))</span><br><span class="line">      runningStages -= stage</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 接下来就由TaskScheduler提交task去运行了，它的实现类是TaskSchedulerImpl，可以被其他scheduler实现例如YARN</span></span><br><span class="line">  <span class="keyword">if</span> (tasks.nonEmpty) &#123;</span><br><span class="line">    logInfo(<span class="string">s&quot;Submitting <span class="subst">$&#123;tasks.size&#125;</span> missing tasks from <span class="subst">$stage</span> (<span class="subst">$&#123;stage.rdd&#125;</span>) (first 15 &quot;</span> +</span><br><span class="line">      <span class="string">s&quot;tasks are for partitions <span class="subst">$&#123;tasks.take(15).map(_.partitionId)&#125;</span>)&quot;</span>)</span><br><span class="line">    taskScheduler.submitTasks(<span class="keyword">new</span> <span class="type">TaskSet</span>(</span><br><span class="line">      tasks.toArray, stage.id, stage.latestInfo.attemptNumber, jobId, properties,</span><br><span class="line">      stage.resourceProfileId))</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    markStageAsFinished(stage, <span class="type">None</span>)</span><br><span class="line">    <span class="comment">// 省略</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="TaskScheduler-submitTasks"><a href="#TaskScheduler-submitTasks" class="headerlink" title="TaskScheduler.submitTasks"></a>TaskScheduler.submitTasks</h2><p>提交一个需要运行的task序列到Pool，最终由SchedulerBackend更新并启动它们</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">submitTasks</span></span>(taskSet: <span class="type">TaskSet</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> tasks = taskSet.tasks</span><br><span class="line">  logInfo(<span class="string">&quot;Adding task set &quot;</span> + taskSet.id + <span class="string">&quot; with &quot;</span> + tasks.length + <span class="string">&quot; tasks &quot;</span></span><br><span class="line">    + <span class="string">&quot;resource profile &quot;</span> + taskSet.resourceProfileId)</span><br><span class="line">  <span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">    <span class="comment">// 创建TaskSetManager，它在TaskSchedulerImpl中的单个TaskSet中调度任务。此类跟踪每个task，如果任务task失败（最多失败次数以内）重试任务</span></span><br><span class="line">    <span class="keyword">val</span> manager = createTaskSetManager(taskSet, maxTaskFailures)</span><br><span class="line">    <span class="keyword">val</span> stage = taskSet.stageId</span><br><span class="line">    <span class="keyword">val</span> stageTaskSets =</span><br><span class="line">      taskSetsByStageIdAndAttempt.getOrElseUpdate(stage, <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">TaskSetManager</span>])</span><br><span class="line"></span><br><span class="line">    stageTaskSets.foreach &#123; <span class="keyword">case</span> (_, ts) =&gt;</span><br><span class="line">      ts.isZombie = <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">    stageTaskSets(taskSet.stageAttemptId) = manager</span><br><span class="line">    <span class="comment">// 将TaskSetManager添加到Pool队列中，由它来根据Fair或者FIFO算法调度TaskSetManager</span></span><br><span class="line">    schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!isLocal &amp;&amp; !hasReceivedTask) &#123;</span><br><span class="line">      starvationTimer.scheduleAtFixedRate(<span class="keyword">new</span> <span class="type">TimerTask</span>() &#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">          <span class="keyword">if</span> (!hasLaunchedTask) &#123;</span><br><span class="line">            logWarning(<span class="string">&quot;Initial job has not accepted any resources; &quot;</span> +</span><br><span class="line">              <span class="string">&quot;check your cluster UI to ensure that workers are registered &quot;</span> +</span><br><span class="line">              <span class="string">&quot;and have sufficient resources&quot;</span>)</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.cancel()</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;, <span class="type">STARVATION_TIMEOUT_MS</span>, <span class="type">STARVATION_TIMEOUT_MS</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    hasReceivedTask = <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 更新并安排运行task，向driver发送一条ReviveOffers消息，再往后就是RPC相关的点了</span></span><br><span class="line">  backend.reviveOffers()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="CoarseGrainedSchedulerBackend-reviveOffers"><a href="#CoarseGrainedSchedulerBackend-reviveOffers" class="headerlink" title="CoarseGrainedSchedulerBackend.reviveOffers"></a>CoarseGrainedSchedulerBackend.reviveOffers</h2><p>backend是SchedulerBackend，它是一个特质，由其他调度系统继承并重写，例如Mesos、Yarn等等。</p>
<p>这里以YarnSchedulerBackend为例，假设提交到Yarn上，它其实调用的是CoarseGrainedSchedulerBackend的reviveOffers方法，向driver发送一个ReviveOffers消息</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建DriverEndpoint</span></span><br><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">createDriverEndpoint</span></span>(): <span class="type">DriverEndpoint</span> = <span class="keyword">new</span> <span class="type">DriverEndpoint</span>()</span><br><span class="line"><span class="comment">// 获取DriverEndpointRef，向谁发送消息就要获取谁的Ref</span></span><br><span class="line"><span class="keyword">val</span> driverEndpoint = rpcEnv.setupEndpoint(<span class="type">ENDPOINT_NAME</span>, createDriverEndpoint())</span><br><span class="line">  <span class="comment">// createDriverEndpoint方法被YarnSchedulerBackend重写了，所以返回的是YarnDriverEndpoint，但是YarnDriverEndpoint没重写receive方法，所以接收消息还是得看DriverEndpoint的receive</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createDriverEndpoint</span></span>(): <span class="type">DriverEndpoint</span> = &#123;</span><br><span class="line">      <span class="keyword">new</span> <span class="type">YarnDriverEndpoint</span>()</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// ReviveOffers就是一个Spark内部的消息，像start或stop一样代表不同的含义</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reviveOffers</span></span>(): <span class="type">Unit</span> = <span class="type">Utils</span>.tryLogNonFatalError &#123;</span><br><span class="line">  driverEndpoint.send(<span class="type">ReviveOffers</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="DriverEndpoint-receive-gt-ReviveOffers-gt-makeOffers"><a href="#DriverEndpoint-receive-gt-ReviveOffers-gt-makeOffers" class="headerlink" title="DriverEndpoint.receive-&gt;ReviveOffers-&gt;makeOffers"></a>DriverEndpoint.receive-&gt;ReviveOffers-&gt;makeOffers</h2><p>DriverEndpoint的receive的方法对ReviveOffers的处理方法就是调用makeOffers方法，这个方法目的是封装task的任务描述，然后在executor启动这些任务</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeOffers</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 返回我们提交的task的任务描述，包含taskId，executorId、task内容、jar包和file等</span></span><br><span class="line">  <span class="keyword">val</span> taskDescs = withLock &#123;</span><br><span class="line">    <span class="comment">// 过滤掉killed的executor</span></span><br><span class="line">    <span class="keyword">val</span> activeExecutors = executorDataMap.filterKeys(isExecutorActive)</span><br><span class="line">    <span class="keyword">val</span> workOffers = activeExecutors.map &#123;</span><br><span class="line">      <span class="keyword">case</span> (id, executorData) =&gt;</span><br><span class="line">        <span class="comment">// 用来存放executor上可用的免费资源，暂且不管ExecutorData是如何管理它自身的资源的</span></span><br><span class="line">        <span class="keyword">new</span> <span class="type">WorkerOffer</span>(id, executorData.executorHost, executorData.freeCores,</span><br><span class="line">          <span class="type">Some</span>(executorData.executorAddress.hostPort),</span><br><span class="line">          executorData.resourcesInfo.map &#123; <span class="keyword">case</span> (rName, rInfo) =&gt;</span><br><span class="line">            (rName, rInfo.availableAddrs.toBuffer)</span><br><span class="line">          &#125;, executorData.resourceProfileId)</span><br><span class="line">    &#125;.toIndexedSeq</span><br><span class="line">    <span class="comment">// 获取task的任务描述，这个方法中会从上面的Pool对象中的队列里按FIFO或者Fair算法获取TaskSetManager列表，也就是我们刚才提交的task</span></span><br><span class="line">    <span class="comment">// 然后给这些TaskSetManager分配WorkerOffer资源，细节比较复杂</span></span><br><span class="line">    scheduler.resourceOffers(workOffers, <span class="literal">true</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (taskDescs.nonEmpty) &#123;</span><br><span class="line">    launchTasks(taskDescs)  <span class="comment">// 启动这些任务</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="DriverEndpoint-launchTasks"><a href="#DriverEndpoint-launchTasks" class="headerlink" title="DriverEndpoint.launchTasks"></a>DriverEndpoint.launchTasks</h2><p>启动这些任务，将task任务描述序列化后封装为LaunchTask消息发送到对应的executor去执行</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">launchTasks</span></span>(tasks: <span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">TaskDescription</span>]]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">for</span> (task &lt;- tasks.flatten) &#123;</span><br><span class="line">    <span class="comment">// 序列化TaskDescription</span></span><br><span class="line">    <span class="keyword">val</span> serializedTask = <span class="type">TaskDescription</span>.encode(task)</span><br><span class="line">    <span class="comment">// 省略</span></span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> executorData = executorDataMap(task.executorId)</span><br><span class="line">      <span class="comment">// 在这里分配task资源，这些资源在task运行完之后释放</span></span><br><span class="line">      <span class="keyword">val</span> rpId = executorData.resourceProfileId</span><br><span class="line">      <span class="keyword">val</span> prof = scheduler.sc.resourceProfileManager.resourceProfileFromId(rpId)</span><br><span class="line">      <span class="keyword">val</span> taskCpus = <span class="type">ResourceProfile</span>.getTaskCpusOrDefaultForProfile(prof, conf)</span><br><span class="line">      executorData.freeCores -= taskCpus</span><br><span class="line">      task.resources.foreach &#123; <span class="keyword">case</span> (rName, rInfo) =&gt;</span><br><span class="line">        assert(executorData.resourcesInfo.contains(rName))</span><br><span class="line">        executorData.resourcesInfo(rName).acquire(rInfo.addresses)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      logDebug(<span class="string">s&quot;Launching task <span class="subst">$&#123;task.taskId&#125;</span> on executor id: <span class="subst">$&#123;task.executorId&#125;</span> hostname: &quot;</span> +</span><br><span class="line">        <span class="string">s&quot;<span class="subst">$&#123;executorData.executorHost&#125;</span>.&quot;</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 将LaunchTask消息发送到对应的executor去执行</span></span><br><span class="line">      executorData.executorEndpoint.send(<span class="type">LaunchTask</span>(<span class="keyword">new</span> <span class="type">SerializableBuffer</span>(serializedTask)))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="ExecutorBackend-receive"><a href="#ExecutorBackend-receive" class="headerlink" title="ExecutorBackend.receive"></a>ExecutorBackend.receive</h2><p>上述LaunchTask消息最终发送给CoarseGrainedExecutorBackend，它实现了ExecutorBackend，所以直接去看它的receive方法</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">  <span class="comment">// 省略</span></span><br><span class="line">  <span class="keyword">case</span> <span class="type">LaunchTask</span>(data) =&gt;</span><br><span class="line">    <span class="keyword">if</span> (executor == <span class="literal">null</span>) &#123;</span><br><span class="line">      exitExecutor(<span class="number">1</span>, <span class="string">&quot;Received LaunchTask command but executor was null&quot;</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 反序列化TaskDescription</span></span><br><span class="line">      <span class="keyword">val</span> taskDesc = <span class="type">TaskDescription</span>.decode(data.value)</span><br><span class="line">      logInfo(<span class="string">&quot;Got assigned task &quot;</span> + taskDesc.taskId)</span><br><span class="line">      taskResources(taskDesc.taskId) = taskDesc.resources</span><br><span class="line">      <span class="comment">// 终于到了Executor</span></span><br><span class="line">      executor.launchTask(<span class="keyword">this</span>, taskDesc)</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="comment">// 省略</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Executor-launchTask"><a href="#Executor-launchTask" class="headerlink" title="Executor.launchTask"></a>Executor.launchTask</h2><p>在该Executor执行task并将结果发送给driver</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">launchTask</span></span>(context: <span class="type">ExecutorBackend</span>, taskDescription: <span class="type">TaskDescription</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 启动一个TaskRunner，它是一个单独的线程，去运行TaskDescription对应的task，执行逻辑在TaskRunner的run方法中</span></span><br><span class="line">  <span class="comment">// 最终还是调用Task的run方法，针对ShuffleMapTask和ResultTask有不同的执行方法，ShuffleMapTask则将中间结果写到磁盘中，ResultTask执行完之后发送StatusUpdate任务成功和结果消息给DriverEndpoint</span></span><br><span class="line">  <span class="keyword">val</span> tr = <span class="keyword">new</span> <span class="type">TaskRunner</span>(context, taskDescription, plugins)</span><br><span class="line">  <span class="comment">// 将该task标识为正在运行</span></span><br><span class="line">  runningTasks.put(taskDescription.taskId, tr)</span><br><span class="line">  <span class="comment">// 执行该task</span></span><br><span class="line">  threadPool.execute(tr)</span><br><span class="line">  <span class="keyword">if</span> (decommissioned) &#123;</span><br><span class="line">    log.error(<span class="string">s&quot;Launching a task while in decommissioned state.&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="DriverEndpoint-receive-gt-StatusUpdate"><a href="#DriverEndpoint-receive-gt-StatusUpdate" class="headerlink" title="DriverEndpoint.receive-&gt;StatusUpdate"></a>DriverEndpoint.receive-&gt;StatusUpdate</h2><p>driver接收到结果数据消息后更新task状态、释放资源、将结果数据传给JobWaiter中的resultHandler</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">StatusUpdate</span>(executorId, taskId, state, data, resources) =&gt;</span><br><span class="line">    <span class="comment">// 更新task状态，并将最终的结果数据传给最开始的JobWaiter中的resultHandler，由此就形成了一个闭环</span></span><br><span class="line">    scheduler.statusUpdate(taskId, state, data.value)</span><br><span class="line">    <span class="comment">// 释放task申请的资源</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="type">TaskState</span>.isFinished(state)) &#123;</span><br><span class="line">      executorDataMap.get(executorId) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Some</span>(executorInfo) =&gt;</span><br><span class="line">          <span class="keyword">val</span> rpId = executorInfo.resourceProfileId</span><br><span class="line">          <span class="keyword">val</span> prof = scheduler.sc.resourceProfileManager.resourceProfileFromId(rpId)</span><br><span class="line">          <span class="keyword">val</span> taskCpus = <span class="type">ResourceProfile</span>.getTaskCpusOrDefaultForProfile(prof, conf)</span><br><span class="line">          executorInfo.freeCores += taskCpus</span><br><span class="line">          resources.foreach &#123; <span class="keyword">case</span> (k, v) =&gt;</span><br><span class="line">            executorInfo.resourcesInfo.get(k).foreach &#123; r =&gt;</span><br><span class="line">              r.release(v.addresses)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          makeOffers(executorId)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">          <span class="comment">// Ignoring the update since we don&#x27;t know about the executor.</span></span><br><span class="line">          logWarning(<span class="string">s&quot;Ignored task status update (<span class="subst">$taskId</span> state <span class="subst">$state</span>) &quot;</span> +</span><br><span class="line">            <span class="string">s&quot;from unknown executor with ID <span class="subst">$executorId</span>&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="comment">// 省略</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">WangXun</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://wangxukun.top/2022/10/18/Software/Spark源码-collect流程/">https://wangxukun.top/2022/10/18/Software/Spark源码-collect流程/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Spark/">Spark</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2022/10/24/Software/Spark%E6%BA%90%E7%A0%81-broadcast%E6%B5%81%E7%A8%8B%E5%8E%9F%E7%90%86/"><i class="fa fa-chevron-left">  </i><span>Spark源码-broadcast流程原理</span></a></div><div class="next-post pull-right"><a href="/2022/09/16/Language/Shell-If%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"><span>Shell-If条件判断</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'aaf2844e0aeef4917c17',
  clientSecret: '10b96d24dffda7d3b4544778cf620f81990b676d',
  repo: 'blog-issue',
  owner: 'w749',
  admin: 'w749',
  id: md5(decodeURI(location.pathname)),
  language: 'en'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(/img/top-img.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2019 - 2022 By WangXun</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/lib/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.1"></script><script src="/js/fancybox.js?version=1.9.1"></script><script src="/js/sidebar.js?version=1.9.1"></script><script src="/js/copy.js?version=1.9.1"></script><script src="/js/fireworks.js?version=1.9.1"></script><script src="/js/transition.js?version=1.9.1"></script><script src="/js/scroll.js?version=1.9.1"></script><script src="/js/head.js?version=1.9.1"></script><script src="/js/search/algolia.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>