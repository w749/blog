<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="常用软件命令"><meta name="keywords" content="Other"><meta name="author" content="WangXun"><meta name="copyright" content="WangXun"><title>常用软件命令 | Wake</title><link rel="shortcut icon" href="/img/favicon-blank.svg"><link rel="stylesheet" href="/css/index.css?version=1.9.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"HSM2EINL2X","apiKey":"6f1478b12150efd917d5ecfcddfb8b8b","indexName":"wangxun","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '6.0.0'
} </script><meta name="generator" content="Hexo 6.0.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#MySQL"><span class="toc-number">1.</span> <span class="toc-text">MySQL</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MySQL%E5%AE%89%E8%A3%85"><span class="toc-number">1.1.</span> <span class="toc-text">MySQL安装</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E8%80%81%E7%89%88%E6%9C%AC"><span class="toc-number">1.1.1.</span> <span class="toc-text">删除老版本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%89%8D%E7%9A%84%E5%87%86%E5%A4%87"><span class="toc-number">1.1.2.</span> <span class="toc-text">安装前的准备</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E7%99%BB%E5%BD%95"><span class="toc-number">1.1.3.</span> <span class="toc-text">初始化登录</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8MySQL"><span class="toc-number">1.2.</span> <span class="toc-text">远程连接服务器MySQL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6"><span class="toc-number">1.3.</span> <span class="toc-text">MySQL主从复制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEmaster%E6%9C%BA%E5%99%A8"><span class="toc-number">1.3.1.</span> <span class="toc-text">配置master机器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEslave"><span class="toc-number">1.3.2.</span> <span class="toc-text">配置slave</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86"><span class="toc-number">1.3.3.</span> <span class="toc-text">故障处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%87%E6%8D%A2%E4%B8%BB%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="toc-number">1.3.4.</span> <span class="toc-text">切换主从服务器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E6%BA%90%E5%A4%8D%E5%88%B6"><span class="toc-number">1.3.5.</span> <span class="toc-text">多源复制</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis"><span class="toc-number">2.</span> <span class="toc-text">Redis</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis%E5%AE%89%E8%A3%85"><span class="toc-number">2.1.</span> <span class="toc-text">Redis安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis%E9%85%8D%E7%BD%AE"><span class="toc-number">2.2.</span> <span class="toc-text">Redis配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95"><span class="toc-number">2.3.</span> <span class="toc-text">Redis基础语法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#shell"><span class="toc-number">2.3.1.</span> <span class="toc-text">shell</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#string"><span class="toc-number">2.3.2.</span> <span class="toc-text">string</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#hash"><span class="toc-number">2.3.3.</span> <span class="toc-text">hash</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#list"><span class="toc-number">2.3.4.</span> <span class="toc-text">list</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#set"><span class="toc-number">2.3.5.</span> <span class="toc-text">set</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B6%E4%BB%96"><span class="toc-number">2.3.6.</span> <span class="toc-text">其他</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-number">2.4.</span> <span class="toc-text">Redis基础知识</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">2.4.1.</span> <span class="toc-text">多数据库</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">2.4.2.</span> <span class="toc-text">数据类型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1"><span class="toc-number">2.4.3.</span> <span class="toc-text">事务</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">2.4.4.</span> <span class="toc-text">持久化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6"><span class="toc-number">2.4.5.</span> <span class="toc-text">主从复制</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop"><span class="toc-number">3.</span> <span class="toc-text">Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E8%AF%91Hadoop"><span class="toc-number">3.1.</span> <span class="toc-text">编译Hadoop</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85"><span class="toc-number">3.2.</span> <span class="toc-text">安装</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85Hadoop"><span class="toc-number">3.2.1.</span> <span class="toc-text">安装Hadoop</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85zookeeper"><span class="toc-number">3.2.2.</span> <span class="toc-text">安装zookeeper</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85Hive"><span class="toc-number">3.2.3.</span> <span class="toc-text">安装Hive</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Zookeeper"><span class="toc-number">3.3.</span> <span class="toc-text">Zookeeper</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS"><span class="toc-number">3.4.</span> <span class="toc-text">HDFS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce"><span class="toc-number">3.5.</span> <span class="toc-text">MapReduce</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive"><span class="toc-number">4.</span> <span class="toc-text">Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%90%AF%E5%8A%A8"><span class="toc-number">4.1.</span> <span class="toc-text">初始化启动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95"><span class="toc-number">4.2.</span> <span class="toc-text">常用语法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-number">4.3.</span> <span class="toc-text">示例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Docker"><span class="toc-number">5.</span> <span class="toc-text">Docker</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-1"><span class="toc-number">5.1.</span> <span class="toc-text">安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%95%9C%E5%83%8F%E5%91%BD%E4%BB%A4"><span class="toc-number">5.2.</span> <span class="toc-text">镜像命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%B9%E5%99%A8%E5%91%BD%E4%BB%A4"><span class="toc-number">5.3.</span> <span class="toc-text">容器命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E5%91%BD%E4%BB%A4"><span class="toc-number">5.4.</span> <span class="toc-text">其他命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%B9%E5%99%A8%E6%95%B0%E6%8D%AE%E5%8D%B7"><span class="toc-number">5.5.</span> <span class="toc-text">容器数据卷</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dockerfile%E3%80%81Docker%E7%BD%91%E7%BB%9C"><span class="toc-number">5.6.</span> <span class="toc-text">Dockerfile、Docker网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E5%B8%83%E9%95%9C%E5%83%8F"><span class="toc-number">5.7.</span> <span class="toc-text">发布镜像</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Docker%E7%BD%91%E7%BB%9C"><span class="toc-number">5.8.</span> <span class="toc-text">Docker网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Docker-Compose"><span class="toc-number">5.9.</span> <span class="toc-text">Docker-Compose</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MongoDB"><span class="toc-number">6.</span> <span class="toc-text">MongoDB</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4%E8%A1%8C"><span class="toc-number">6.0.1.</span> <span class="toc-text">命令行</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SQL%E5%92%8CMQL"><span class="toc-number">6.0.2.</span> <span class="toc-text">SQL和MQL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Python%E6%93%8D%E4%BD%9C"><span class="toc-number">6.0.3.</span> <span class="toc-text">Python操作</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark"><span class="toc-number">7.</span> <span class="toc-text">Spark</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-2"><span class="toc-number">7.1.</span> <span class="toc-text">安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C"><span class="toc-number">7.2.</span> <span class="toc-text">运行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84"><span class="toc-number">7.3.</span> <span class="toc-text">架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="toc-number">7.4.</span> <span class="toc-text">核心概念</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.jpg"></div><div class="author-info__name text-center">WangXun</div><div class="author-info__description text-center"></div><div class="follow-button"><a target="_blank" rel="noopener" href="https://github.com/w749">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">71</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">20</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">6</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/top-img.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Wake</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">常用软件命令</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-10-18</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Language/">Language</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">22.1k</span><span class="post-meta__separator">|</span><span>Reading time: 86 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>常用软件的安装方法以及命令操作。</p>
<span id="more"></span>

<h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><h3 id="MySQL安装"><a href="#MySQL安装" class="headerlink" title="MySQL安装"></a>MySQL安装</h3><h4 id="删除老版本"><a href="#删除老版本" class="headerlink" title="删除老版本"></a>删除老版本</h4><ol>
<li><p>检查是否有MySQL相关包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa|grep -i mysql</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除之前安装的MySQL<br>删除命令：rpm -e –nodeps 包名；<br>如果提示依赖包错误，则使用以下命令尝试：rpm -ev 包名 –nodeps；<br>如果提示错误：error: %preun(xxxxxx) scriptlet failed, exit status 1，则用以下命令尝试：rpm -e –noscripts 包名。</p>
</li>
<li><p>删除以前的MySQL目录、文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find / -name mysql</span><br></pre></td></tr></table></figure>

<p>删除对应目录；<br>注意：卸载后&#x2F;etc&#x2F;my.cnf不会删除，需要进行手工删除：rm -rf &#x2F;etc&#x2F;my.cnf。</p>
</li>
<li><p>再次查找是否存在MySQL包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa|grep -i mysql</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="安装前的准备"><a href="#安装前的准备" class="headerlink" title="安装前的准备"></a>安装前的准备</h4><ol>
<li><p>下载包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://downloads.mysql.com/archives/get/p/23/file/mysql-8.0.21-linux-glibc2.12-x86_64.tar.xz</span><br></pre></td></tr></table></figure>
</li>
<li><p>解压包<br>解压包到指定位置并修改文件名：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -xvf mysql-8.0.21-linux-glibc2.12-x86_64.tar.xz -C /usr/local</span><br><span class="line">cd /usr/local</span><br><span class="line">mv mysql-8.0.21-linux-glibc2.12-x86_64 mysql</span><br><span class="line">mkdir -p /usr/local/mysql/data</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建用户组分配权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">groupadd mysql</span><br><span class="line">useradd -r -g mysql mysql</span><br><span class="line">chown mysql.mysql -R /usr/local/mysql</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置文件<br>vim &#x2F;etc&#x2F;my.profile后添加以下内容，路径随安装路径改变</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">bind-address=0.0.0.0</span><br><span class="line">port=3306</span><br><span class="line">user=mysql</span><br><span class="line">basedir=/usr/local/mysql</span><br><span class="line">datadir=/usr/local/mysql/data</span><br><span class="line">socket=/tmp/mysql.sock</span><br><span class="line">log-error=/usr/local/mysql/data/mysql.err</span><br><span class="line">pid-file=/usr/local/mysql/data/mysql.pid</span><br><span class="line"><span class="meta">#</span><span class="language-bash">character config</span></span><br><span class="line">character_set_server=utf8mb4</span><br><span class="line">symbolic-links=0</span><br><span class="line">explicit_defaults_for_timestamp=true</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="初始化登录"><a href="#初始化登录" class="headerlink" title="初始化登录"></a>初始化登录</h4><ol>
<li><p>初始化<br>首先安装依赖libaio，随后cd到mysql&#x2F;bin目录下初始化<br>初始化完成后需要去查看临时密码以供登录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">yum install -y libaio</span><br><span class="line">cd /usr/local/mysql/bin</span><br><span class="line"><span class="meta"># </span><span class="language-bash">初始化</span></span><br><span class="line">./mysqld --defaults-file=/etc/my.cnf --basedir=/usr/local/mysql/ --datadir=/usr/local/mysql/data/ --user=mysql --initialize</span><br><span class="line"><span class="meta"># </span><span class="language-bash">查看临时密码，在最后一行</span></span><br><span class="line">cat /usr/local/mysql/data/mysql.err</span><br><span class="line"><span class="meta"># </span><span class="language-bash">将mysql.server放置到 /etc/init.d/mysql中</span></span><br><span class="line">cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysql</span><br><span class="line"><span class="meta"># </span><span class="language-bash">启动Mysql</span></span><br><span class="line">service mysql start</span><br><span class="line"><span class="meta"># </span><span class="language-bash">使用临时密码登录MySQL</span></span><br><span class="line">./mysql -uroot -p</span><br></pre></td></tr></table></figure>
</li>
<li><p>登录修改密码</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 修改密码</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">user</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> identified <span class="keyword">by</span> <span class="string">&#x27;123456&#x27;</span>；</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">user</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> password expire never;</span><br><span class="line">flush privileges;</span><br><span class="line">quit;</span><br></pre></td></tr></table></figure>

<p>这时候需要退出登录，重新使用修改后的密码登录</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 使root可以在任何host访问</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> host <span class="operator">=</span> <span class="string">&#x27;%&#x27;</span> <span class="keyword">where</span> <span class="keyword">user</span> <span class="operator">=</span> <span class="string">&#x27;root&#x27;</span>;</span><br><span class="line">flush privileges;</span><br><span class="line">quit;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="远程连接服务器MySQL"><a href="#远程连接服务器MySQL" class="headerlink" title="远程连接服务器MySQL"></a>远程连接服务器MySQL</h3><p>以阿里云Centos8云服务器为例，需要注意的是需要使用公网ip，若是个人电脑则需要两台电台在同一个网段下才可以。</p>
<ol>
<li><p>服务器端MySQL设置</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 登录mysql</span><br><span class="line">use mysql;</span><br><span class="line"># 更新host允许外部访问</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> host<span class="operator">=</span><span class="string">&#x27;%&#x27;</span> <span class="keyword">where</span> <span class="keyword">user</span> <span class="operator">=</span><span class="string">&#x27;root&#x27;</span>;</span><br><span class="line"># 刷新权限</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>

<p>以上是root账号和密码，若需新增用户需要分配对应的读写权限。</p>
</li>
<li><p>服务器端开放端口</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">查看防火墙状态</span></span><br><span class="line">systemctl status firewalld</span><br><span class="line"><span class="meta"># </span><span class="language-bash">查看3306端口是否开放</span></span><br><span class="line">firewall-cmd --query-port=3306/tcp</span><br><span class="line"><span class="meta"># </span><span class="language-bash">开放防火墙端口3306</span></span><br><span class="line">firewall-cmd --zone=public --add-port=3306/tcp --permanent</span><br><span class="line"><span class="meta"># </span><span class="language-bash">重启防火墙</span></span><br><span class="line">systemctl restart firewalld</span><br></pre></td></tr></table></figure>

<p>这是Centos8的设置方法，若是其他系统可能方式不一样。</p>
</li>
<li><p>最重要的步骤<br>阿里云服务器需要在控制台设置安全组，开放3306端口，否则还是无法远程访问。</p>
</li>
</ol>
<h3 id="MySQL主从复制"><a href="#MySQL主从复制" class="headerlink" title="MySQL主从复制"></a>MySQL主从复制</h3><p>前提条件是从MySQL（slave）可以远程访问主MySQL（master）</p>
<h4 id="配置master机器"><a href="#配置master机器" class="headerlink" title="配置master机器"></a><strong>配置master机器</strong></h4><p>首先需要在master开启binlog日志，其次指定binlog日志目录（如果已有就不要改了）和server-id&#x3D;1；</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/my.cnf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">添加以下代码到文件最后</span></span><br><span class="line">log-bin = &quot;/usr/local/mysql/bin-log&quot;</span><br><span class="line">server_id = 1</span><br><span class="line">binlog-do-db = mydb  # 复制哪个数据库</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">配置完成后需要重启MySQL</span></span><br><span class="line">service mysql restart</span><br></pre></td></tr></table></figure>

<p>接下来需要分配一个账号并给replacation slave权限（这里容易出错，要测试账号），查看master状态并记住File和Position对应的值，后面会用到。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 查看log_bin状态</span><br><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;%log_bin%&#x27;</span>;</span><br><span class="line"># 新建账号并分配权限</span><br><span class="line"></span><br><span class="line"># 查看master状态，注意File和Position</span><br><span class="line"><span class="keyword">show</span> master status;</span><br></pre></td></tr></table></figure>

<p>最后需要把现有数据库的数据迁移到slave数据库，position是偏移量，从现有数据库状态的基础上记录日志的行数位置，这里需要同版本同系统，若不相同就不要使用Mysqldump方法了</p>
<h4 id="配置slave"><a href="#配置slave" class="headerlink" title="配置slave"></a><strong>配置slave</strong></h4><p>首先需要在slave开启binlog日志，这里和master一样，其次指定binlog日志目录（如果已有就不要改了）和server-id&#x3D;2</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/my.cnf</span><br><span class="line"><span class="meta"># </span><span class="language-bash">添加以下代码到文件最后</span></span><br><span class="line">log-bin = &quot;/usr/local/mysql/bin-log&quot;</span><br><span class="line">server_id = 2</span><br><span class="line"><span class="meta"># </span><span class="language-bash">配置完成后需要重启MySQL</span></span><br><span class="line">service mysql restart</span><br></pre></td></tr></table></figure>

<p>接下来登录MySQL进行配置</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 关闭slave服务后再进行操作</span><br><span class="line">stop slave;</span><br><span class="line"># master_log_file和master_log_pos对应刚才master的file和position</span><br><span class="line">change master <span class="keyword">to</span> master_host<span class="operator">=</span><span class="string">&#x27;8.131.90.208&#x27;</span>,master_user<span class="operator">=</span><span class="string">&#x27;root&#x27;</span>,master_password<span class="operator">=</span><span class="string">&#x27;Wang1024...&#x27;</span>,master_log_file<span class="operator">=</span><span class="string">&#x27;mysql-bin.000002&#x27;</span>,master_log_pos<span class="operator">=</span><span class="number">775</span>;</span><br><span class="line"></span><br><span class="line"># 启用slave并检查状态</span><br><span class="line"><span class="keyword">start</span> slave;</span><br><span class="line"><span class="keyword">show</span> slave status;</span><br></pre></td></tr></table></figure>

<p>主从复制配置到这里就结束了，需要注意的地方有master账号的权限，尽量不要使用root账号；其次是server-id的设置；再然后是复制的前提是从服务器已存在目标数据库；最后是file和position的正确配置。</p>
<h4 id="故障处理"><a href="#故障处理" class="headerlink" title="故障处理"></a><strong>故障处理</strong></h4><p><strong>问题一</strong>：如果是表结构的问题，可以先停止服务，修改表结构和master相同再start slave</p>
<p><strong>问题二</strong>：出现“log event entry exceeded max_allowed_pack”错误。</p>
<p>如果在应用中使用大的BLOG列或者长字符串，那么在从服务器上回复时可能会出现“log event entryexceeded max_allowed_pack”错误，这是因为含有大文本的记录无法通过网络进行传输，解决方法是在主从服务器上添加max_allowed_packet参数（默认设置是1MB）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span><span class="string">&#x27;MAX_ALLOWED_PACKET&#x27;</span>;</span><br><span class="line"><span class="keyword">set</span> @<span class="variable">@global</span>.max_allowed_packet<span class="operator">=</span><span class="number">16777216</span>;  # <span class="number">16</span>M</span><br></pre></td></tr></table></figure>

<p>同时，在my.cnf里设置max_allowed_packet&#x3D;16MB，数据库重新启动之后该参数将有效。</p>
<p><strong>问题三</strong>：多主复制时的自增长变量冲突问题。</p>
<p>大多数情况下使用一台主服务器对一台或者多台从服务器，但是在某些情况下可能会将多个服务器配置为复制主服务器，所以使用auto_increment时应采取特殊步骤以防止键值冲突，否则插入行时多个主服务器会试图使用相同的auto_increment值。</p>
<p>服务器变量auto_increment_increment和auto_increment_offset可以协调多主服务器复制和auto_increment列。</p>
<p>在多主服务器复制到从服务器过程中，迟早会发生主键冲突，为了解决这种情况，可以重新设置不同主服务器的这两个参数，比如在A数据库服务器上设置auto_increment_increment&#x3D;1、auto_increment_offset&#x3D;1，在B数据库服务器上设置auto_increment_increment&#x3D;1、auto_increment_offset&#x3D;0。</p>
<p><strong>问题四</strong>：利用pos偏移量解决小问题</p>
<p>不建议使用这种方法，可能会造成数据丢失，而且bin-log数据文件可能因为过大或者重启服务已变更为新的文件。</p>
<h4 id="切换主从服务器"><a href="#切换主从服务器" class="headerlink" title="切换主从服务器"></a><strong>切换主从服务器</strong></h4><p>在实际工作环境中，有时候遇到这样的问题：在一个工作环境中，有一个主数据库服务器A，两个从数据库服务器B、C同时指向主数据库服务器，当主数据库服务器A发生故障时，需要将其中的一个从数据库B服务器切换成主数据库，同时修改数据库C服务器的配置，使其指向新的主数据库B。</p>
<ol>
<li><p>首先要确保所有的从数据库都已经执行了relay log中的全部更新，查看从数据库的状态是否是Has read all relay log（是否更新都已经执行完成）。</p>
</li>
<li><p>在从数据库B上停止slave服务，然后执行reset master，重置成主数据库。（前提是确保&#x2F;etc&#x2F;my.cnf中设置了bin-log地址，并且重启服务器）</p>
</li>
<li><p>在从数据库B上添加具有replication权限的用户rep1，查询主数据库状态。在从数据库C上配置复制的参数。在从数据库C上执行show slave status命令，查看从数据库服务是否成功启动。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 查看relay log是否全部更新，查看Slave_SQL_Running_Statu字段是否为Slave has read <span class="keyword">all</span> relay log</span><br><span class="line"><span class="keyword">show</span> slave status;</span><br><span class="line"># B服务器停止slave，配置bin<span class="operator">-</span>log地址，重置成主数据库</span><br><span class="line">stop slave;</span><br><span class="line">reset master;</span><br><span class="line"><span class="keyword">show</span> master status;</span><br><span class="line"># 需要重新配置数据库C，方法就没什么差别了，停止服务，配置slave参数，启动服务</span><br><span class="line">change master <span class="keyword">to</span> master_host<span class="operator">=</span><span class="string">&#x27;8.131.90.208&#x27;</span>,master_user<span class="operator">=</span><span class="string">&#x27;root&#x27;</span>,master_password<span class="operator">=</span><span class="string">&#x27;Wang1024...&#x27;</span>,master_log_file<span class="operator">=</span><span class="string">&#x27;mysql-bin.000002&#x27;</span>,master_log_pos<span class="operator">=</span><span class="number">775</span>;</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="多源复制"><a href="#多源复制" class="headerlink" title="多源复制"></a>多源复制</h4><p>MySQL 8.0添加了多源复制功能，可以实现多主服务器和一从服务器的复制。</p>
<ol>
<li>如果在主服务器进行了分库分表的操作，可以在从服务器进行数据汇总。为了实现后期的一些数据统计功能，往往需要把数据汇总在一起再统计。</li>
<li>在从服务器时对主服务器的数据进行备份，在MySQL 8.0之前每一个主服务器都需要一个从服务器，很容易造成资源浪费，同时也加大了数据库管理员的维护成本；MySQL 8.0则引入了多源复制，可以把多个主服务器的数据同步到一个从服务器进行备份。</li>
</ol>
<h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><h3 id="Redis安装"><a href="#Redis安装" class="headerlink" title="Redis安装"></a>Redis安装</h3><ol>
<li><p>下载解压</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.redis.io/releases/redis-6.0.9.tar.gz  # 下载</span><br><span class="line">tar -zxvf redis-6.0.9.tar.gz  # 解压</span><br><span class="line">make PREFIX=/usr/local/redis install  # 安装到/usr/local/redis</span><br><span class="line">cd /usr/local/redis/bin</span><br></pre></td></tr></table></figure>

<p>目录结构对应关系</p>
<table>
<thead>
<tr>
<th align="center">文件</th>
<th align="center">功能</th>
</tr>
</thead>
<tbody><tr>
<td align="center">redis-check-aof</td>
<td align="center">AOF文件修复工具</td>
</tr>
<tr>
<td align="center">redis-check-rdb</td>
<td align="center">redis-check-rdb</td>
</tr>
<tr>
<td align="center">redis-cli</td>
<td align="center">redis命令行客户端</td>
</tr>
<tr>
<td align="center">redis.conf</td>
<td align="center">redis配置文件</td>
</tr>
<tr>
<td align="center">redis-sentinal</td>
<td align="center">redis集群管理工具</td>
</tr>
<tr>
<td align="center">redis-server</td>
<td align="center">redis服务进程</td>
</tr>
<tr>
<td align="center">redis-benchmark</td>
<td align="center">redis性能测试工具</td>
</tr>
</tbody></table>
</li>
<li><p>基本配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/local/redis/bin/redis.conf</span><br><span class="line"><span class="meta"># </span><span class="language-bash">找到daemonize=no并改为<span class="built_in">yes</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>启动Redis</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">启动Redis</span></span><br><span class="line">cd /usr/local/redis/bin</span><br><span class="line">./redis-server ./redis.conf</span><br><span class="line"><span class="meta"># </span><span class="language-bash">连接Redis</span></span><br><span class="line">./redis-cli</span><br><span class="line"><span class="meta"># </span><span class="language-bash">关闭Redis</span></span><br><span class="line">./redis-cli shutdown</span><br><span class="line"><span class="meta"># </span><span class="language-bash">强行终止Redis</span></span><br><span class="line">pkill redis-server</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">设置开机自启动</span></span><br><span class="line">vim /etc/rc.local</span><br><span class="line"><span class="meta"># </span><span class="language-bash">添加</span></span><br><span class="line">/usr/local/redis/bin/redis-server /usr/local/redis/bin/redis-conf</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="Redis配置"><a href="#Redis配置" class="headerlink" title="Redis配置"></a>Redis配置</h3><ol>
<li><p>基础参数配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">是否在后台执行，<span class="built_in">yes</span>：后台运行；no：不是后台运行（老版本默认）</span></span><br><span class="line">daemonize yes</span><br><span class="line"><span class="meta"># </span><span class="language-bash">是否开启保护模式（默认开启）</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">要是配置里没有指定<span class="built_in">bind</span>和密码。开启该参数后，redis只会本地进行访问，拒绝外部访问。要是开启了密码  和<span class="built_in">bind</span>，可以开启。否  则最好关闭，设置为no。</span></span><br><span class="line">protected-mode yes</span><br><span class="line"><span class="meta"># </span><span class="language-bash">redis的进程文件</span></span><br><span class="line">pidfile /var/run/redis/redis-server.pid</span><br><span class="line"><span class="meta"># </span><span class="language-bash">redis监听的端口号</span></span><br><span class="line">port 6379</span><br><span class="line"><span class="meta"># </span><span class="language-bash">此参数确定了TCP连接中已完成队列的长度(默认511)</span></span><br><span class="line">tcp-backlog 511</span><br><span class="line"><span class="meta"># </span><span class="language-bash">指定redis只接收指定IP地址的请求</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">如需处理所有请求（远程访问） <span class="built_in">bind</span> 0.0.0.0</span></span><br><span class="line">bind 127.0.0.1</span><br><span class="line"><span class="meta"># </span><span class="language-bash">配置unix socket来让redis支持监听本地连接。</span></span><br><span class="line">unixsocket /var/run/redis/redis.sock</span><br><span class="line"><span class="meta"># </span><span class="language-bash">配置unix socket使用文件的权限</span></span><br><span class="line">unixsocketperm 700</span><br><span class="line"><span class="meta"># </span><span class="language-bash">此参数为设置客户端空闲超过<span class="built_in">timeout</span>，服务端会断开连接，为0则服务端不会主动断开连接，不能小于0。</span></span><br><span class="line">timeout 0</span><br><span class="line"><span class="meta"># </span><span class="language-bash">tcp keepalive参数。如果设置不为0，就使用配置tcp的SO_KEEPALIVE值，使用keepalive有两个好处:检测挂掉的对端。降低中间设备出问题而导致网络看似连接却已经与对端端口的问题。在Linux内核中，设置了keepalive，redis会定时给对端发送ack。检测到对端关闭需要两倍的设置值。</span></span><br><span class="line">tcp-keepalive 0</span><br><span class="line"><span class="meta"># </span><span class="language-bash">指定了服务端日志的级别</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">debug（适合开发、测试环境）</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">verbose（较少于debug级别 适合开发、测试环境）</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">notice（适合生产环境）</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">warn（只有非常重要的信息）</span></span><br><span class="line">loglevel notice</span><br><span class="line"><span class="meta"># </span><span class="language-bash">指定了记录日志的文件。空字符串的话，日志会打印到标准输出设备。后台运行的redis标准输出是/dev/null。</span></span><br><span class="line">logfile /var/log/redis/redis-server.log</span><br><span class="line"><span class="meta"># </span><span class="language-bash">是否打开记录syslog功能</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">syslog-enabled no</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">syslog的标识符</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">syslog-ident redis</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">日志的来源、设备</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">syslog-facility local0</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">数据库的数量（默认16）</span></span><br><span class="line">databases 16</span><br></pre></td></tr></table></figure>
</li>
<li><p>持久化配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">注释掉<span class="string">&quot;save&quot;</span>这一行配置项就可以让保存数据库功能失效</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">设置redis进行数据库镜像的频率。</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">900秒（15分钟）内至少1个key值改变（则进行数据库保存--持久化）</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">300秒（5分钟）内至少10个key值改变（则进行数据库保存--持久化）</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">60秒（1分钟）内至少10000个key值改变（则进行数据库保存--持久化）</span></span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br><span class="line"><span class="meta"># </span><span class="language-bash">当rdb持久化出现错误后，是否依然进行继续进行工作，</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash"><span class="built_in">yes</span>：不能进行工作，</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">no：可以继续进行工作，</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">可以通过info中的rdb_last_bgsave_status了解RDB持久化是否有错误</span></span><br><span class="line">stop-writes-on-bgsave-error yes</span><br><span class="line"><span class="meta"># </span><span class="language-bash">使用压缩rdb文件</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash"><span class="built_in">yes</span>：压缩，但是需要一些cpu的消耗</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">no：不压缩，需要更多的磁盘空间</span></span><br><span class="line">rdbcompression yes</span><br><span class="line"><span class="meta"># </span><span class="language-bash">是否校验rdb文件</span></span><br><span class="line">rdbchecksum yes</span><br><span class="line"><span class="meta"># </span><span class="language-bash">rdb文件的名称</span></span><br><span class="line">dbfilename dump.rdb</span><br><span class="line"><span class="meta"># </span><span class="language-bash">数据目录，数据库的写入会在这个目录。rdb、aof文件也会写在这个目录</span></span><br><span class="line">dir /var/lib/redis</span><br><span class="line"><span class="meta"># </span><span class="language-bash">默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。</span></span><br><span class="line">appendonly no</span><br><span class="line"><span class="meta"># </span><span class="language-bash">aof文件名</span></span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br><span class="line"><span class="meta"># </span><span class="language-bash">aof持久化策略的配置</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">always表示每次写入都执行fsync，以保证数据同步到磁盘。</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。</span></span><br><span class="line">appendfsync everysec</span><br><span class="line"><span class="meta"># </span><span class="language-bash">在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。如果对延迟要求很高的应用，这个字段可以设置为<span class="built_in">yes</span>，否则还是设置为no，这样对持久化特性来说这是更安全的选择。设置为<span class="built_in">yes</span>表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议<span class="built_in">yes</span>。Linux的默认fsync策略是30秒。可能丢失30秒数据。</span></span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"><span class="meta"># </span><span class="language-bash">aof自动重写配置。当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。</span></span><br><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line"><span class="meta"># </span><span class="language-bash">设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写</span></span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br><span class="line"><span class="meta"># </span><span class="language-bash">aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项（redis宕机或者异常终止不会造成尾部不完整现象。）出现这种现象，可以选择让redis退出，或者导入尽可能多的数据。如果选择的是<span class="built_in">yes</span>，当截断的aof文件被导入的时候，会自动发布一个<span class="built_in">log</span>给客户端然后load。如果是no，用户必须手动redis-check-aof修复AOF文件才可以。</span></span><br><span class="line">aof-load-truncated yes</span><br></pre></td></tr></table></figure>
</li>
<li><p>主从配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">复制选项，slave复制对应的master</span></span><br><span class="line">slaveof &lt;masterip&gt; &lt;masterport&gt;</span><br><span class="line"><span class="meta"># </span><span class="language-bash">如果master设置了requirepass，那么slave要连上master，需要有master的密码才行。masterauth就是用来配置master的密码，这样可以在连上master后进行认证</span></span><br><span class="line">masterauth &lt;master-password&gt;</span><br><span class="line"><span class="meta"># </span><span class="language-bash">当slave同master失去连接或者复制正在进行，slave的运行方式</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">1.如果slave-serve-stale-data设置为<span class="built_in">yes</span>(默认设置)，slave会继续响应客户端的请求。</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">2.如果slave-serve-stale-data设置为no，除去INFO和SLAVOF命令之外的任何请求都会返回一个错误”SYNC with master <span class="keyword">in</span> progress”。</span></span><br><span class="line">slave-serve-stale-data yes</span><br><span class="line"><span class="meta"># </span><span class="language-bash">slave服务器读写配置</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">默认情况下是只读的（<span class="built_in">yes</span>）</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">修改成no，可读可写（不建议）</span></span><br><span class="line">slave-read-only yes</span><br><span class="line"><span class="meta"># </span><span class="language-bash">是否使用socket方式复制数据。目前redis复制提供两种方式，disk和socket。如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件。有2种方式：disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave。socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave。disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件。socket的方式就的一个个slave顺序复制。在磁盘速度缓慢，网速快的情况下推荐用socket方式。</span></span><br><span class="line">repl-diskless-sync no</span><br><span class="line"><span class="meta"># </span><span class="language-bash">diskless复制的延迟时间，防止设置为0。一旦复制开始，节点不会再接收新slave的复制请求直到下一个rdb传输。所以最好等待一段时间，等更多的slave连上来。</span></span><br><span class="line">repl-diskless-sync-delay 5</span><br><span class="line"><span class="meta"># </span><span class="language-bash">slave根据指定的时间间隔向服务器发送ping请求</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">时间间隔可以通过 repl_ping_slave_period 来设置，默认10秒。</span></span><br><span class="line">repl-ping-slave-period 10</span><br><span class="line"><span class="meta"># </span><span class="language-bash">复制连接超时时间。master和slave都有超时时间的设置。master检测到slave上次发送的时间超过repl-timeout，即认为slave离线，清除该slave信息。slave检测到上次和master交互的时间超过repl-timeout，则认为master离线。需要注意的是repl-timeout需要设置一个比repl-ping-slave-period更大的值，不然会经常检测到超时。</span></span><br><span class="line">repl-timeout 60</span><br><span class="line"><span class="meta"># </span><span class="language-bash">是否禁止复制tcp链接的tcp nodelay参数，可传递<span class="built_in">yes</span>或者no。默认是no，即使用tcp nodelay。如果master设置了<span class="built_in">yes</span>来禁止tcp nodelay设置，在把数据复制给slave的时候，会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。默认我们推荐更小的延迟，但是在数据量传输很大的场景下，建议选择<span class="built_in">yes</span>。</span></span><br><span class="line">repl-disable-tcp-nodelay no</span><br><span class="line"><span class="meta"># </span><span class="language-bash">复制缓冲区大小，这是一个环形复制缓冲区，用来保存最新复制的命令。这样在slave离线的时候，不需要完全复制master的数据，如果可以执行部分同步，只需要把缓冲区的部分数据复制给slave，就能恢复正常复制状态。缓冲区的大小越大，slave离线的时间可以更长，复制缓冲区只有在有slave连接的时候才分配内存。没有slave的一段时间，内存会被释放出来，默认1m。</span></span><br><span class="line">repl-backlog-size 5mb</span><br><span class="line"><span class="meta"># </span><span class="language-bash">master没有slave一段时间会释放复制缓冲区的内存，repl-backlog-ttl用来设置该时间长度。单位为秒。</span></span><br><span class="line">repl-backlog-ttl 3600</span><br><span class="line"><span class="meta"># </span><span class="language-bash">当master不可用，Sentinel会根据slave的优先级选举一个master。最低的优先级的slave，当选master。而配置成0，永远不会被选举。</span></span><br><span class="line">slave-priority 100</span><br><span class="line"><span class="meta"># </span><span class="language-bash">redis提供了可以让master停止写入的方式，如果配置了min-slaves-to-write，健康的slave的个数小于N，mater就禁止写入。master最少得有多少个健康的slave存活才能执行写命令。这个配置虽然不能保证N个slave都一定能接收到master的写操作，但是能避免没有足够健康的slave的时候，master不能写入来避免数据丢失。设置为0是关闭该功能。</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">min-slaves-to-write 3</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">延迟小于min-slaves-max-lag秒的slave才认为是健康的slave。</span></span><br><span class="line">min-slaves-max-lag 10</span><br><span class="line"><span class="meta"># </span><span class="language-bash">设置1或另一个设置为0禁用这个特性。</span></span><br><span class="line">min-slaves-max-lag is set to 10</span><br></pre></td></tr></table></figure>
</li>
<li><p>安全配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">配置redis连接密码（默认未启用，建议启用）</span></span><br><span class="line">requirepass foobared</span><br><span class="line"><span class="meta"># </span><span class="language-bash">把危险的命令给修改成其他名称。比如CONFIG命令可以重命名为一个很难被猜到的命令，这样外部连接不能使用，而服务器内部连接工具还能继续使用。</span></span><br><span class="line">rename-command CONFIG cmd</span><br><span class="line"><span class="meta"># </span><span class="language-bash">设置成一个空的值，可以禁止一个命令</span></span><br><span class="line">rename-command CONFIG &quot;&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>连接配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">设置能连上redis的最大客户端连接数量。默认是10000个客户端连接。由于redis不区分连接是客户端连接还是内部打开文件或者和slave连接等，所以maxclients最小建议设置到32。如果超过了maxclients，redis会给新的连接发送’max number of clients reached’，并关闭连接。</span></span><br><span class="line">maxclients 10000</span><br><span class="line"><span class="meta"># </span><span class="language-bash">redis配置的最大内存容量。当内存满了，需要配合maxmemory-policy策略进行处理。注意slave的输出缓冲区是不计算在maxmemory内的。所以为了防止主机内存使用完，建议设置的maxmemory需要更小一些。</span></span><br><span class="line">maxmemory &lt;bytes&gt;</span><br><span class="line"><span class="meta"># </span><span class="language-bash">内存容量超过maxmemory后的处理策略。</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">volatile-lru：利用LRU算法移除设置过过期时间的key。</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">volatile-random：随机移除设置过过期时间的key。</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">volatile-ttl：移除即将过期的key，根据最近过期时间来删除（辅以TTL）</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">allkeys-lru：利用LRU算法移除任何key。</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">allkeys-random：随机移除任何key。</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">noeviction：不移除任何key，只是返回一个写错误。</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">上面的这些驱逐策略，如果redis没有合适的key驱逐，对于写命令，还是会返回错误。redis将不再接收写请求，只接收get请求。</span></span><br><span class="line">maxmemory-policy noeviction</span><br><span class="line"><span class="meta"># </span><span class="language-bash">lru检测的样本数。使用lru或者ttl淘汰算法，从需要淘汰的列表中随机选择sample个key，选出闲置时间最长的key移除。</span></span><br><span class="line">maxmemory-samples 5</span><br><span class="line"><span class="meta"># </span><span class="language-bash">如果达到最大时间限制（毫秒），redis会记个<span class="built_in">log</span>，然后返回error。当一个脚本超过了最大时限。只有SCRIPT KILL和SHUTDOWN NOSAVE可以用。第一个可以杀没有调write命令的东西。要是已经调用了write，只能用第二个命令杀。</span></span><br><span class="line">lua-time-limit 5000</span><br></pre></td></tr></table></figure>
</li>
<li><p>集群配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">集群开关，默认是不开启集群模式。</span></span><br><span class="line">cluster-enabled yes</span><br><span class="line"><span class="meta"># </span><span class="language-bash">集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件，请确保与实例运行的系统中配置文件名称不冲突</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">cluster-config-file nodes-a.conf</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">节点互连超时的阀值。集群节点超时毫秒数</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">cluster-node-timeout 15000</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了，导致数据过于陈旧，这样的slave不应该被提升为master。该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">比较slave断开连接的时间和(node-timeout * slave-validity-factor) +repl-ping-slave-period</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">如果节点超时时间为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移</span></span><br><span class="line">cluster-slave-validity-factor 10</span><br><span class="line"><span class="meta"># </span><span class="language-bash">master的slave数量大于该值，slave才能迁移到其他孤立master上，如这个参数若被设为2，那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。</span></span><br><span class="line">cluster-migration-barrier 1</span><br><span class="line"><span class="meta"># </span><span class="language-bash">默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。设置为no，可以在slot没有全部分配的时候提供服务。不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致。</span></span><br><span class="line">cluster-require-full-coverage yes</span><br></pre></td></tr></table></figure>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8d64c6e849d9">其他配置</a></p>
</li>
</ol>
<h3 id="Redis基础语法"><a href="#Redis基础语法" class="headerlink" title="Redis基础语法"></a>Redis基础语法</h3><h4 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./redis-server ./redis.conf  # 从redis.conf读取配置并启动redis服务</span><br><span class="line">./redis-cli -h 127.0.0.1 -p 6379  # 从默认端口启动redis服务</span><br><span class="line">./redis-cli ping  # 返回PONG则说明客户端与redis服务的连接正常</span><br><span class="line">./redis-cli shutdown  # 关闭redis服务</span><br></pre></td></tr></table></figure>

<h4 id="string"><a href="#string" class="headerlink" title="string"></a>string</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">set foo 1  # 赋值</span><br><span class="line">get foo  # 字符串回复，当请求一个字符串类型键的键值或一个其他类型键中的某个元素</span><br><span class="line">keys *  # keys命令的作用是获取数据库中符合指定规则的键名，支持glob风格通配符格式（?,*,[],\x）</span><br><span class="line">exists key  # exists判断key键是否存在，返回1和0</span><br><span class="line">del key1 key2 ...  # del删除一个或多个键</span><br><span class="line">type key  # type获得key值的数据类型</span><br><span class="line">incr foo  # 增键值的INCR命令会以整数形式返回递增后的键值</span><br><span class="line">incrby foo 2  # 增加指定的整数</span><br><span class="line">incrbyfloat foo 0.1  # 增加指定的浮点数</span><br><span class="line">decr foo  # 自减1</span><br><span class="line">decrby foo 2  # 减少指定的整数</span><br><span class="line">append key &quot;value&quot;  # 在key键原有的值尾部追加“value”</span><br><span class="line">strlen key  # strlen返回字符串长度</span><br><span class="line">mget key1 key2...  # 同时获取多个键值</span><br><span class="line">mset key1 value1 key2 value2...  # 同时赋值多个键值对</span><br></pre></td></tr></table></figure>

<h4 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">hset key field1 value1  # 对键、字段、value赋值，若字段已存在则更新value</span><br><span class="line">hmset key field1 value1 field2 value2...  # 赋值多个字段和value</span><br><span class="line">hsetnx key field1 value1...  # 若字段不存在则新建赋值，已存在则不进行任何操作（nx：if not exists）</span><br><span class="line">hget key field1  # 返回键、字段对应的value</span><br><span class="line">hmget key field1 field2...  # 返回键对应的多个字段value</span><br><span class="line">hgetall key  # 返回键对应的所有字段和value，返回的结果是字段和字段值遍历组成的列表，不是很直观</span><br><span class="line">hkeys key  # 只获取键下的字段名</span><br><span class="line">hvals key  # 只获取键下所有的value</span><br><span class="line">hlen key  # 获取键长度，也就是字段数量</span><br><span class="line">hexists key field1  # 判断键对应的字段是否存在，返回1和0</span><br><span class="line">hincrbr key field1 2  # 对value进行自增指定数字，若不存在则会新建</span><br><span class="line">hdel key field1 field2...  # 删除键下的一个或多个字段</span><br></pre></td></tr></table></figure>

<h4 id="list"><a href="#list" class="headerlink" title="list"></a>list</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">lpush key value1 value2...  # 向列表左边添加一个或多个元素，会首先添加value1</span><br><span class="line">rpush key value1 value2...  # 向列表右边添加一个或多个元素</span><br><span class="line">lpop key  # 从列表左边弹出一个元素并从列表中删除这个元素</span><br><span class="line">rpop key  # 从列表右边弹出一个元素并从列表中删除这个元素</span><br><span class="line">brpop key... timeout  # brpop和rpop相似，区别是当列表中没有元素时brpop命令会一直阻塞住连接，直到有新元素加入，timeout指定超时时间，单位是秒。当超过了此时间仍然没有获得新元素的话就会返回nil，若为0则不限制等待时间</span><br><span class="line">llen key  # 列表中元素的个数</span><br><span class="line">lrange key start stop  # 获得列表从start到stop的所有的列表元素，返回的元素从上到下即从左到右</span><br><span class="line">lrange key 0 -1  # 获得列表中的所有元素</span><br><span class="line">lrem key count value  # 删除前count个值为value的元素（当count＞0时从列表左边开始删除前count个值为value的元素；当count＜0时从列表右边开始删除前|count|个值为value的元素；当count = 0时会删除所有值为value的元素）</span><br><span class="line">lindex key index  # 获得列表中指定index的value，index从左往右从0开始依次排列，或者从右至左从-1开始</span><br><span class="line">lset key index value  # 设置列表中指定index的值为value，若该index位置已存在值，则替换原有值</span><br><span class="line">linsert key before|after pivot value  # 在指定值前/后插入value。首先在列表中从左到右查找值为pivot的元素，然后根据第二个参数是BEFORE还是AFTER来决定将value插入到该元素的前面还是后面。</span><br><span class="line">rpoplpush key key1  # 将元素从一个列表转移到另外一个列表。先执行rpop命令再执行lpush命令。先从key列表类型键的右边弹出一个元素，然后将其加入到key1列表类型键的左边，并返回这个元素的值。</span><br></pre></td></tr></table></figure>

<h4 id="set"><a href="#set" class="headerlink" title="set"></a>set</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sadd key member1 member2...  # 向集合中添加一个或多个元素，返回实际修改元素数量，若已存在则忽略</span><br><span class="line">srem key member1 member2...  # 从集合中删除一个或多个元素，并返回删除成功的个数</span><br><span class="line">smembers key  # 获得集合中的所有元素</span><br><span class="line">sismember key member1  # 判断元素member1是否存在于集合key中，返回1和0</span><br><span class="line">sdiff A B  # 返回A与B的差集，A-B，支持多个集合</span><br><span class="line">sinter A B  # 返回A与B的交集，A∩B，支持多个集合</span><br><span class="line">sunion A B  # 返回A与B的并集，A∪B，支持多个集合</span><br><span class="line">scard key  # 返回集合长度，也就是元素数量</span><br><span class="line">sdiffstore new key1 key2...  # 计算两个或多个集合的差集并存储到new中</span><br><span class="line">sinterstore new key1 key2...  # 计算两个或多个集合的交集并存储到new中</span><br><span class="line">sunion new key1 key2...  # 计算两个或多个集合的并集并存储到new中</span><br><span class="line">spop key  # 从集合中随机弹出一个元素</span><br><span class="line">srandmember key [count]  # 随机获得集合中的元素。count参数来一次随机获得多个元素：当count为正数时，随机从集合里获得count个不重复的元素。如果count的值大于集合中的元素个数，则会返回集合中的全部元素；当count为负数时，会随机从集合里获得|count|个的元素，这些元素有可能相同。</span><br></pre></td></tr></table></figure>

<p>sorted set</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">zadd key score member [score member...]  # 新建/添加/修改有序索引，score为分数，member为元素</span><br><span class="line">zscore key member  # 获得一个member的score</span><br><span class="line">zrange key start stop [withscores]  # 从start stop指定下标从key取出元素，withscores指定是否输出score</span><br><span class="line">zrevrange key start stop [withscores]  # 与zrange不同之处是会按score从大到小排列输出元素</span><br><span class="line">zrangebyscore key min max [withscores] [limit offset count]  # 获得指定分数范围的元素，如果希望分数范围不包含端点值，可以在分数前加上“(”符号；min和max还支持无穷大，同ZADD命令一样，-inf和+inf分别表示负无穷和正无穷；在本命令中limit offset count 与SQL中的用法基本相同，即在获得的元素列表的基础上向后偏移offset个元素，并且只获取前count个元素。</span><br><span class="line">zincrby key increment member  # 增加某个元素的分数，若指定的元素不存在，会先建立它并将它的分数赋为0再操作。</span><br><span class="line">zcard key  # 获得集合中元素的数量</span><br><span class="line">zcount key min max  # 返回指定分数范围内的元素个数</span><br><span class="line">zremrangebyrank key min max  # 按照排名范围删除元素，按照元素分数从小到大的顺序（即索引0表示最小的值）删除处在指定排名范围内的所有元素，并返回删除的元素数量</span><br><span class="line">zrank key member  # 返回member元素的排名（从小到大排列）</span><br><span class="line">zrevrank key member  # 返回member元素的排名（从大到小排列）</span><br></pre></td></tr></table></figure>

<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">事务 multi开始，<span class="built_in">exec</span>结束</span></span><br><span class="line">multi</span><br><span class="line">sadd key1 1</span><br><span class="line">sadd key2 2</span><br><span class="line">exec</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">watch命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行。</span></span><br><span class="line">watch key</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">生存时间</span></span><br><span class="line">expire key 900  # 指定key在15分钟（900s）后删除，再次指定可重新设置生存时间，覆盖已有生存时间</span><br><span class="line">expireat key 1351858600  # 同样是生存时间，不过单位是以秒为单位的Unix时间戳</span><br><span class="line">paxpireat key 1351858600000  # 单位是以毫秒为单位的Unix时间戳</span><br><span class="line">ttl key  # 查看键在多少秒后删除</span><br><span class="line">persist key  # 取消键的生存时间设置（即将键恢复成永久的）</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">排序</span></span><br><span class="line">sort key [desc]  # 按照key值对key进行从小到大排列，若是有序集合则忽略score对value进行排序，desc从大到小</span><br><span class="line">sort key alpha [desc]  # 若value是字符串，则使用alpha指定按第一个字母排序，desc从大到小</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">按key排序</span></span><br><span class="line">lpush fdf 3 5 6  # 需要排序的列表</span><br><span class="line">set dd:3 10  # 新建三个dd:v 普通类型数据，v值对应列表中的value值</span><br><span class="line">set dd:6 7</span><br><span class="line">set dd:5 5</span><br><span class="line">sort fdf by dd:* desc  # 则sort fdf会按dd:v对应的值对列表中的value值进行排序，结果为3 6 5</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">SORT是Redis中最强大最复杂的命令之一，如果使用不好很容易成为性能瓶颈。</span></span><br></pre></td></tr></table></figure>

<h3 id="Redis基础知识"><a href="#Redis基础知识" class="headerlink" title="Redis基础知识"></a>Redis基础知识</h3><h4 id="多数据库"><a href="#多数据库" class="headerlink" title="多数据库"></a>多数据库</h4><p>Redis是一个字典结构的存储服务器，而实际上一个Redis实例提供了多个用来存储数据的字典，客户端可以指定将数据存储在哪个字典中。这与我们熟知的在一个关系数据库实例中可以创建多个数据库类似，所以可以将其中的每个字典都理解成一个独立的数据库。</p>
<p>每个数据库对外都是以一个从0开始的递增数字命名，Redis默认支持16个数据库，可以通过配置参数databases来修改这一数字。客户端与Redis建立连接后会自动选择0号数据库，不过可以随时使用SELECT命令更换数据库。</p>
<blockquote>
<p>然而这些以数字命名的数据库又与我们理解的数据库有所区别。首先Redis不支持自定义数据库的名字，每个数据库都以编号命名，开发者必须自己记录哪些数据库存储了哪些数据。另外Redis也不支持为每个数据库设置不同的访问密码，所以一个客户端要么可以访问全部数据库，要么连一个数据库也没有权限访问。最重要的一点是多个数据库之间并不是完全隔离的，比如FLUSHALL命令可以清空一个Redis实例中所有数据库中的数据。综上所述，这些数据库更像是一种命名空间，而不适宜存储不同应用程序的数据。比如可以使用0号数据库存储某个应用生产环境中的数据，使用1号数据库存储测试环境中的数据，但不适宜使用0号数据库存储A应用的数据而使用1号数据库存储B应用的数据，不同的应用应该使用不同的Redis实例存储数据。由于Redis非常轻量级，一个空Redis实例占用的内存只有1MB左右，所以不用担心多个Redis实例会额外占用很多内存。</p>
</blockquote>
<h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><ol>
<li><p>字符串类型<br>字符串类型是Redis中最基本的数据类型，它能存储任何形式的字符串，包括二进制数据。你可以用其存储用户的邮箱、JSON化的对象甚至是一张图片。一个字符串类型键允许存储的数据的最大容量是512 MB</p>
</li>
<li><p>哈希类型<br>哈希类型（hash）的键值也是一种字典结构，其存储了字段（field）和字段值的映射，但字段值只能是字符串，不支持其他数据类型，换句话说，哈希类型不能嵌套其他的数据类型。一个哈希类型键可以包含至多232-1个字段。</p>
<blockquote>
<p>除了哈希类型，Redis的其他数据类型同样不支持数据类型嵌套。比如集合类型的每个元素都只能是字符串，不能是另一个集合或哈希表等。</p>
</blockquote>
</li>
<li><p>列表类型<br>列表类型（list）可以存储一个有序的字符串列表，常用的操作是向列表两端添加元素，或者获得列表的某一个片段。</p>
<p>列表类型内部是使用双向链表（double linked list）实现的，所以向列表两端添加元素的时间复杂度为O(1)，获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元素的列表，获取头部或尾部的10条记录也是极快的。</p>
</li>
<li><p>集合类型<br>在集合中的每个元素都是不同的，且没有顺序。一个集合类型（set）键可以存储至多232 -1个字符串。</p>
<p>集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在等，由于集合类型在Redis内部是使用值为空的哈希表（hash table）实现的，所以这些操作的时间复杂度都是O(1)。最方便的是多个集合类型键之间还可以进行并集、交集和差集运算。</p>
</li>
<li><p>有序集合<br>在集合类型的基础上有序集合类型为集合中的每个元素都关联了一个分数，这使得我们不仅可以完成插入、删除和判断元素是否存在等集合类型支持的操作，还能够获得分数最高（或最低）的前N个元素、获得指定分数范围内的元素等与分数有关的操作。<br>虽然集合中每个元素都是不同的，但是它们的分数却可以相同。有序集合类型在某些方面和列表类型有些相似。（1）二者都是有序的。<br>（2）二者都可以获得某一范围的元素。<br>但是二者有着很大的区别，这使得它们的应用场景也是不同的。<br>（1）列表类型是通过链表实现的，获取靠近两端的数据速度极快，而当元素增多后，访问中间数据的速度会较慢，所以它更加适合实现如“新鲜事”或“日志”这样很少访问中间元素的应用。<br>（2）有序集合类型是使用散列表和跳跃表（Skip list）实现的，所以即使读取位于中间部分的数据速度也很快（时间复杂度是O(log(N))）。<br>（3）列表中不能简单地调整某个元素的位置，但是有序集合可以（通过更改这个元素的分数）。<br>（4）有序集合要比列表类型更耗费内存。</p>
</li>
</ol>
<h4 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h4><p>Redis也支持事务，由multi开始，exec结束，中间是要运行的代码。Redis保证一个事务中的所有命令要么都执行，要么都不执行。如果在发送EXEC命令前客户端断线了，则Redis会清空事务队列，事务中的所有命令都不会执行。</p>
<p>语法错误。语法错误指命令不存在或者命令参数的个数不对。而只要有一个命令有语法错误，执行EXEC命令后Redis就会直接返回错误，连语法正确的命令也不会执行。</p>
<p>运行错误。运行错误指在命令执行时出现的错误，比如使用散列类型的命令操作集合类型的键，这种错误在实际执行之前Redis是无法发现的，所以在事务里这样的命令是会被Redis接受并执行的。如果事务里的一条命令出现了运行错误，事务里其他的命令依然会继续执行（包括出错命令之后的命令）。</p>
<p>Redis的事务没有关系数据库事务提供的回滚（rollback）[插图]功能。为此开发者必须在事务执行出错后自己收拾剩下的摊子（将数据库复原回事务执行前的状态等）。</p>
<h4 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h4><p>Redis的强劲性能很大程度上是由于其将所有数据都存储在了内存中，为了使Redis在重启之后仍能保证数据不丢失，需要将数据从内存中以某种形式同步到硬盘中，这一过程就是持久化。Redis支持两种方式的持久化，一种是RDB方式，一种是AOF方式。可以单独使用其中一种或将二者结合使用。</p>
<ol>
<li><p>RDB方式的持久化是通过快照（snapshotting）完成的，当符合一定条件时Redis会自动将内存中的所有数据进行快照并存储在硬盘上。进行快照的条件可以由用户在配置文件中自定义，由两个参数构成：时间和改动的键的个数。当在指定的时间内被更改的键的个数大于指定的数值时就会进行快照。RDB是Redis默认采用的持久化方式。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">save参数指定了快照条件，可以存在多个条件，条件之间是“或”的关系。save 900 1的意思是在15分钟（900秒钟）内有至少一个键被更改则进行快照。</span></span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">sava 6010000</span><br></pre></td></tr></table></figure>

<p>Redis默认会将快照文件存储在当前目录的dump.rdb文件中，可以通过配置dir和dbfilename两个参数分别指定快照文件的存储路径和文件名。<br>理清Redis实现快照的过程对我们了解快照文件的特性有很大的帮助。快照的过程如下。<br>（1）Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）；<br>（2）父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件；<br>（3）当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此一次快照操作完成。</p>
<p>通过上述过程可以发现Redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。这使得我们可以通过定时备份RDB文件来实现Redis数据库备份。RDB文件是经过压缩（可以配置rdbcompression参数以禁用压缩节省CPU占用）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。</p>
<p>除了自动快照，还可以手动发送SAVE或BGSAVE命令让Redis执行快照，两个命令的区别在于，前者是由主进程进行快照操作，会阻塞住其他请求，后者会通过fork子进程进行快照操作。Redis启动后会读取RDB快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和服务器性能不同，这个时间也不同。通常将一个记录一千万个字符串类型键、大小为1GB的快照文件载入到内存中需要花费20～30秒钟。</p>
<p>通过RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据。这就需要开发者根据具体的应用场合，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受的范围。如果数据很重要以至于无法承受任何损失，则可以考虑使用AOF方式进行持久化。</p>
</li>
<li><p>AOF（append only file）方式的持久化</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启</span></span><br><span class="line">appendonly yes</span><br><span class="line"><span class="meta"># </span><span class="language-bash">开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。文件位置和RDB文件的位置相同，都是通过<span class="built_in">dir</span>参数设置的，默认的文件名是appendonly.aof，可通过appendfilename name修改</span></span><br><span class="line">appendfilename appendonly.aof</span><br></pre></td></tr></table></figure>

<p>可见AOF文件是纯文本文件，其内容正是Redis客户端向Redis发送的原始通信协议的内容（Redis的通信协议会在7.4节中介绍，为了便于阅读，这里将实际的命令部分以粗体显示），从中可见Redis确实只记录了前3条命令。然而这时有一个问题是前2条命令其实都是冗余的，因为这两条的执行结果会被第三条命令覆盖。随着执行的命令越来越多，AOF文件的大小也会越来越大，即使内存中实际的数据可能并没有多少。很自然地，我们希望Redis可以自动优化AOF文件，就上例而言，就是将前两条无用的记录删除，只保留第三条。实际上Redis也正是这样做的，每当达到一定条件时Redis就会自动重写AOF文件，这个条件可以在配置文件中设置。</p>
<p>Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。此时重新启动Redis后Redis会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少。</p>
</li>
</ol>
<h4 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h4><p>在Redis中使用复制功能非常容易，只需要在从数据库的配置文件中加入“slaveof主数据库IP主数据库端口”即可，主数据库无需进行任何配置。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server --slaveof 8.131.90.208 6379</span><br></pre></td></tr></table></figure>

<p>从数据库持久化</p>
<p>另一个相对耗时的操作是持久化，为了提高性能，可以通过复制功能建立一个（或若干个）从数据库，并在从数据库中启用持久化，同时在主数据库禁用持久化。当从数据库崩溃时重启后主数据库会自动将数据同步过来，所以无需担心数据丢失。而当主数据库崩溃时，需要在从数据库中使用SLAVEOF NO ONE命令将从数据库提升成主数据库继续服务，并在原来的主数据库启动后使用SLAVEOF命令将其设置成新的主数据库的从数据库，即可将数据同步回来。</p>
<h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><h3 id="编译Hadoop"><a href="#编译Hadoop" class="headerlink" title="编译Hadoop"></a>编译Hadoop</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">下载相关包（一定要用java1.8）</span></span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.2.1/hadoop-3.2.1-src.tar.gz  # Hadoop源码包</span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz  # Maven包</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">下载ProtocolBuffer2.5.0，MapReduce和HDFS用protocol buffer来压缩和交换数据</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">百度网盘：链接：https://pan.baidu.com/s/1ljoP-tLCPkVbtssEdiGTFQ 提取码：q5fe</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">安装依赖库</span></span><br><span class="line">yum -y updates</span><br><span class="line">yum -y install kernel-devel  </span><br><span class="line">yum -y install gcc* </span><br><span class="line">yum -y install cmake3  # 必须是最新的</span><br><span class="line">ln -s /usr/bin/cmake3 /usr/bin/cmake  # 最后将cmake3做一个软链cmake</span><br><span class="line">yum -y install glibc-headers  </span><br><span class="line">yum -y install gcc-c++  </span><br><span class="line">yum -y install zip-devel  </span><br><span class="line">yum -y install openssl-devel  </span><br><span class="line">yum -y install svn  </span><br><span class="line">yum -y install git  </span><br><span class="line">yum -y install ncurses-devel  </span><br><span class="line">yum -y install lzo-devel  </span><br><span class="line">yum -y install autoconf  </span><br><span class="line">yum -y install libtool  </span><br><span class="line">yum -y install automake  </span><br><span class="line">yum -y install patch</span><br><span class="line">yum -y install doxygen</span><br><span class="line">yum -y install protobuf</span><br><span class="line">yum install -y graphviz</span><br><span class="line">yum install -y protobuf-devel</span><br><span class="line">yum -y install build-essential libtool zlib1g-dev pkg-config libssl-dev libsasl2-dev</span><br><span class="line">yum install -y cyrus-sasl* </span><br><span class="line">yum install -y libgsasl-devel*</span><br></pre></td></tr></table></figure>

<p>编译前的准备</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">Maven配置</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">解压Maven包并把路径添加到环境变量中</span></span><br><span class="line">export PATH=&quot;/usr/local/servers/apache-maven-3.6.3/bin:$PATH&quot;</span><br><span class="line"><span class="meta"># </span><span class="language-bash">将Maven镜像更换为阿里云中央仓库</span></span><br><span class="line">vim /usr/local/servers/apache-maven-3.6.3/conf/settings.xml</span><br><span class="line"><span class="meta"># </span><span class="language-bash">在&lt;mirrors&gt;节点中添加</span></span><br><span class="line">&lt;mirror&gt;</span><br><span class="line">    &lt;id&gt;alimaven&lt;/id&gt;</span><br><span class="line">    &lt;name&gt;aliyun maven&lt;/name&gt;</span><br><span class="line">    &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;</span><br><span class="line">    &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;        </span><br><span class="line">&lt;/mirror&gt;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">安装ProtocolBuffer</span></span><br><span class="line">tar -zxf protobuf-2.5.0.tar.gz</span><br><span class="line">cd protobuf-2.5.0/bin</span><br><span class="line">./configure --prefix=/usr/local/servers/protobuf-2.5.0</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="meta"># </span><span class="language-bash">在/etc/profile中添加bin路径到path中</span></span><br><span class="line">export LD_LIBRARY_PATH=&quot;/usr/local/servers/protobuf-2.5.0/lib&quot;</span><br><span class="line">export PATH=&quot;/usr/local/servers/protobuf-2.5.0/bin:$PATH&quot;</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line">protoc --version  # 安装完成查看版本 </span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">设置Hadoop编译时下载为阿里云maven镜像</span></span><br><span class="line">cd hadoop-3.2.1-src</span><br><span class="line">vim pom.xml</span><br><span class="line"><span class="meta"># </span><span class="language-bash">在repositories下添加如下内容</span></span><br><span class="line">&lt;repositories&gt;  </span><br><span class="line">    &lt;repository&gt;  </span><br><span class="line">        &lt;id&gt;alimaven&lt;/id&gt;  </span><br><span class="line">        &lt;name&gt;aliyun maven&lt;/name&gt;  </span><br><span class="line">        &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;  </span><br><span class="line">        &lt;releases&gt;  </span><br><span class="line">            &lt;enabled&gt;true&lt;/enabled&gt;  </span><br><span class="line">        &lt;/releases&gt;  </span><br><span class="line">        &lt;snapshots&gt;  </span><br><span class="line">            &lt;enabled&gt;false&lt;/enabled&gt;  </span><br><span class="line">        &lt;/snapshots&gt;  </span><br><span class="line">    &lt;/repository&gt;  </span><br><span class="line">&lt;/repositories&gt; </span><br><span class="line"><span class="meta"># </span><span class="language-bash">注释掉不必要的代码</span></span><br><span class="line">vim /usr/local/softwares/hadoop-3.2.1-src/hadoop-client-modules/pom.xml</span><br><span class="line"></span><br><span class="line">&lt;module&gt;hadoop-client-minicluster&lt;/module&gt;</span><br><span class="line">&lt;!-- Checks invariants above --&gt;</span><br><span class="line">&lt;module&gt;hadoop-client-check-invariants&lt;/module&gt;</span><br><span class="line"><span class="meta"># </span><span class="language-bash">修改这里注释掉这一行</span></span><br><span class="line">&lt;!-- &lt;module&gt;hadoop-client-check-test-invariants&lt;/module&gt;--&gt;</span><br><span class="line">&lt;!-- Attempt to use the created libraries --&gt;</span><br><span class="line">&lt;module&gt;hadoop-client-integration-tests&lt;/module&gt;</span><br></pre></td></tr></table></figure>

<p>开始编译，有三种编译方式</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash"><span class="built_in">cd</span>到Hadoop源码包中</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">仅编译正常源码部分，对于native部分不进行编译，最终结果打包</span></span><br><span class="line">mvn package -Pdist -DskipTests -Dtar -Dmaven.javadoc.skip=true </span><br><span class="line"><span class="meta"># </span><span class="language-bash">编译正常部分源码、native依赖库以及帮助文档，最终结果打包</span></span><br><span class="line">mvn package -Pdist,native,docs -DskipTests -Dtar </span><br><span class="line"><span class="meta"># </span><span class="language-bash">一般使用下面这种方法</span></span><br><span class="line">mvn -X package -Pdist,native,docs -DskipTests -Dtar -Dmaven.skip.test=true -Dmaven.javadoc.skip=true </span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">查看编译好的包（hadoop-3.2.1和hadoop-3.2.1.tar.gz一样）</span></span><br><span class="line">ls /usr/local/softwares/hadoop-3.2.1-src/hadoop-dist/target/</span><br></pre></td></tr></table></figure>

<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><h4 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">将编译好的安装包解压到/usr/local/servers目录下，设置Hadoop_home</span></span><br><span class="line">vim /etc/profile</span><br><span class="line">export HADOOP_HOME=/usr/local/servers/hadoop-3.2.1</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin</span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">新建使用的文件夹</span></span><br><span class="line">cd /usr/local/servers/hadoop-3.2.1</span><br><span class="line">mkdir -p data/dfs/name</span><br><span class="line">mkdir -p data/dfs/name2</span><br><span class="line">mkdir -p data/dfs/data</span><br><span class="line">mkdir -p data/dfs/data2</span><br><span class="line">mkdir -p data/jobhistory/donedatas</span><br><span class="line">mkdir -p data/jobhistory/intermediate</span><br><span class="line">mkdir -p data/nn/edits</span><br><span class="line">mkdir -p data/nodemanager/data</span><br><span class="line">mkdir -p data/nodemanager/logs</span><br><span class="line">mkdir -p data/remote/logs</span><br><span class="line">mkdir -p data/snn/name</span><br><span class="line">mkdir -p data/snn/edits</span><br></pre></td></tr></table></figure>

<p>配置文件（一共修改七个）</p>
<p>​    core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定NameNode的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node01:9009<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/servers/hadoop-3.2.1/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--  缓冲区大小，实际工作中根据服务器性能动态调整--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>io.file.buffer.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>8192<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--  开启hdfs的垃圾桶机制，删除掉的数据可以从垃圾桶中回收，默认10080分钟--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10080<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node03:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--  指定namenode的访问端口和端口  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--  指定namenode存储元数据的地址  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///usr/local/servers/hadoop-3.2.1/data/dfs/name,file:///usr/local/servers/hadoop-3.2.1/data/dfs/name2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--  指定datanode存储数据的地址  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///usr/local/servers/hadoop-3.2.1/data/dfs/data,file:///usr/local/servers/hadoop-3.2.1/data/dfs/data2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--  指定存放日志文件的文件地址  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///usr/local/servers/hadoop-3.2.1/data/nn/edits<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--  检查点路径  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///usr/local/servers/hadoop-3.2.1/data/snn/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--  检查点日志路径  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///usr/local/servers/hadoop-3.2.1/data/snn/edits<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--  文件切片的副本个数  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--  设置hdfs的文件权限  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--  设置一个文件切片的大小：128M  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blocksize<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>Xmx512M<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>Xmx512M<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.task.io.sort.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>256<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.task.io.sort.factor<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>100<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.shuffle.parallelcopies<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>25<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.intermediate-done-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/servers/hadoop-3.2.1/data/jobhistory/intermediate<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.done-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/servers/hadoop-3.2.1/data/jobhistory/donedatas<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/usr/local/servers/hadoop-3.2.1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/usr/local/servers/hadoop-3.2.1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定MR走shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定ResourceManager的地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:8033<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 开启日志聚集功能 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://node01:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置日志保留时间为7天 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- yarn容器允许分配的最大最小内存 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- yarn容器允许管理的物理内存大小 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2.1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 关闭yarn对物理内存和虚拟内存的限制检查 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.detect-hardware-capabilities<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.local-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///usr/local/servers/hadoop-3.2.1/dfs/nodemanager/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.log-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///usr/local/servers/hadoop-3.2.1/dfs/nodemanager/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///usr/local/servers/hadoop-3.2.1/dfs/remote/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir-suffix<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>18144000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-check-interval-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>86400<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>yarn-env.sh</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在最后添加语句</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/local/servers/jdk8</span><br></pre></td></tr></table></figure>

<p>mapred-env.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">在最后添加语句</span></span><br><span class="line">export JAVA_HOME=/usr/local/servers/jdk8</span><br><span class="line">export HADOOP_JOB_HISTORYSERVER_HEAPSIZE=1000</span><br><span class="line">export HADOOP_MAPRED_ROOT_LOGGER=INFO,RFA</span><br></pre></td></tr></table></figure>

<p>hadoop-env.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">在最后添加语句</span></span><br><span class="line">export JAVA_HOME=/usr/local/servers/jdk8</span><br><span class="line">export HDFS_NAMENODE_OPTS=&quot;-XX:+UseParallelGC -Xmx4g&quot;</span><br><span class="line">export NAMENODE_HEAPSIZE=&quot;-Xmx204m&quot;</span><br></pre></td></tr></table></figure>

<h4 id="安装zookeeper"><a href="#安装zookeeper" class="headerlink" title="安装zookeeper"></a>安装zookeeper</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">下载安装包</span></span><br><span class="line">cd /usr/local/softwares</span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.6.2/apache-zookeeper-3.6.2-bin.tar.gz</span><br><span class="line">tar -zxvf apache-zookeeper-3.6.2-bin.tar.gz -C ../servers</span><br><span class="line">cd ../servers</span><br><span class="line">mv apache-zookeeper-3.6.2-bin zookeeper-3.6.2</span><br><span class="line">cd zookeeper-3.6.2</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">配置文件修改</span></span><br><span class="line">mkdir ./data</span><br><span class="line">cp ./conf/zoo_sample.cfg ./conf/zoo.cfg</span><br><span class="line">vim ./conf/zoo.cfg</span><br><span class="line"><span class="meta"># </span><span class="language-bash">在最后添加以下语句</span></span><br><span class="line">dataDir=/usr/local/servers/zookeeper-3.6.2/data</span><br><span class="line">server.1=node01:2888:3888</span><br><span class="line">server.2=node02:2888:3888</span><br><span class="line">server.3=node03:2888:3888</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">创建myid文件</span></span><br><span class="line">touch ./data/myid</span><br><span class="line">echo &quot;1&quot; &gt;&gt; ./data/myid  # 在scp到其他机器上后要修改myid为2、3、4...</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">将用户修改为elk，复制到其他主机并启动</span></span><br><span class="line">chown -R elk. /usr/local/servers/zookeeper-3.6.2</span><br><span class="line">scp -r zookeeper-3.6.2 node02:$PWD  # 记得修改myid</span><br><span class="line">scp -r zookeeper-3.6.2 node03:$PWD  # 记得修改myid</span><br><span class="line">su -elk  # 切换用户并启动</span><br><span class="line">cd /usr/local/servers/zookeeper-3.6.2/bin</span><br><span class="line">./zkServer.start  # 其他主机也是一样</span><br><span class="line">./zkServer.status  # 查看主机是leader或者follower</span><br><span class="line">./zkServer.stop  # 停止zookeeper</span><br></pre></td></tr></table></figure>

<h4 id="安装Hive"><a href="#安装Hive" class="headerlink" title="安装Hive"></a>安装Hive</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">下载解压</span></span><br><span class="line">cd /usr/local/softwares</span><br><span class="line">wget http://archive.apache.org/dist/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz</span><br><span class="line">tar -zxvf apache-hive-3.1.2-bin.tar.gz -C /usr/local/servers/</span><br><span class="line">cd /usr/local/servers</span><br><span class="line">mv apache-hive-3.1.2-bin hive-3.1.2</span><br><span class="line">cd hive-3.1.2/conf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">修改配置</span></span><br><span class="line">cp ./hive-env.sh.template hive-env.sh</span><br><span class="line">mkdir -p /data/hive/iotmp</span><br><span class="line">vim hive-env.sh  # 修改HADOOP_HOME和HIVE_CONF_DIR（hive的conf目录）</span><br><span class="line">vim hive-site.xml  # 新建配置文件，内容如下</span><br><span class="line">cd ../lib</span><br><span class="line">wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.23.tar.gz  # 下载连接mysql所需的jar包并放入lib文件夹里</span><br><span class="line">tar -zxvf mysql-connector-java-8.0.23.tar.gz </span><br><span class="line">cd mysql-connector-java-8.0.23/</span><br><span class="line">mv mysql-connector-java-8.0.23.jar ../</span><br><span class="line">cd ..</span><br><span class="line">rm -rf mysql-connector-java-8.0.23.tar.gz  mysql-connector-java-8.0.23</span><br><span class="line">chown -R elk. /usr/local/servers/hive-3.1.2</span><br><span class="line">chown -R elk. /data/hive</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">启动前的准备（检查Hadoop和hive的guava.jar版本是否一致，如不一致删除低版本的）</span></span><br><span class="line">vim /etc/profile  # 确保hive和hadoop home在环境变量中</span><br><span class="line"></span><br><span class="line">export  HADOOP_HOME=&quot;/usr/local/servers/hadoop-3.2.1&quot;</span><br><span class="line">export HIVE_HOME=&quot;/usr/local/servers/hive-3.1.2&quot;</span><br><span class="line">export PATH=&quot;$PATH:$HIVE_HOME/bin</span><br><span class="line">export PATH=&quot;$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin&quot;</span><br><span class="line"></span><br><span class="line">ls /usr/local/servers/hive-3.1.2/lib/</span><br><span class="line">ls /usr/local/servers/hadoop-3.2.1/share/hadoop/common/lib</span><br><span class="line">cp /usr/local/servers/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar /usr/local/servers/hive-3.1.2/lib/  # 将高版本的jar包复制过去</span><br><span class="line">rm -rf /usr/local/servers/hive-3.1.2/lib/guava-19.0.jar  # 删除低版本的jar包</span><br><span class="line">su - elk</span><br><span class="line">cd /usr/local/servers/hive-3.1.2</span><br><span class="line">./bin/schematool -dbType mysql -initSchema # schematool初始化当前Hive版本的Metastore架构</span><br><span class="line">./bin/hive  # 启动hive</span><br></pre></td></tr></table></figure>

<p>hive-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--连接MySQL的链接--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://node01:3306/hive?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--指定驱动类型--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.cj.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--指定MySQL用户名--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--连接MySQL密码--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--Hive表存放位置--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span>     #会在hdfs生成相应路径</span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/log<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.local.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/hive/iotmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Local scratch space for Hive jobs<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.downloaded.resources.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/hive/iotmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Temporary local directory for added resources in the remote file system.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/servers/zookeeper-3.6.2/bin</span><br><span class="line">./zkServer.sh start  # 启动zkserver，关闭则改为stop</span><br><span class="line">./zkClient.sh  # 进入client交互模式</span><br><span class="line">ls /  # 查看节点、文件（-s返回详细信息，-R返回递归目录）</span><br><span class="line"><span class="meta"># </span><span class="language-bash">新建节点并写入hello内容（-s顺序节点，-e临时节点；也可在已有节点下创建子节点，不可以在上层节点不存在的情况下创建子节点）</span></span><br><span class="line">create -s -e /tmp hello</span><br><span class="line">get /tmp  # 获取节点数据（-s获取详细内容，包括创建修改时间、子节点数量等）</span><br><span class="line">get -w /app1  # watch监控（内容修改时会发送消息）</span><br><span class="line">set /tmp world  # 修改节点内容</span><br><span class="line"><span class="meta"># </span><span class="language-bash">删除节点</span></span><br><span class="line">delete /tmp  # 若节点下有子节点则删除失败</span><br><span class="line">deleteall /app1  # 递归删除（删除节点及子节点）</span><br></pre></td></tr></table></figure>

<h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh  # 启动HDFS集群</span><br><span class="line">stop-dfs.sh  # 关闭HDFS集群</span><br><span class="line"></span><br><span class="line">hdfs dfs -ls /  # 查看路径下的文件或者文件夹</span><br><span class="line">hdfs dfs -mkdir -p /a/b/c  # 递归创建文件夹</span><br><span class="line">hdfs dfs -moveFronLocal localpath hdfspath  # 从本地上传文件到hdfs中（本地文件会被删除）</span><br><span class="line">hdfs dfs -mv oldpath newpath  # 移动文件</span><br><span class="line">hdfs dfs -put localpath hdfspath  # 从本地上传文件到hdfs中（文件还在本地）</span><br><span class="line">hdfs dfs -appendToFile a.txt b.txt /c.txt  # 追加本地文件a、b到hdfs文件c中</span><br><span class="line">hdfs dfs -cat /c.txt  # 打印文件到shell</span><br><span class="line">hdfs dfs -cp oldpath newpath  # 拷贝文件</span><br><span class="line">hdfs dfs -rm path  # 删除文件夹或者文件（如需递归加参数r）</span><br><span class="line"></span><br><span class="line">hdfs dfs -chmod -R 777 filepath  # 更改文件访问权限</span><br><span class="line">hdfs dfs -chown -R elk:elk filepath  # 更改文件用户组和用户</span><br></pre></td></tr></table></figure>

<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh # 启动Map Reduce</span><br><span class="line">stop-yarn.sh # 停止Map Reduce</span><br><span class="line">mr-jobhistory-daemon.sh start historyserver  # 启动Map Reduce历史记录</span><br><span class="line">mr-jobhistory-daemon.sh stop historyserver  # 停止Map Reduce历史记录</span><br></pre></td></tr></table></figure>

<h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><p>Hive基本操作如下。Hive真正的难点在自定义函数，详见&#x3D;&#x3D;<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/HIve/HivePlugins">官方文档</a>&#x3D;&#x3D;。</p>
<h3 id="初始化启动"><a href="#初始化启动" class="headerlink" title="初始化启动"></a>初始化启动</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">Hive启动一（会话关闭Hive关闭，<span class="built_in">log</span>打印到控制台）</span></span><br><span class="line">hive --service metastore &amp;  # 启动Hive元数据服务</span><br><span class="line">netstat -atunlp | grep 9083</span><br><span class="line">hive --service hiveserver2 &amp;  # 启动Hive的服务端，供外部连接使用</span><br><span class="line">netstat -atunlp | grep 10000</span><br><span class="line"><span class="meta"># </span><span class="language-bash">Hive启动二（会话关闭Hive关闭，<span class="built_in">log</span>重定向到文件）</span></span><br><span class="line">hive --service metastore &gt;&gt; /tmp/root/hivemetastore.log 2&gt;&amp;1 &amp;</span><br><span class="line">hive --service hiveserver2 &gt;&gt; /tmp/root/hiveserver2.log 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="meta"># </span><span class="language-bash">Hive启动三（Hive不受会话关闭影响，<span class="built_in">log</span>重定向到文件）</span></span><br><span class="line">nohup hive --service metastore &gt;&gt; /tmp/root/hivemetastore.log 2&gt;&amp;1 &amp;</span><br><span class="line">nohup hive --service hiveserver2 &gt;&gt; /tmp/root/hiveserver2.log 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">初始化MySQL元数据库</span></span><br><span class="line">schematool -initSchema -dbType mysql -verbose</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">Hive关闭</span></span><br><span class="line">jps  # 找到RunJar对应的端口号，一般有两个</span><br><span class="line">kill -9 端口号</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">Hive参数</span></span><br><span class="line">hive -e &quot;select * from mall.user;&quot;  # 执行sql语句</span><br><span class="line">hive -f ./xxx.sql  # 执行本地sql文件</span><br><span class="line">hive -f hdfs://tmp/xxx.sql  # 执行hdfs sql文件</span><br><span class="line">hive -hiveconf proprepty=value  # 给指定参数传入值，在当前会话有效</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">beeline连接Hive</span></span><br><span class="line">beeline</span><br><span class="line">!connect jdbc:hive2://localhost:10000</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">测试tez</span></span><br><span class="line"><span class="meta">$</span><span class="language-bash">HADOOP_HOME/bin/yarn jar <span class="variable">$TEZ_HOME</span>/tez-examples-0.10.1-SNAPSHOT.jar orderedwordcount /tez/word.txt /tez/output/</span></span><br></pre></td></tr></table></figure>

<h3 id="常用语法"><a href="#常用语法" class="headerlink" title="常用语法"></a>常用语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># HQL语法</span><br><span class="line"><span class="keyword">create</span> database dbname location <span class="string">&#x27;/hivedb&#x27;</span>;  # 指定新建数据库的存放位置，默认在xml中配置</span><br><span class="line"><span class="keyword">alter</span> database dbname <span class="keyword">set</span> dbpropreties(<span class="string">&#x27;createtime&#x27;</span><span class="operator">=</span><span class="string">&#x27;20210101&#x27;</span>);  # 修改数据库基本信息</span><br><span class="line"><span class="keyword">desc</span> database [extended] dbname;  # 查看数据库基本信息，extended参数查看详细内容</span><br><span class="line"><span class="keyword">desc</span> [formatted] tb;  # 查看表信息，formatted查看详细信息</span><br><span class="line"><span class="keyword">drop</span> database dbname [cascade];  # 删除数据库，cascade如果其中有表强制删除</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tb <span class="keyword">values</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>);  # 插入数据，会很慢，因为使用mapreduce</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> tb <span class="keyword">as</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> othertb;  # 复制表结构和表内容</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> tb <span class="keyword">like</span> othertb;  # 复制表结构</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> oldname rename <span class="keyword">to</span> newname;  # 更改表名</span><br><span class="line"><span class="keyword">show</span> functions;  # 查看内置函数</span><br><span class="line"><span class="keyword">desc</span> <span class="keyword">function</span> [extended] upper; # 查看函数的用法，extended返回详细内容</span><br><span class="line"></span><br><span class="line"># 创建表（内部表：会将数据移动到数据仓库指向的路径；外部表：仅记录数据所在的路径，不改变数据位置，删除表时，内部表的元数据和数据一起被删除，而外部表只会删除元数据，不会删除数据）</span><br><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] table_name  # <span class="keyword">EXTERNAL</span>表示创建外部表</span><br><span class="line">[(col_name data_type [COMMENT col_comment], ...)]  # 表字段</span><br><span class="line">[COMMENT table_comment]  # 为表与字段增加注释</span><br><span class="line">[PARTITIONED <span class="keyword">BY</span> (col_name data_type [COMMENT col_comment], ...)]  # 分区，一个表可以有多个分区，每个分区以文件夹的方式单独存储在表的目录下</span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...)  # 分桶，获得更高的查询效率</span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS]  # 排序</span><br><span class="line">[<span class="type">ROW</span> FORMAT row_format]  # 字段之间的分隔符</span><br><span class="line">[STORED <span class="keyword">AS</span> file_format]  # 存储类型，一般是textfile纯文本，需要压缩SEQUENCE</span><br><span class="line">[LOCATION hdfs_path]  # 指定存储位置</span><br></pre></td></tr></table></figure>

<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># 创建外部表示例</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> movies(id <span class="type">int</span>,content string,genre string) </span><br><span class="line">comment <span class="string">&#x27;This is movies.&#x27;</span> </span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> </span><br><span class="line">stored <span class="keyword">as</span> textfile;  # 创建外部表示例</span><br><span class="line"># 从本地加载数据到hive，数据上传到movies表目录下，overwrite覆盖原数据（数据不要有标题）</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/tmp/win/movies.csv&#x27;</span> [overwrite] <span class="keyword">into</span> <span class="keyword">table</span> movies;</span><br><span class="line"># 从hdfs文件系统加载数据到hive，会将文件移动到movies表目录下</span><br><span class="line">load data inpath <span class="string">&#x27;/user/elk/tmp/movies.csv&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> movies;</span><br><span class="line"></span><br><span class="line"># 创建分区表，实则就是在表下面用一个类型标识这部分数据并分开存储在不同的目录下，一般用时间标识</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> tb(id <span class="type">int</span>, name string) </span><br><span class="line">partitioned <span class="keyword">by</span> (<span class="keyword">year</span> string)  # 可支持多个分区</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;  # 创建分区表</span><br><span class="line"># 加载数据并标识数据为<span class="number">2020</span>，继续加载其他年份的数据改变<span class="keyword">year</span>值即可，会在表目录下生成不同的文件夹</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/tmp/win/tb.csv&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> movies <span class="keyword">partition</span>(<span class="keyword">year</span><span class="operator">=</span><span class="string">&#x27;2020&#x27;</span>);</span><br><span class="line"># 如果不加<span class="keyword">where</span>条件会查询出所有的内容，如需查询单个分区则需加上<span class="keyword">where</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tb <span class="keyword">where</span> <span class="keyword">year</span> <span class="operator">=</span><span class="operator">=</span> <span class="string">&#x27;2020&#x27;</span>;</span><br><span class="line"># 若需查询多个分区的内容，各查询之间用<span class="keyword">union</span>连接</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tb <span class="keyword">where</span> <span class="keyword">year</span> <span class="operator">=</span><span class="operator">=</span> <span class="string">&#x27;2020&#x27;</span> <span class="keyword">union</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tb <span class="keyword">where</span> <span class="keyword">year</span> <span class="operator">=</span><span class="operator">=</span> <span class="string">&#x27;2021&#x27;</span>;</span><br><span class="line"><span class="keyword">show</span> <span class="keyword">partition</span> tb;  # 查看所有分区</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> tb <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">year</span><span class="operator">=</span><span class="string">&#x27;2019&#x27;</span>)  # 增加分区</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> tb <span class="keyword">drop</span> <span class="keyword">partition</span>(<span class="keyword">year</span><span class="operator">=</span><span class="string">&#x27;2019&#x27;</span>)  # 删除分区</span><br><span class="line"></span><br><span class="line"># 创建分桶表（按照数据字段将数据划分到多个文件中去）</span><br><span class="line"><span class="keyword">set</span> hive.enforce.bucketing<span class="operator">=</span><span class="literal">true</span>;  # 开启分桶功能</span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">3</span>;  # 设置reduce个数</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> tb(id <span class="type">int</span>, name string, type string) </span><br><span class="line">clustered <span class="keyword">by</span> (type) <span class="keyword">into</span> <span class="number">3</span> buckets  # 可支持多个分区</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;  # 创建分桶表</span><br><span class="line"># 加载数据不用以前的方法，使用<span class="keyword">insert</span> overwrite</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> tb2(id <span class="type">int</span>, name string, type string) </span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;  # 创建普通表用来辅助</span><br><span class="line">load data inpath <span class="string">&#x27;/user/elk/tmp/movies.csv&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> tb2;  # 加载数据到辅助表</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> tb <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tb2 cluster <span class="keyword">by</span>(type);  # 通过cluster <span class="keyword">by</span>分桶加载</span><br></pre></td></tr></table></figure>

<h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">Linux安装起来比较麻烦</span></span><br><span class="line">yum install -y yum-utils</span><br><span class="line">yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">yum install -y docker-ce docker-ce-cli containerd.io</span><br><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure>

<h3 id="镜像命令"><a href="#镜像命令" class="headerlink" title="镜像命令"></a>镜像命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">查看镜像</span></span><br><span class="line">docker images</span><br><span class="line">docker images [-aq]  # 加参数aq只显示镜像id</span><br><span class="line"><span class="meta"># </span><span class="language-bash">搜索docker hub中的镜像</span></span><br><span class="line">docker search mysql</span><br><span class="line"><span class="meta"># </span><span class="language-bash">拉取镜像</span></span><br><span class="line">docker pull mysql</span><br><span class="line">docker pull mysql:5.7  # 拉取指定版本镜像</span><br><span class="line"><span class="meta"># </span><span class="language-bash">删除镜像</span></span><br><span class="line">docker rmi -f 镜像ID [镜像ID] [镜像ID]</span><br><span class="line">docker rmi -f $(docker images -aq)  # 删除所有镜像</span><br></pre></td></tr></table></figure>

<h3 id="容器命令"><a href="#容器命令" class="headerlink" title="容器命令"></a>容器命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">容器运行</span></span><br><span class="line">docker fun [可选参数] image</span><br><span class="line">--name=&quot;name&quot;  # 容器名字，用来区分容器</span><br><span class="line">-d  # 后台运行</span><br><span class="line">-it  # 使用交互式运行，进入容器查看内容</span><br><span class="line">-p  # 指定容器端口 -p 8080:8080</span><br><span class="line">    -p ip:主机端口：容器端口</span><br><span class="line">    -p 主机端口：容器端口（常用）</span><br><span class="line">    -p 容器端口</span><br><span class="line">    -p  # 不加参数随机指定端口</span><br><span class="line">docker run -it ubuntu /bin/bash  # 启动并进入容器</span><br><span class="line">docker run -d --name mysql01 -p:3344:3306 mysql  # 后台启动一个MySQL镜像命名为mysql01并将容器内的3306端口映射到主机3344端口上，访问主机3344就可以访问到mysql01</span><br><span class="line">docker run -it --rm tomcat  # 用完即删，用作测试，不建议使用</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">win10启动容器（必须在docker desktop setting/Resources/FILE SHARING中增加文件共享目录e：workspace/docker/volume）</span></span><br><span class="line">docker run -d -it --name test -v /e/workspace/docker/volume/test:/root centos </span><br><span class="line"></span><br><span class="line">exit  # 退出容器，容器也会停止（Ctrl + P + Q退出容器不停止容器）</span><br><span class="line">docker ps  # 查看正在运行的容器</span><br><span class="line">docker ps -a  # 查看以前运行过的所有容器</span><br><span class="line">docker rm 容器id  # 删除没有正在运行的容器</span><br><span class="line">docker rm -f 容器id  # 强制删除容器</span><br><span class="line">docker rm -f $(docker ps -aq)  # 删除所有容器</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">启动和停止容器</span></span><br><span class="line">docker start 容器id  # 启动容器</span><br><span class="line">docker restart 容器id  # 重启容器</span><br><span class="line">docker stop 容器id  # 停止容器</span><br><span class="line">docker kill 容器id  # 杀死容器</span><br><span class="line"><span class="meta"># </span><span class="language-bash">只要容器在数据就在，不会丢失，重新启动即可（使用docker ps -a查看已关闭的容器）</span></span><br></pre></td></tr></table></figure>

<h3 id="其他命令"><a href="#其他命令" class="headerlink" title="其他命令"></a>其他命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">查看日志、元数据</span></span><br><span class="line">docker -tfn 20 容器ID  # 查看容器日志，t表示显示时间戳，f跟踪日志输出，n指定输出日志数量</span><br><span class="line">docker top 容器ID  # 查看容器内进程</span><br><span class="line">docker inspect 容器ID  # 查看容器元数据</span><br><span class="line">docker stats [容器ID] # 查看所有/指定容器内存使用情况</span><br><span class="line">docker exec -it 容器ID /bin/bash  # 进入正在运行的容器（进入容器开启一个新的终端，常用）</span><br><span class="line">docker attach 容器ID  # 进入正在运行的容器（进入容器正在执行的终端）</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">拷贝容器内文件到当前主机</span></span><br><span class="line">docker cp 容器ID:/root/test /home/wxk</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">内存管理</span></span><br><span class="line">docker stats 容器ID  # 查看容器占用内存情况</span><br><span class="line">docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=&quot;-Xms64m -Xmx512m&quot; elasticsearch  # 通过-e修改配置文件，最大最小内存</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">Commit镜像，保存当前容器的所有状态，打包成一个镜像</span></span><br><span class="line">docker commit -a &quot;作者&quot; -m &quot;提交信息说明&quot; 容器ID 镜像名称:镜像版本</span><br><span class="line">docker commit -a &quot;wxk&quot; -m &quot;add test&quot; 38ff0892001a ubuntu01:1.0</span><br></pre></td></tr></table></figure>

<h3 id="容器数据卷"><a href="#容器数据卷" class="headerlink" title="容器数据卷"></a>容器数据卷</h3><p>容器之间的一个共享技术，Docker容器中产生的数据，可以同步到本地作持久化，将容器内的目录挂载到Linux中，跟容器是否启动无关，这样在容器删了之后不会面对数据也不存在的情况。而且容器之间也是可以数据共享的。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">新建数据卷</span></span><br><span class="line">docker run -d -v 本机目录:容器目录 [-v 本机目录:容器目录] 容器ID  # 指定路径挂载，将两个/多个目录连接起来</span><br><span class="line">docker run -d -v 容器目录 容器ID  # 匿名挂载，只有容器内的路径</span><br><span class="line">docker run -d -v 卷名:容器目录 容器ID  # 具名挂载，给数据卷起个名字（常用）</span><br><span class="line">docker run -d -v 卷名:容器目录:ro/rw 容器ID  # ro表示容器内只读，只能主机写；默认rw，主机和容器都可读可写</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">查看数据卷情况</span></span><br><span class="line">docker volume ls  # 查看所有数据卷</span><br><span class="line">docker colume inspect 卷名  # 查看指定卷名的情况，包括本地路径</span><br></pre></td></tr></table></figure>

<h3 id="Dockerfile、Docker网络"><a href="#Dockerfile、Docker网络" class="headerlink" title="Dockerfile、Docker网络"></a>Dockerfile、Docker网络</h3><p>Dockerfile就是用来构造docker镜像的构造文件，通过脚本可以生成自己的镜像，指路<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1og4y1q7M4?p=26">教程</a>。<br>Docker网络在容器之间的通信和集群的搭建需要考虑，同样指路上方教程。</p>
<h3 id="发布镜像"><a href="#发布镜像" class="headerlink" title="发布镜像"></a>发布镜像</h3><p>可以发布镜像到自己的<a target="_blank" rel="noopener" href="https://cr.console.aliyun.com/cn-beijing/instances/repositories">阿里云容器镜像服务</a>，相当于是一个仓库，创建自己的镜像，以供自己和他人随时随地进行拉取。新建仓库push自己的镜像，使用的时候直接使用公网地址pull即可。</p>
<h3 id="Docker网络"><a href="#Docker网络" class="headerlink" title="Docker网络"></a>Docker网络</h3><p>每启动一个Docker容器，就会给容器分配一个IP，使用的是evth-pair桥接模式，在宿主机使用ip-addr查看docker0以及桥接的网络。<br>evth-pair就是一对的虚拟接口设备，他们都是成对出现的，一端连着协议，一端连着彼此，正因为有这个特性，evth-pair充当一个桥梁，连接各种虚拟网络设备。</p>
<p>Tomcat01和Tomcat02共用同一个路由器docker0，所有容器不指定网络的情况下，都是由docker0路由的，docker会给容器分配一个默认的可用IP，当然每一次启动都会重新分配新的IP。<br>而Docker使用的是Linux的桥接，宿主机是一个Docker容器的网桥docker0。Docker中所有的网络接口都是虚拟的，转发效率高。<br>Docker0不支持容器名连接，只能使用link，但是会有局限性，所以一般会搭建自己的网络。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">查看容器网络配置信息</span></span><br><span class="line">docker network ls  # 查看所有容器网络</span><br><span class="line">docker network inspect 网络ID  # 查看容器网络配置的详细信息</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">创建自己的网络</span></span><br><span class="line">docker run -d -it --net bridge centos  # 默认创建容器时使用bridge桥接</span><br><span class="line">docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet  # 创建自己的网络，使用docker network create --help查看使用方法</span><br><span class="line">docker run -d -it --name ubuntu01 --net mynet ubuntu  # 使用自己的网络启动容器</span><br><span class="line">docker run -d -it --name ubuntu02 --net mynet ubuntu </span><br><span class="line">docker exec -it ubuntu01 ping ubuntu02  # 网络下启动的所有容器彼此可以通信，重要的是可以直接使用容器名（当然你得先在容器中安装iputils-ping）</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">连接一个容器到一个网络（一个容器两个地址，解决不同网络的容器互连问题）</span></span><br><span class="line">docker run -d -it --name ubuntu-docker0 ubuntu  # 使用默认网络bridge</span><br><span class="line">docker run -d -it --name ubuntu-mynet --net mynet ubuntu  # 使用自己的网络mynet</span><br><span class="line">docker network connect mynet ubuntu-docker0  # 连接一个容器到一个网络中，这样ubuntu-docker0和ubuntu-mynet就可以互相通信了</span><br></pre></td></tr></table></figure>

<h3 id="Docker-Compose"><a href="#Docker-Compose" class="headerlink" title="Docker-Compose"></a>Docker-Compose</h3><p><a target="_blank" rel="noopener" href="https://docs.docker.com/compose/">Docker Compose</a>是一个用来定义和运行复杂应用的Docker工具。使用Compose，你可以在一个文件中定义一个多容器应用，然后使用一条命令来启动并管理你的应用，完成一切准备工作。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">安装docker-compose</span></span><br><span class="line">yum install docker-compose </span><br><span class="line">docker-compose version</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">docker-compose基本命令</span></span><br><span class="line">build 构建或重建服务</span><br><span class="line">help 命令帮助</span><br><span class="line">kill 杀掉容器</span><br><span class="line">logs 显示容器的输出内容</span><br><span class="line">port 打印绑定的开放端口</span><br><span class="line">ps 显示容器</span><br><span class="line">pull 拉取服务镜像</span><br><span class="line">restart 重启服务</span><br><span class="line">rm 删除停止的容器</span><br><span class="line">run 运行一个一次性命令</span><br><span class="line">scale 设置服务的容器数目</span><br><span class="line">start 开启服务</span><br><span class="line">stop 停止服务</span><br><span class="line">up 创建并启动容器</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">使用docker-compose构建wordpress</span></span><br><span class="line">mkdir wordpress</span><br><span class="line">cd wordpress</span><br><span class="line">vim docker-compose.yml  # 内容如下</span><br><span class="line">docker-compose -f docker-compose.wordpress.yml up -d  # 后台运行</span><br><span class="line"><span class="meta"># </span><span class="language-bash">后台访问地址：IP:3344/wp-admin</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">基本操作（需要在docker-compose.yml目录下操作）</span></span><br><span class="line">docker-compose ps  # 查看容器运行情况</span><br><span class="line">docker-compose logs  # 返回容器log</span><br><span class="line">docker-compose stop  # 停止相关的容器</span><br><span class="line">docker-compose start  # 启动相关的容器</span><br></pre></td></tr></table></figure>

<p>docker-compose.yml</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3.3&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">db:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">mysql:5.7</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">db:/var/lib/mysql</span>  <span class="comment"># 数据卷，使用docker volume ls &amp; docker inspect 卷名查看挂载地址</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">MYSQL_ROOT_PASSWORD:</span> <span class="string">wordpress</span></span><br><span class="line">      <span class="attr">MYSQL_DATABASE:</span> <span class="string">wordpress</span></span><br><span class="line">      <span class="attr">MYSQL_USER:</span> <span class="string">wordpress</span></span><br><span class="line">      <span class="attr">MYSQL_PASSWORD:</span> <span class="string">wordpress</span></span><br><span class="line">  <span class="attr">wordpress:</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">db</span>  <span class="comment"># 依赖</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">wordpress:latest</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;3344:80&quot;</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">WORDPRESS_DB_HOST:</span> <span class="string">db:3306</span></span><br><span class="line">      <span class="attr">WORDPRESS_DB_USER:</span> <span class="string">wordpress</span></span><br><span class="line">      <span class="attr">WORDPRESS_DB_PASSWORD:</span> <span class="string">wordpress</span></span><br><span class="line">      <span class="attr">WORDPRESS_DB_NAME:</span> <span class="string">wordpress</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">wordpress:/var/www/html</span>  <span class="comment"># 数据卷</span></span><br><span class="line"><span class="attr">volumes:</span>  <span class="comment"># 使数据卷生效</span></span><br><span class="line">  <span class="attr">db:</span></span><br><span class="line">  <span class="attr">wordpress:</span></span><br></pre></td></tr></table></figure>

<h2 id="MongoDB"><a href="#MongoDB" class="headerlink" title="MongoDB"></a>MongoDB</h2><h4 id="命令行"><a href="#命令行" class="headerlink" title="命令行"></a>命令行</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">数据库集合相关</span></span><br><span class="line">show dbs;  # 显示所有数据库</span><br><span class="line">use mydb;  # 进入数据库</span><br><span class="line">db;  # 显示当前数据库名称</span><br><span class="line">db.dropDatabase();  # 删除当前进入的数据库，并且释放磁盘</span><br><span class="line">show collections;  # 查看所有集合，也可以用tables</span><br><span class="line">db.fruit.drop();  # 删除一个集合</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">插入数据</span></span><br><span class="line">db.fruit.insetOne(&#123;name : &quot;apple&quot;&#125;);  # 插入一条数据</span><br><span class="line">db.fruit.insetMany([  # 插入多条数据</span><br><span class="line">    &#123;name : &quot;pair&quot;&#125;,</span><br><span class="line">    &#123;name : &quot;orange&quot;&#125;</span><br><span class="line">]);</span><br><span class="line">db.fruit.insertOne(  # 插入多层次的数据</span><br><span class="line">    &#123;name:&quot;app&quot;,</span><br><span class="line">    from:&#123;</span><br><span class="line">        country:&quot;china&quot;,</span><br><span class="line">        province:&quot;beijing&quot;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br><span class="line">db.fruit.insert([  # 使用insert也可以插入多条，插入一个数组</span><br><span class="line">    &#123;name:&quot;ppp&quot;,color:[&quot;black&quot;,&quot;yeelow&quot;]&#125;,</span><br><span class="line">    &#123;name:&quot;www&quot;,color:[&quot;white&quot;,&quot;blue&quot;]&#125;]</span><br><span class="line">)</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">查找数据</span></span><br><span class="line">db.moives.find();  # find查询语句</span><br><span class="line">db.users.findOne();  # 只返回一条记录</span><br><span class="line">db.fruit.find().pretty();  # 结构化显示查询结果</span><br><span class="line">db.moives.find(&#123;&quot;year&quot; : 1975, &quot;title&quot; : &quot;agg&quot;&#125;);  # 多条件and查询</span><br><span class="line">db.moives.find(&#123;$and : [&#123;&quot;year&quot;:1975&#125;, &#123;&quot;title&quot;:&quot;agg&quot;&#125;]&#125;);  # 多条件and</span><br><span class="line">db.moives.find(&#123;$or : [&#123;&quot;year&quot;:1975&#125;, &#123;&quot;title&quot;:&quot;agg&quot;&#125;]&#125;);  # 多条件or</span><br><span class="line">db.fruit.find(&#123;&quot;from.country&quot;:&quot;china&quot;&#125;);  # 查找多层次结构数据</span><br><span class="line">db.fruit.find(&#123;&#125;,&#123;&quot;_id&quot;:0,&quot;name&quot;:1&#125;);  # 第一个大括号内是条件，第二个指定不返回_id字段，只返回name字段</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">删除数据</span></span><br><span class="line">db.fruit.remove(&#123;&#125;);  # 删除集合内所有内容，相当于sql中的delete</span><br><span class="line">db.fruit.remove(&#123;a: &#123;$lt: 5&#125;&#125;)  # 删除a小于5的记录</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">更新数据</span></span><br><span class="line">db.fruit.updateOne(&#123;name:&quot;app&quot;&#125;,&#123;$set:&#123;from.province:&quot;xian&quot;&#125;&#125;);  # 更新一条记录，第一个大括号是条件，第二个是更新的内容，若更新字段不存在则自动新建，不管匹配多少条，默认更新第一条</span><br><span class="line">db.fruit.updateMany(&#123;name:&quot;app&quot;&#125;,&#123;$set:&#123;from.province:&quot;xian&quot;&#125;&#125;); # 更新匹配到的多条记录，必须有以下字段：</span><br><span class="line"><span class="meta"># </span><span class="language-bash"><span class="variable">$set</span>/<span class="variable">$unset</span></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">/<span class="variable">$push</span>（增加一个对象到数组底部）/<span class="variable">$pushAll</span>（增加多个对象到数组底部）/<span class="variable">$pop</span>（从数组底部删除一个对象）</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">/<span class="variable">$pull</span>（如果匹配指定的值则从数组中删除）/<span class="variable">$pullAll</span>（如果匹配任意的值则从数组中删除相应的对象）</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">/<span class="variable">$addToSet</span>（如果不存在则增加一个值到数组）</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">聚合查询</span></span><br><span class="line">db.users.aggregate([#select username &quot;姓名&quot;,age &quot;年龄&quot; from users where phone=&quot;19991259321&quot; limit 1 1;</span><br><span class="line">    &#123;&quot;$match&quot;:&#123;&quot;phone&quot;:&quot;19991259321&quot;&#125;&#125;,</span><br><span class="line">    &#123;&quot;$skip&quot;:1&#125;,</span><br><span class="line">    &#123;&quot;$limit&quot;:1&#125;,</span><br><span class="line">    &#123;&quot;$project&quot;:&#123;&quot;姓名&quot;:&quot;$username&quot;,&quot;年龄&quot;:&quot;$age&quot;&#125;&#125;</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">user_coll.insert(  # 插入一条数组记录</span><br><span class="line">    &#123;&quot;username&quot;:&quot;wang&quot;,&quot;score&quot;:[</span><br><span class="line">        &#123;&quot;subject&quot;:&quot;语文&quot;,&quot;score&quot;:80&#125;,</span><br><span class="line">        &#123;&quot;subject&quot;:&quot;数学&quot;,&quot;score&quot;:90&#125;,</span><br><span class="line">        &#123;&quot;subject&quot;:&quot;英语&quot;,&quot;score&quot;:78&#125;</span><br><span class="line">]&#125;)</span><br><span class="line">db.users.aggregate([&#123;&quot;$unwind&quot;:&quot;$score&quot;&#125;])  # 将数组拆分展示</span><br><span class="line"></span><br><span class="line">db.users.insert([</span><br><span class="line">    &#123;&quot;name&quot;:&quot;wxk&quot;, &quot;price&quot;:90&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;wx&quot;, &quot;price&quot;:56&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;qqq&quot;, &quot;price&quot;:66&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;www&quot;, &quot;price&quot;:56&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;eee&quot;, &quot;price&quot;:96&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;rrr&quot;, &quot;price&quot;:36&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;ttt&quot;, &quot;price&quot;:86&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;yyy&quot;, &quot;price&quot;:76&#125;</span><br><span class="line">])</span><br><span class="line">db.users.aggregate([  # 分桶计数</span><br><span class="line">    &#123;$bucket:&#123;</span><br><span class="line">        groupBy:&quot;$score&quot;,</span><br><span class="line">        boundaries:[0,30,60,80,90],</span><br><span class="line">        default:&quot;Other&quot;,</span><br><span class="line">        output:&#123;&quot;count&quot;:&#123;&quot;$sum&quot;:1&#125;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;])</span><br></pre></td></tr></table></figure>

<h4 id="SQL和MQL"><a href="#SQL和MQL" class="headerlink" title="SQL和MQL"></a>SQL和MQL</h4><table>
<thead>
<tr>
<th>SQL</th>
<th>MQL</th>
</tr>
</thead>
<tbody><tr>
<td>a &#x3D; 1</td>
<td>{a : 1}</td>
</tr>
<tr>
<td>a &lt;&gt; 1</td>
<td>{a : {$ne : 1}}</td>
</tr>
<tr>
<td>a &gt; 1</td>
<td>{a : {$gt : 1}}</td>
</tr>
<tr>
<td>a &gt;&#x3D; 1</td>
<td>{a : {$gte : 1}}</td>
</tr>
<tr>
<td>a &lt; 1</td>
<td>{a : {$lt : 1}}</td>
</tr>
<tr>
<td>a &lt;&#x3D; 1</td>
<td>{a : {$lte : 1}}</td>
</tr>
<tr>
<td>a &#x3D; 1 AND b &#x3D; 1</td>
<td>{a &#x3D; 1, b &#x3D; 1}或者{$and: [{a&#x3D;1}, {b&#x3D;1}]}</td>
</tr>
<tr>
<td>a &#x3D; 1 OR b &#x3D; 1</td>
<td>{$or: [{a&#x3D;1}, {b&#x3D;1}]}</td>
</tr>
<tr>
<td>a IS NULL</td>
<td>{a: {$exsits: false}}</td>
</tr>
<tr>
<td>a IN (1, 2, 3)</td>
<td>{a: {$in: [1, 2, 3]}}</td>
</tr>
<tr>
<td>WHERE</td>
<td>$match</td>
</tr>
<tr>
<td>AS</td>
<td>$project</td>
</tr>
<tr>
<td>ORDER BY</td>
<td>$sort</td>
</tr>
<tr>
<td>GROUP BY</td>
<td>$group</td>
</tr>
<tr>
<td>SKIP&#x2F;LIMIT</td>
<td>$sklp&#x2F;$limit</td>
</tr>
<tr>
<td>LEFT OUTER JOIN</td>
<td>$lookup</td>
</tr>
</tbody></table>
<h4 id="Python操作"><a href="#Python操作" class="headerlink" title="Python操作"></a>Python操作</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymongo  <span class="comment"># pymongo包</span></span><br><span class="line"><span class="keyword">import</span> dns  <span class="comment"># dnspython包</span></span><br><span class="line"><span class="comment"># 建立连接，使用的是Atlas集群</span></span><br><span class="line">client = pymongo.MongoClient(</span><br><span class="line">    <span class="string">&quot;mongodb+srv://wang:wangxukun1024@wxk.t4vz2.mongodb.net/myFirstDatabase?        retryWrites=true&amp;w=majority&quot;</span>)</span><br><span class="line"><span class="comment"># client = pymongo.MongoClient(&quot;mongodb://localhost:27017&quot;)  # 本地连接方式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建数据库eshop和表users</span></span><br><span class="line">db = client[<span class="string">&#x27;eshop&#x27;</span>]</span><br><span class="line">user_coll = db[<span class="string">&#x27;users&#x27;</span>]</span><br><span class="line">user_coll.insert_many([  <span class="comment"># 插入数据</span></span><br><span class="line">    &#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;wxk&quot;</span>,<span class="string">&quot;age&quot;</span>:<span class="number">26</span>,<span class="string">&quot;email&quot;</span>:<span class="string">&quot;w749@qq.com&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;wx&quot;</span>,<span class="string">&quot;age&quot;</span>:<span class="number">26</span>,<span class="string">&quot;email&quot;</span>:<span class="string">&quot;31923@qq.com&quot;</span>&#125;</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新数据</span></span><br><span class="line">user_coll.update_one(&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;wxk&quot;</span>&#125;,&#123;<span class="string">&quot;$set&quot;</span>:&#123;<span class="string">&quot;phone&quot;</span>:<span class="string">&quot;19991259321&quot;</span>&#125;&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚合</span></span><br><span class="line">user_coll.aggregate([</span><br><span class="line">    &#123;<span class="string">&quot;$match&quot;</span>:&#123;<span class="string">&quot;phone&quot;</span>:<span class="string">&quot;19991259321&quot;</span>&#125;&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;$skip&quot;</span>:<span class="number">1</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;$limit&quot;</span>:<span class="number">1</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;$project&quot;</span>:&#123;<span class="string">&quot;姓名&quot;</span>:<span class="string">&quot;$username&quot;</span>,<span class="string">&quot;年龄&quot;</span>:<span class="string">&quot;$age&quot;</span>&#125;&#125;</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><h3 id="安装-2"><a href="#安装-2" class="headerlink" title="安装"></a>安装</h3><ol>
<li>Local模式，直接下载安装包解压即可，甚至不用配置，直接运行bin目录下的spark-shell就可以启动一个交互式spark环境</li>
<li>Standalone模式，区别于Local模式，这是多台机器组成的集群，有Master用于管理任务和Worker用于运行任务，配置时修改conf目录下的spark-env.sh文件，添加JAVA_HOME、SPARK_MASTER_HOST和SPARK_MASTER_PORT三个环境变量即可，用以指定Master机器，随后修改workers文件，添加计算任务的机器IP。最后将安装包分发到其他机器上，在Master机器上启动sbin目录下的start-all.sh即可。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">spark-env.sh</span></span><br><span class="line">JAVA_HOME=/usr/lib/java/jdk1.8.0_181</span><br><span class="line">SPARK_MASTER_HOST=node01</span><br><span class="line">SPARK_MASTER_PORT=7077</span><br><span class="line">SPARK_MASTER_WEBUI_PORT=8080</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">workers</span></span><br><span class="line">node01</span><br><span class="line">node02</span><br><span class="line">node03</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Yarn on Spark模式，这种模式是将Spark托管在Hadoop下的Yarn用以资源调度，配合Hadoop使用，只需要在spark-env.sh再添加两个环境变量，在spark-defaults.conf中添加几项配置，然后将jars目录下的所有jar包打包放在hdfs下，这个位置需要在spark-defaults.conf中指定，需要特别注意lzo的配置，目前就卡在这了，要将所需jar包放在jars目录下。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">spark-env.sh</span></span><br><span class="line">JAVA_HOME=/usr/lib/java/jdk1.8.0_181</span><br><span class="line">HADOOP_CONF_DIR=/opt/app/hadoop-3.1.3/etc/hadoop</span><br><span class="line">YARN_CONF_DIR=/opt/app/hadoop-3.1.3/etc/hadoop</span><br><span class="line">SPARK_MASTER_HOST=node01</span><br><span class="line">SPARK_MASTER_PORT=7077</span><br><span class="line">SPARK_MASTER_WEBUI_PORT=8080</span><br><span class="line">SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://node01:9000/sparklog/ -Dspark.history.fs.cleaner.enabled=true&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">workers</span></span><br><span class="line">node01</span><br><span class="line">node02</span><br><span class="line">node03</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">spark-defaults.conf</span></span><br><span class="line">spark.eventLog.enabled           true  # 开启日志</span><br><span class="line">spark.eventLog.dir               hdfs://node01:9000/sparklog/  # 日志位置，hdfs提前建好目录</span><br><span class="line">spark.eventLog.compress          true</span><br><span class="line">spark.yarn.historyServer.address node01:18080</span><br><span class="line">spark.yarn.jars                  hdfs://node01:9000/spark/jars/* /opt/app/spark-3.1.2-bin-hadoop3.2/jars/</span><br></pre></td></tr></table></figure>

<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><p>Spark任务一般使用spark-submit命令提交，有下面几个参数比较常用</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark-submit \</span><br><span class="line">--class spark.core.WordCount  # Spark程序中包含主程序的类</span><br><span class="line">--master local[*]             # Spark程序运行的模式（环境）</span><br><span class="line">--executor-memory 1G          # 指定每个executor可用内存为1G（512m）</span><br><span class="line">--total-executor-cores 2      # 指定所有executor使用的cpu核数为两个</span><br><span class="line">--executor-cores 2            # 指定每个executor使用的cpu核数</span><br><span class="line">spark-wordcount-1.0.jar       # 打包好的包含依赖的jar包，本地或者hdfs</span><br></pre></td></tr></table></figure>

<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>Spark 框架的核心是一个计算引擎，整体来说，它采用了标准 master-slave 的结构。如下图所示，它展示了一个 Spark 执行时的基本结构。图形中的 Driver 表示 master， 负责管理整个集群中的作业任务调度。图形中的 Executor 则是 slave，负责实际执行任务。</p>
<div align=center><img src="image-20210825151104511.png"></div>

<p><strong>Diver &amp; Executor</strong></p>
<ul>
<li><strong>Diver</strong><br>Spark驱动节点，用于执行Spark任务中的main方法，负责实际代码的执行工作。</li>
<li><strong>Executor</strong><br>Spark Executor 是集群中工作节点(Worker)中的一个 JVM 进程，负责在 Spark 作业中运行具体任务(Task)，任务彼此之间相互独立。Spark应用启动时，Executor节点被同时启动，并且始终伴随着整个Spark应用的生命周期而存在。如果有Executor节点发生了 故障或崩溃，Spark应用也可以继续执行，会将出错节点上的任务调度到其他 Executor节点上继续运行。</li>
</ul>
<p><strong>Master &amp; Worker</strong></p>
<p>Spark集群的独立部署环境中，不需要依赖其他的资源调度框架，自身就实现了资源调 度的功能，所以环境中还有其他两个核心组件:Master和Worker，这里的Master是一个进程，主要负责资源的调度和分配，并进行集群的监控等职责，类似于Yarn环境中的ResourceManager, 而Worker呢，也是进程，一个Worker运行在集群中的一台服务器上，由 Master分配资源对 数据进行并行的处理和计算，类似于 Yarn 环境中NodeManager。</p>
<p><strong>ApplicationMaster</strong><br>Hadoop用户向YARN 集群提交应用程序时,提交程序中应该包含ApplicationMaster，用 于向资源调度器申请执行任务的资源容器Container，运行用户自己的程序任务job，监控整个任务的执行，跟踪整个任务的状态，处理任务失败等异常情况。说的简单点就是，ResourceManager(资源)和Driver(计算)之间的解耦合靠的就是ApplicationMaster。</p>
<h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><p><strong>Executor与Core</strong></p>
<p>Spark Executor 是集群中运行在工作节点(Worker)中的一个 JVM 进程，是整个集群中的专门用于计算的节点。在提交应用中，可以提供参数指定计算节点的个数，以及对应的资 源。这里的资源一般指的是工作节点 Executor 的内存大小和使用的虚拟 CPU 核(Core)数 量。<br>应用程序相关启动参数如下:<code>--num-executors</code>、<code>--executor-memory</code>、<code>--executor-cores</code></p>
<p><strong>并行度(Parallelism)</strong> </p>
<p>在分布式计算框架中一般都是多个任务同时执行，由于任务分布在不同的计算节点进行<br>计算，所以能够真正地实现多任务并行执行，记住，这里是并行，而不是并发。这里我们将 整个集群并行执行任务的数量称之为并行度。那么一个作业到底并行度是多少呢?这个取决 于框架的默认配置。应用程序也可以在运行过程中动态修改。</p>
<p><strong>有向无环图(DAG)</strong></p>
<p>大数据计算引擎框架我们根据使用方式的不同一般会分为四类，其中第一类就是 Hadoop 所承载的 MapReduce,它将计算分为两个阶段，分别为 Map 阶段 和 Reduce 阶段。 对于上层应用来说，就不得不想方设法去拆分算法，甚至于不得不在上层应用实现多个 Job 的串联，以完成一个完整的算法，例如迭代计算。 由于这样的弊端，催生了支持DAG 框 架的产生。因此，支持 DAG 的框架被划分为第二代计算引擎。如 Tez 以及更上层的 Oozie。这里我们不去细究各种 DAG 实现之间的区别，不过对于当时的 Tez 和 Oozie 来 说，大多还是批处理的任务。接下来就是以 Spark 为代表的第三代的计算引擎。第三代计 算引擎的特点主要是 Job 内部的 DAG 支持(不跨越 Job)，以及实时计算。</p>
<p><strong>提交流程</strong></p>
<p>所谓的提交流程，其实就是我们开发人员根据需求写的应用程序通过 Spark 客户端提交 给 Spark 运行环境执行计算的流程。在不同的部署环境中，这个提交过程基本相同，但是又 有细微的区别，我们这里不进行详细的比较，但是因为国内工作中，将 Spark 引用部署到 Yarn 环境中会更多一些，所以本课程中的提交流程是基于 Yarn 环境的。</p>
<div align=center><img src="image-20210825154407863.png"></div>

<p>Spark 应用程序提交到 Yarn 环境中执行的时候，一般会有两种部署执行的方式:Client 和 Cluster。两种模式主要区别在于:Driver 程序的运行节点位置。</p>
<ol>
<li><strong>Yarn Client 模式</strong></li>
</ol>
<p>Client 模式将用于监控和调度的 Driver 模块在客户端执行，而不是在 Yarn 中，所以一<br>般用于测试。</p>
<ul>
<li>Driver在任务提交的本地机器上运行</li>
<li>Driver启动后会和ResourceManager通讯申请启动ApplicationMaster</li>
<li>ResourceManager分配container，在合适的NodeManager上启动ApplicationMaster，负责向 ResourceManager 申请 Executor 内存</li>
<li>ResourceManager接到ApplicationMaster的资源申请后会分配container，然后ApplicationMaster 在资源分配指定的 NodeManager 上启动 Executor 进程</li>
<li>Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行 main 函数</li>
</ul>
<p>之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分stage，每个stage生 成对应的 TaskSet，之后将 task 分发到各个 Executor 上执行。</p>
<ol start="2">
<li><strong>Yarn Cluster 模式</strong></li>
</ol>
<p>Cluster 模式将用于监控和调度的 Driver 模块启动在 Yarn 集群资源中执行。一般应用于<br>实际生产环境。</p>
<ul>
<li>在YARNCluster模式下，任务提交后会和ResourceManager通讯申请启动<br>ApplicationMaster，</li>
<li>随后ResourceManager分配container，在合适的NodeManager上启动ApplicationMaster，<br>此时的 ApplicationMaster 就是 Driver。</li>
<li>Driver启动后向ResourceManager申请Executor内存，ResourceManager接到ApplicationMaster 的资源申请后会分配 container，然后在合适的 NodeManager 上启动Executor 进程</li>
<li>Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main 函数</li>
<li>之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分stage，每个stage生<br>成对应的 TaskSet，之后将 task 分发到各个 Executor 上执行。</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">WangXun</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://wangxukun.top/2020/10/18/Language/常用软件命令/">https://wangxukun.top/2020/10/18/Language/常用软件命令/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Other/">Other</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/11/07/Language/%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E7%BB%9F%E8%AE%A1/"><i class="fa fa-chevron-left">  </i><span>常见错误统计</span></a></div><div class="next-post pull-right"><a href="/2020/10/18/Software/ELK%E5%91%BD%E4%BB%A4%E8%AF%AD%E6%B3%95%E8%AF%A6%E8%A7%A3/"><span>ELK命令语法详解</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'aaf2844e0aeef4917c17',
  clientSecret: '10b96d24dffda7d3b4544778cf620f81990b676d',
  repo: 'blog-issue',
  owner: 'w749',
  admin: 'w749',
  id: md5(decodeURI(location.pathname)),
  language: 'en'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(/img/top-img.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2019 - 2022 By WangXun</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/lib/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.1"></script><script src="/js/fancybox.js?version=1.9.1"></script><script src="/js/sidebar.js?version=1.9.1"></script><script src="/js/copy.js?version=1.9.1"></script><script src="/js/fireworks.js?version=1.9.1"></script><script src="/js/transition.js?version=1.9.1"></script><script src="/js/scroll.js?version=1.9.1"></script><script src="/js/head.js?version=1.9.1"></script><script src="/js/search/algolia.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>