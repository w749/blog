<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Hive入门-Hive知识体系"><meta name="keywords" content="Hive"><meta name="author" content="WangXun"><meta name="copyright" content="WangXun"><title>Hive入门-Hive知识体系 | Wake</title><link rel="shortcut icon" href="/img/favicon-blank.svg"><link rel="stylesheet" href="/css/index.css?version=1.9.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"HSM2EINL2X","apiKey":"6f1478b12150efd917d5ecfcddfb8b8b","indexName":"wangxun","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '6.0.0'
} </script><meta name="generator" content="Hexo 6.0.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-Hive%E6%A6%82%E8%A7%88"><span class="toc-number">1.</span> <span class="toc-text">一. Hive概览</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-hive%E7%9A%84%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 hive的简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-hive%E7%9A%84%E6%9E%B6%E6%9E%84"><span class="toc-number">1.2.</span> <span class="toc-text">1.2 hive的架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-hive%E4%B8%8Ehadoop%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.3.</span> <span class="toc-text">1.3 hive与hadoop的关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-hive%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E6%AF%94"><span class="toc-number">1.4.</span> <span class="toc-text">1.4 hive与传统数据库对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-hive%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8"><span class="toc-number">1.5.</span> <span class="toc-text">1.5 hive的数据存储</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Hive%E8%A1%A8%E7%B1%BB%E5%9E%8B"><span class="toc-number">2.</span> <span class="toc-text">二、Hive表类型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Hive-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 Hive 数据类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Hive-%E5%86%85%E9%83%A8%E8%A1%A8"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 Hive 内部表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-Hive-%E5%A4%96%E9%83%A8%E8%A1%A8"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 Hive 外部表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-Hive-%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="toc-number">2.4.</span> <span class="toc-text">2.4 Hive 分区表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-Hive-%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="toc-number">2.5.</span> <span class="toc-text">2.5 Hive 分桶表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-6-Hive-%E8%A7%86%E5%9B%BE"><span class="toc-number">2.6.</span> <span class="toc-text">2.6 Hive 视图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81Hive%E6%95%B0%E6%8D%AE%E6%8A%BD%E6%A0%B7"><span class="toc-number">3.</span> <span class="toc-text">三、Hive数据抽样</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E9%9A%8F%E6%9C%BA%E6%8A%BD%E6%A0%B7"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 随机抽样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%9D%97%E6%8A%BD%E6%A0%B7"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 块抽样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E6%A1%B6%E8%A1%A8%E6%8A%BD%E6%A0%B7"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 桶表抽样</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81Hive%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E"><span class="toc-number">4.</span> <span class="toc-text">四、Hive计算引擎</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-MR%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E"><span class="toc-number">4.1.</span> <span class="toc-text">4.1 MR计算引擎</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Tez%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E"><span class="toc-number">4.2.</span> <span class="toc-text">4.2 Tez计算引擎</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Spark%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E"><span class="toc-number">4.3.</span> <span class="toc-text">4.3 Spark计算引擎</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%AD%98%E5%82%A8%E4%B8%8E%E5%8E%8B%E7%BC%A9"><span class="toc-number">5.</span> <span class="toc-text">五、存储与压缩</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Hive%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F"><span class="toc-number">5.1.</span> <span class="toc-text">5.1 Hive存储格式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-1-%E8%A1%8C%E5%BC%8F%E5%AD%98%E5%82%A8%E5%92%8C%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8"><span class="toc-number">5.1.1.</span> <span class="toc-text">5.1.1 行式存储和列式存储</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-2-TEXTFILE"><span class="toc-number">5.1.2.</span> <span class="toc-text">5.1.2 TEXTFILE</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-3-ORC%E6%A0%BC%E5%BC%8F"><span class="toc-number">5.1.3.</span> <span class="toc-text">5.1.3 ORC格式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-4-PARQUET%E6%A0%BC%E5%BC%8F"><span class="toc-number">5.1.4.</span> <span class="toc-text">5.1.4 PARQUET格式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-Hive%E5%8E%8B%E7%BC%A9%E6%A0%BC%E5%BC%8F"><span class="toc-number">5.2.</span> <span class="toc-text">5.2 Hive压缩格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E5%AD%98%E5%82%A8%E5%92%8C%E5%8E%8B%E7%BC%A9%E7%9B%B8%E7%BB%93%E5%90%88"><span class="toc-number">5.3.</span> <span class="toc-text">5.3  存储和压缩相结合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-%E4%B8%BB%E6%B5%81%E5%AD%98%E5%82%A8%E6%96%87%E4%BB%B6%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94"><span class="toc-number">5.4.</span> <span class="toc-text">5.4 主流存储文件性能对比</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81Hive-Sql-%E5%A4%A7%E5%85%A8"><span class="toc-number">6.</span> <span class="toc-text">六、Hive Sql 大全</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#hive%E7%9A%84DDL%E8%AF%AD%E6%B3%95"><span class="toc-number">6.1.</span> <span class="toc-text">hive的DDL语法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%93%8D%E4%BD%9C"><span class="toc-number">6.2.</span> <span class="toc-text">对数据库的操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E6%93%8D%E4%BD%9C"><span class="toc-number">6.3.</span> <span class="toc-text">对数据表的操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E7%AE%A1%E7%90%86%E8%A1%A8-%E5%86%85%E9%83%A8%E8%A1%A8-%E7%9A%84%E6%93%8D%E4%BD%9C"><span class="toc-number">6.3.1.</span> <span class="toc-text">对管理表(内部表)的操作:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E5%A4%96%E9%83%A8%E8%A1%A8%E6%93%8D%E4%BD%9C"><span class="toc-number">6.3.2.</span> <span class="toc-text">对外部表操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E5%88%86%E5%8C%BA%E8%A1%A8%E7%9A%84%E6%93%8D%E4%BD%9C"><span class="toc-number">6.3.3.</span> <span class="toc-text">对分区表的操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E5%88%86%E6%A1%B6%E8%A1%A8%E6%93%8D%E4%BD%9C"><span class="toc-number">6.3.4.</span> <span class="toc-text">对分桶表操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E8%A1%A8%E5%92%8C%E5%88%A0%E9%99%A4%E8%A1%A8"><span class="toc-number">6.3.5.</span> <span class="toc-text">修改表和删除表</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%91hive%E8%A1%A8%E4%B8%AD%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-number">6.3.6.</span> <span class="toc-text">向hive表中加载数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#hive%E8%A1%A8%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA"><span class="toc-number">6.3.7.</span> <span class="toc-text">hive表中数据导出</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hive%E7%9A%84DQL%E6%9F%A5%E8%AF%A2%E8%AF%AD%E6%B3%95"><span class="toc-number">6.4.</span> <span class="toc-text">hive的DQL查询语法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%95%E8%A1%A8%E6%9F%A5%E8%AF%A2"><span class="toc-number">6.5.</span> <span class="toc-text">单表查询</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E5%87%BD%E6%95%B0"><span class="toc-number">7.</span> <span class="toc-text">Hive函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0"><span class="toc-number">7.1.</span> <span class="toc-text">聚合函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E7%B3%BB%E8%BF%90%E7%AE%97"><span class="toc-number">7.2.</span> <span class="toc-text">关系运算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97"><span class="toc-number">7.3.</span> <span class="toc-text">数学运算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97"><span class="toc-number">7.4.</span> <span class="toc-text">逻辑运算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%80%BC%E8%BF%90%E7%AE%97"><span class="toc-number">7.5.</span> <span class="toc-text">数值运算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E5%87%BD%E6%95%B0"><span class="toc-number">7.6.</span> <span class="toc-text">条件函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0"><span class="toc-number">7.7.</span> <span class="toc-text">日期函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%87%BD%E6%95%B0"><span class="toc-number">7.8.</span> <span class="toc-text">字符串函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E5%90%88%E7%B1%BB%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%93%8D%E4%BD%9C"><span class="toc-number">7.9.</span> <span class="toc-text">复合类型构建操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E6%9D%82%E7%B1%BB%E5%9E%8B%E8%AE%BF%E9%97%AE%E6%93%8D%E4%BD%9C"><span class="toc-number">7.10.</span> <span class="toc-text">复杂类型访问操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E6%9D%82%E7%B1%BB%E5%9E%8B%E9%95%BF%E5%BA%A6%E7%BB%9F%E8%AE%A1%E5%87%BD%E6%95%B0"><span class="toc-number">7.11.</span> <span class="toc-text">复杂类型长度统计函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hive%E5%BD%93%E4%B8%AD%E7%9A%84lateral-view-%E4%B8%8E-explode%E4%BB%A5%E5%8F%8Areflect%E5%92%8C%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0"><span class="toc-number">8.</span> <span class="toc-text">hive当中的lateral view 与 explode以及reflect和窗口函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8explode%E5%87%BD%E6%95%B0%E5%B0%86hive%E8%A1%A8%E4%B8%AD%E7%9A%84Map%E5%92%8CArray%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E6%8B%86%E5%88%86"><span class="toc-number">8.1.</span> <span class="toc-text">使用explode函数将hive表中的Map和Array字段数据进行拆分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8explode%E6%8B%86%E5%88%86json%E5%AD%97%E7%AC%A6%E4%B8%B2"><span class="toc-number">8.2.</span> <span class="toc-text">使用explode拆分json字符串</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E5%90%88LATERAL-VIEW%E4%BD%BF%E7%94%A8"><span class="toc-number">8.3.</span> <span class="toc-text">配合LATERAL  VIEW使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%8C%E8%BD%AC%E5%88%97"><span class="toc-number">8.4.</span> <span class="toc-text">行转列</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%97%E8%BD%AC%E8%A1%8C"><span class="toc-number">8.5.</span> <span class="toc-text">列转行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#reflect%E5%87%BD%E6%95%B0"><span class="toc-number">8.6.</span> <span class="toc-text">reflect函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%E4%B8%8E%E5%88%86%E6%9E%90%E5%87%BD%E6%95%B0"><span class="toc-number">9.</span> <span class="toc-text">窗口函数与分析函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#sum%E3%80%81avg%E3%80%81min%E3%80%81max"><span class="toc-number">9.1.</span> <span class="toc-text">sum、avg、min、max</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#row-number%E3%80%81rank%E3%80%81dense-rank%E3%80%81ntile"><span class="toc-number">9.2.</span> <span class="toc-text">row_number、rank、dense_rank、ntile</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E4%B8%80%E4%BA%9B%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0"><span class="toc-number">10.</span> <span class="toc-text">其他一些窗口函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#lag-lead-first-value-last-value"><span class="toc-number">10.1.</span> <span class="toc-text">lag,lead,first_value,last_value</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cume-dist-percent-rank"><span class="toc-number">10.2.</span> <span class="toc-text">cume_dist,percent_rank</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#grouping-sets-grouping-id-cube-rollup"><span class="toc-number">10.3.</span> <span class="toc-text">grouping sets,grouping__id,cube,rollup</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81Hive%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92"><span class="toc-number">11.</span> <span class="toc-text">七、Hive执行计划</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8BSQL%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92"><span class="toc-number">11.1.</span> <span class="toc-text">查看SQL的执行计划</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-explain-%E7%9A%84%E7%94%A8%E6%B3%95"><span class="toc-number">11.2.</span> <span class="toc-text">1.  explain 的用法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-explain-%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">11.3.</span> <span class="toc-text">2. explain 的使用场景</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E4%B8%80%EF%BC%9Ajoin-%E8%AF%AD%E5%8F%A5%E4%BC%9A%E8%BF%87%E6%BB%A4-null-%E7%9A%84%E5%80%BC%E5%90%97%EF%BC%9F"><span class="toc-number">11.3.1.</span> <span class="toc-text">案例一：join 语句会过滤 null 的值吗？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E4%BA%8C%EF%BC%9Agroup-by-%E5%88%86%E7%BB%84%E8%AF%AD%E5%8F%A5%E4%BC%9A%E8%BF%9B%E8%A1%8C%E6%8E%92%E5%BA%8F%E5%90%97%EF%BC%9F"><span class="toc-number">11.3.2.</span> <span class="toc-text">案例二：group by 分组语句会进行排序吗？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E4%B8%89%EF%BC%9A%E5%93%AA%E6%9D%A1sql%E6%89%A7%E8%A1%8C%E6%95%88%E7%8E%87%E9%AB%98%E5%91%A2%EF%BC%9F"><span class="toc-number">11.3.3.</span> <span class="toc-text">案例三：哪条sql执行效率高呢？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-explain-dependency%E7%9A%84%E7%94%A8%E6%B3%95"><span class="toc-number">11.4.</span> <span class="toc-text">2. explain dependency的用法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E4%B8%80%EF%BC%9A%E8%AF%86%E5%88%AB%E7%9C%8B%E4%BC%BC%E7%AD%89%E4%BB%B7%E7%9A%84%E4%BB%A3%E7%A0%81"><span class="toc-number">11.4.1.</span> <span class="toc-text">案例一：识别看似等价的代码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E4%BA%8C%EF%BC%9A%E8%AF%86%E5%88%ABSQL%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E8%8C%83%E5%9B%B4%E7%9A%84%E5%B7%AE%E5%88%AB"><span class="toc-number">11.4.2.</span> <span class="toc-text">案例二：识别SQL读取数据范围的差别</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-explain-authorization-%E7%9A%84%E7%94%A8%E6%B3%95"><span class="toc-number">11.5.</span> <span class="toc-text">3. explain authorization 的用法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%90%8E"><span class="toc-number">11.6.</span> <span class="toc-text">最后</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB%E3%80%81Hive-SQL%E5%BA%95%E5%B1%82%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86"><span class="toc-number">12.</span> <span class="toc-text">八、Hive SQL底层执行原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive-%E5%BA%95%E5%B1%82%E6%89%A7%E8%A1%8C%E6%9E%B6%E6%9E%84"><span class="toc-number">12.1.</span> <span class="toc-text">Hive 底层执行架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive-SQL-%E7%BC%96%E8%AF%91%E6%88%90-MapReduce-%E8%BF%87%E7%A8%8B"><span class="toc-number">12.2.</span> <span class="toc-text">Hive SQL 编译成 MapReduce 过程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%8B%E9%9D%A2%E5%AF%B9%E8%BF%99%E5%85%AD%E4%B8%AA%E9%98%B6%E6%AE%B5%E8%AF%A6%E7%BB%86%E8%A7%A3%E6%9E%90%EF%BC%9A"><span class="toc-number">12.2.0.1.</span> <span class="toc-text">下面对这六个阶段详细解析：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SQL%E7%BC%96%E8%AF%91%E6%88%90MapReduce%E5%85%B7%E4%BD%93%E5%8E%9F%E7%90%86"><span class="toc-number">12.3.</span> <span class="toc-text">SQL编译成MapReduce具体原理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Join%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">12.3.0.1.</span> <span class="toc-text">Join的实现原理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Group-By%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">12.3.0.2.</span> <span class="toc-text">Group By的实现原理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Distinct%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">12.3.0.3.</span> <span class="toc-text">Distinct的实现原理</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B9%9D%E3%80%81Hive%E5%8D%83%E4%BA%BF%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">13.</span> <span class="toc-text">九、Hive千亿级数据倾斜</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E9%97%AE%E9%A2%98%E5%89%96%E6%9E%90"><span class="toc-number">13.1.</span> <span class="toc-text">数据倾斜问题剖析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">13.2.</span> <span class="toc-text">数据倾斜解决方案</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%A9%BA%E5%80%BC%E5%BC%95%E5%8F%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">13.3.</span> <span class="toc-text">1. 空值引发的数据倾斜</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%B8%8D%E5%90%8C%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%BC%95%E5%8F%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">13.4.</span> <span class="toc-text">2. 不同数据类型引发的数据倾斜</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E4%B8%8D%E5%8F%AF%E6%8B%86%E5%88%86%E5%A4%A7%E6%96%87%E4%BB%B6%E5%BC%95%E5%8F%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">13.5.</span> <span class="toc-text">3. 不可拆分大文件引发的数据倾斜</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%95%B0%E6%8D%AE%E8%86%A8%E8%83%80%E5%BC%95%E5%8F%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">13.6.</span> <span class="toc-text">4. 数据膨胀引发的数据倾斜</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E8%A1%A8%E8%BF%9E%E6%8E%A5%E6%97%B6%E5%BC%95%E5%8F%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">13.7.</span> <span class="toc-text">5. 表连接时引发的数据倾斜</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E7%A1%AE%E5%AE%9E%E6%97%A0%E6%B3%95%E5%87%8F%E5%B0%91%E6%95%B0%E6%8D%AE%E9%87%8F%E5%BC%95%E5%8F%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">13.8.</span> <span class="toc-text">6. 确实无法减少数据量引发的数据倾斜</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">13.9.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%81%E3%80%81Hive%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96"><span class="toc-number">14.</span> <span class="toc-text">十、Hive企业级性能优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E7%9A%84%E6%96%B9%E5%BC%8F"><span class="toc-number">15.</span> <span class="toc-text">Hive性能问题排查的方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%84%E6%96%B9%E5%BC%8F"><span class="toc-number">16.</span> <span class="toc-text">Hive性能调优的方式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-SQL%E8%AF%AD%E5%8F%A5%E4%BC%98%E5%8C%96"><span class="toc-number">16.1.</span> <span class="toc-text">1. SQL语句优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-union-all"><span class="toc-number">16.1.1.</span> <span class="toc-text">1. union all</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-distinct"><span class="toc-number">16.1.2.</span> <span class="toc-text">2. distinct</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E4%BC%98%E5%8C%96"><span class="toc-number">16.2.</span> <span class="toc-text">2. 数据格式优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%B0%8F%E6%96%87%E4%BB%B6%E8%BF%87%E5%A4%9A%E4%BC%98%E5%8C%96"><span class="toc-number">16.3.</span> <span class="toc-text">3. 小文件过多优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8C%E4%BC%98%E5%8C%96"><span class="toc-number">16.4.</span> <span class="toc-text">4. 并行执行优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-JVM%E4%BC%98%E5%8C%96"><span class="toc-number">16.5.</span> <span class="toc-text">5. JVM优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E6%8E%A8%E6%B5%8B%E6%89%A7%E8%A1%8C%E4%BC%98%E5%8C%96"><span class="toc-number">16.6.</span> <span class="toc-text">6. 推测执行优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E5%90%8E-1"><span class="toc-number">16.6.1.</span> <span class="toc-text">最后</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%81%E4%B8%80%E3%80%81Hive%E5%A4%A7%E5%8E%82%E9%9D%A2%E8%AF%95%E7%9C%9F%E9%A2%98"><span class="toc-number">17.</span> <span class="toc-text">十一、Hive大厂面试真题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-hive%E5%86%85%E9%83%A8%E8%A1%A8%E5%92%8C%E5%A4%96%E9%83%A8%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">17.1.</span> <span class="toc-text">1. hive内部表和外部表的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Hive%E6%9C%89%E7%B4%A2%E5%BC%95%E5%90%97"><span class="toc-number">17.2.</span> <span class="toc-text">2. Hive有索引吗</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%BF%90%E7%BB%B4%E5%A6%82%E4%BD%95%E5%AF%B9hive%E8%BF%9B%E8%A1%8C%E8%B0%83%E5%BA%A6"><span class="toc-number">17.3.</span> <span class="toc-text">3. 运维如何对hive进行调度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-ORC%E3%80%81Parquet%E7%AD%89%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E7%9A%84%E4%BC%98%E7%82%B9"><span class="toc-number">17.4.</span> <span class="toc-text">4. ORC、Parquet等列式存储的优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E7%94%A8%E7%9A%84%E5%93%AA%E4%BA%9B%E6%A8%A1%E5%9E%8B%EF%BC%9F"><span class="toc-number">17.5.</span> <span class="toc-text">5. 数据建模用的哪些模型？</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%98%9F%E5%9E%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">17.5.0.1.</span> <span class="toc-text">1. 星型模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E9%9B%AA%E8%8A%B1%E6%A8%A1%E5%9E%8B"><span class="toc-number">17.5.0.2.</span> <span class="toc-text">2. 雪花模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E6%98%9F%E5%BA%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">17.5.0.3.</span> <span class="toc-text">3. 星座模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AF%B9%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%88%86%E5%B1%82%EF%BC%9F"><span class="toc-number">17.6.</span> <span class="toc-text">6. 为什么要对数据仓库分层？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E4%BD%BF%E7%94%A8%E8%BF%87Hive%E8%A7%A3%E6%9E%90JSON%E4%B8%B2%E5%90%97"><span class="toc-number">17.7.</span> <span class="toc-text">7. 使用过Hive解析JSON串吗</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-sort-by-%E5%92%8C-order-by-%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">17.8.</span> <span class="toc-text">8. sort by 和 order by 的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3"><span class="toc-number">17.9.</span> <span class="toc-text">9. 数据倾斜怎么解决</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-Hive-%E5%B0%8F%E6%96%87%E4%BB%B6%E8%BF%87%E5%A4%9A%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3"><span class="toc-number">17.10.</span> <span class="toc-text">10. Hive 小文件过多怎么解决</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E4%BD%BF%E7%94%A8-hive-%E8%87%AA%E5%B8%A6%E7%9A%84-concatenate-%E5%91%BD%E4%BB%A4%EF%BC%8C%E8%87%AA%E5%8A%A8%E5%90%88%E5%B9%B6%E5%B0%8F%E6%96%87%E4%BB%B6"><span class="toc-number">17.10.0.1.</span> <span class="toc-text">1. 使用 hive 自带的 concatenate 命令，自动合并小文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E8%B0%83%E6%95%B4%E5%8F%82%E6%95%B0%E5%87%8F%E5%B0%91Map%E6%95%B0%E9%87%8F"><span class="toc-number">17.10.0.2.</span> <span class="toc-text">2. 调整参数减少Map数量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E5%87%8F%E5%B0%91Reduce%E7%9A%84%E6%95%B0%E9%87%8F"><span class="toc-number">17.10.0.3.</span> <span class="toc-text">3. 减少Reduce的数量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E4%BD%BF%E7%94%A8hadoop%E7%9A%84archive%E5%B0%86%E5%B0%8F%E6%96%87%E4%BB%B6%E5%BD%92%E6%A1%A3"><span class="toc-number">17.10.0.4.</span> <span class="toc-text">4. 使用hadoop的archive将小文件归档</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-Hive%E4%BC%98%E5%8C%96%E6%9C%89%E5%93%AA%E4%BA%9B"><span class="toc-number">17.11.</span> <span class="toc-text">11. Hive优化有哪些</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E5%8F%8A%E5%8E%8B%E7%BC%A9%EF%BC%9A"><span class="toc-number">17.11.0.1.</span> <span class="toc-text">1. 数据存储及压缩：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E9%80%9A%E8%BF%87%E8%B0%83%E5%8F%82%E4%BC%98%E5%8C%96%EF%BC%9A"><span class="toc-number">17.11.0.2.</span> <span class="toc-text">2. 通过调参优化：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E6%9C%89%E6%95%88%E5%9C%B0%E5%87%8F%E5%B0%8F%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B0%86%E5%A4%A7%E8%A1%A8%E6%8B%86%E5%88%86%E6%88%90%E5%AD%90%E8%A1%A8%EF%BC%9B%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8%E5%A4%96%E9%83%A8%E8%A1%A8%E5%92%8C%E5%88%86%E5%8C%BA%E8%A1%A8%E3%80%82"><span class="toc-number">17.11.0.3.</span> <span class="toc-text">3. 有效地减小数据集将大表拆分成子表；结合使用外部表和分区表。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-SQL%E4%BC%98%E5%8C%96"><span class="toc-number">17.11.0.4.</span> <span class="toc-text">4. SQL优化</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%84%EF%BC%9A%E4%B9%9D%E4%B8%AA%E6%9C%80%E6%98%93%E5%87%BA%E9%94%99%E7%9A%84SQL%E8%AE%B2%E8%A7%A3"><span class="toc-number">18.</span> <span class="toc-text">附：九个最易出错的SQL讲解</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-decimal"><span class="toc-number">18.0.1.</span> <span class="toc-text">1. decimal</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-location"><span class="toc-number">18.0.2.</span> <span class="toc-text">2. location</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-load-data-%E5%92%8C-load-data-local"><span class="toc-number">18.0.3.</span> <span class="toc-text">3. load data 和 load data local</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-drop-%E5%92%8C-truncate"><span class="toc-number">18.0.4.</span> <span class="toc-text">4. drop 和 truncate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-join-%E8%BF%9E%E6%8E%A5"><span class="toc-number">18.0.5.</span> <span class="toc-text">5. join 连接</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-left-semi-join"><span class="toc-number">18.0.6.</span> <span class="toc-text">6. left semi join</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0%E4%B8%AD-null-%E5%80%BC"><span class="toc-number">18.0.7.</span> <span class="toc-text">7. 聚合函数中 null 值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-%E8%BF%90%E7%AE%97%E7%AC%A6%E4%B8%AD-null-%E5%80%BC"><span class="toc-number">18.0.8.</span> <span class="toc-text">8. 运算符中 null 值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-and-%E5%92%8C-or"><span class="toc-number">18.0.9.</span> <span class="toc-text">9. and 和 or</span></a></li></ol></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.jpg"></div><div class="author-info__name text-center">WangXun</div><div class="author-info__description text-center"></div><div class="follow-button"><a target="_blank" rel="noopener" href="https://github.com/w749">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">71</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">20</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">6</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/top-img.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Wake</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">Hive入门-Hive知识体系</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-10-27</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Software/">Software</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">40.2k</span><span class="post-meta__separator">|</span><span>Reading time: 153 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>介绍了 Hive 数据仓库的特征、计算引擎、存储压缩、HQL、底层原理、性能优化以及常见面试题等知识。文章来源于<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/bgsRLETej0KcZs-lQKNYKg#">五分钟学大数据</a> ，作者园陌</p>
<span id="more"></span>

<p>Hive涉及的知识点如下图所示，本文将逐一讲解：</p>
<div align=center><img src="Hive涉及的知识点.png"></div>

<p><strong>正文开始：</strong></p>
<h2 id="一-Hive概览"><a href="#一-Hive概览" class="headerlink" title="一. Hive概览"></a>一. Hive概览</h2><h3 id="1-1-hive的简介"><a href="#1-1-hive的简介" class="headerlink" title="1.1 hive的简介"></a>1.1 hive的简介</h3><p>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。</p>
<p>其本质是将SQL转换为MapReduce&#x2F;Spark的任务进行运算，底层由HDFS来提供数据的存储，说白了hive可以理解为一个将SQL转换为MapReduce&#x2F;Spark的任务的工具，甚至更进一步可以说hive就是一个MapReduce&#x2F;Spark Sql的客户端</p>
<p>为什么要使用hive ?</p>
<p>主要的原因有以下几点:</p>
<ul>
<li>学习MapReduce的成本比较高, 项目周期要求太短, MapReduce如果要实现复杂的查询逻辑开发的难度是比较大的。</li>
<li>而如果使用hive, hive采用操作接口类似SQL语法, 提高快速开发的能力. 避免去书写MapReduce,减少学习成本, 而且提供了功能的扩展</li>
</ul>
<p>hive的特点:</p>
<ol>
<li>可扩展 :  Hive可以自由的扩展集群的规模，一般情况下不需要重启服务。</li>
<li>延展性 :  Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</li>
<li>容错 :  良好的容错性，节点出现问题SQL仍可完成执行。</li>
</ol>
<h3 id="1-2-hive的架构"><a href="#1-2-hive的架构" class="headerlink" title="1.2 hive的架构"></a>1.2 hive的架构</h3><div align=center><img src="hive的架构.png"></div>

<p>基本组成:</p>
<p><strong>用户接口</strong>：包括CLI、JDBC&#x2F;ODBC、WebGUI。其中，CLI(command line interface)为shell命令行；JDBC&#x2F;ODBC是Hive的JAVA实现，与传统数据库JDBC类似；WebGUI是通过浏览器访问Hive。</p>
<p><strong>元数据存储</strong>：通常是存储在关系数据库如mysql&#x2F;derby中。Hive 将元数据存储在数据库中。Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。</p>
<p><strong>解释器、编译器、优化器、执行器</strong>:完成HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在HDFS 中，并在随后有MapReduce 调用执行。</p>
<h3 id="1-3-hive与hadoop的关系"><a href="#1-3-hive与hadoop的关系" class="headerlink" title="1.3 hive与hadoop的关系"></a>1.3 hive与hadoop的关系</h3><p>Hive利用HDFS存储数据，利用MapReduce查询分析数据</p>
<div align=center><img src="hive与hadoop的关系.png"></div>

<h3 id="1-4-hive与传统数据库对比"><a href="#1-4-hive与传统数据库对比" class="headerlink" title="1.4 hive与传统数据库对比"></a>1.4 hive与传统数据库对比</h3><p>hive主要是用于海量数据的离线数据分析</p>
<div align=center><img src="hive与传统数据库对比.png"></div>

<ol>
<li><strong>查询语言</strong>。由于 SQL 被广泛的应用在数据仓库中，因此，专门针对 Hive 的特性设计了类 SQL 的查询语言 HQL。熟悉 SQL 开发的开发者可以很方便的使用 Hive 进行开发。</li>
<li><strong>数据存储位置</strong>。Hive 是建立在 Hadoop 之上的，所有 Hive 的数据都是存储在 HDFS 中的。而数据库则可以将数据保存在块设备或者本地文件系统中。</li>
<li><strong>数据格式</strong>。Hive 中没有定义专门的数据格式，数据格式可以由用户指定，用户定义数据格式需要指定三个属性：列分隔符（通常为空格、”\t”、”\x001″）、行分隔符（”\n”）以及读取文件数据的方法（Hive 中默认有三个文件格式 TextFile，SequenceFile 以及 RCFile）。由于在加载数据的过程中，不需要从用户数据格式到 Hive 定义的数据格式的转换，因此，Hive 在加载的过程中不会对数据本身进行任何修改，而只是将数据内容复制或者移动到相应的 HDFS 目录中。而在数据库中，不同的数据库有不同的存储引擎，定义了自己的数据格式。所有数据都会按照一定的组织存储，因此，数据库加载数据的过程会比较耗时。</li>
<li><strong>数据更新</strong>。由于 Hive 是针对数据仓库应用设计的，而数据仓库的内容是读多写少的。因此，Hive 中不支持对数据的改写和添加，所有的数据都是在加载的时候中确定好的。而数据库中的数据通常是需要经常进行修改的，因此可以使用 INSERT INTO …  VALUES 添加数据，使用 UPDATE … SET 修改数据。</li>
<li><strong>索引</strong>。之前已经说过，Hive 在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些 Key 建立索引。Hive 要访问数据中满足条件的特定值时，需要暴力扫描整个数据，因此访问延迟较高。由于 MapReduce 的引入， Hive 可以并行访问数据，因此即使没有索引，对于大数据量的访问，Hive 仍然可以体现出优势。数据库中，通常会针对一个或者几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。由于数据的访问延迟较高，决定了 Hive 不适合在线数据查询。</li>
<li><strong>执行</strong>。Hive 中大多数查询的执行是通过 Hadoop 提供的 MapReduce 来实现的，而数据库通常有自己的执行引擎。</li>
<li><strong>执行延迟</strong>。之前提到，Hive 在查询数据的时候，由于没有索引，需要扫描整个表，因此延迟较高。另外一个导致 Hive 执行延迟高的因素是 MapReduce 框架。由于 MapReduce 本身具有较高的延迟，因此在利用 MapReduce 执行 Hive 查询时，也会有较高的延迟。相对的，数据库的执行延迟较低。当然，这个低是有条件的，即数据规模较小，当数据规模大到超过数据库的处理能力的时候，Hive 的并行计算显然能体现出优势。</li>
<li><strong>可扩展性</strong>。由于 Hive 是建立在 Hadoop 之上的，因此 Hive 的可扩展性是和 Hadoop 的可扩展性是一致的（世界上最大的 Hadoop 集群在 Yahoo!，2009年的规模在 4000 台节点左右）。而数据库由于 ACID 语义的严格限制，扩展行非常有限。目前最先进的并行数据库 Oracle 在理论上的扩展能力也只有 100 台左右。</li>
<li><strong>数据规模</strong>。由于 Hive 建立在集群上并可以利用 MapReduce 进行并行计算，因此可以支持很大规模的数据；对应的，数据库可以支持的数据规模较小。</li>
</ol>
<p>总结：hive具有sql数据库的外表，但应用场景完全不同，hive只适合用来做批量数据统计分析。</p>
<h3 id="1-5-hive的数据存储"><a href="#1-5-hive的数据存储" class="headerlink" title="1.5 hive的数据存储"></a>1.5 hive的数据存储</h3><ol>
<li>Hive中所有的数据都存储在 HDFS 中，没有专门的数据存储格式（可支持Text，SequenceFile，ParquetFile，ORC格式RCFILE等）</li>
</ol>
<blockquote>
<p>SequenceFile是hadoop中的一种文件格式：文件内容是以序列化的kv对象来组织的</p>
</blockquote>
<ol>
<li>只需要在创建表的时候告诉 Hive 数据中的列分隔符和行分隔符，Hive 就可以解析数据。</li>
<li>Hive 中包含以下数据模型：DB、Table，External Table，Partition，Bucket。</li>
</ol>
<ul>
<li>db：在hdfs中表现为<code>hive.metastore.warehouse.dir</code>目录下一个文件夹。</li>
<li>table：在hdfs中表现所属db目录下一个文件夹。</li>
<li>external table：与table类似，不过其数据存放位置可以在任意指定路径。</li>
<li>partition：在hdfs中表现为table目录下的子目录。</li>
<li>bucket：在hdfs中表现为同一个表目录下根据hash散列之后的多个文件。</li>
</ul>
<h2 id="二、Hive表类型"><a href="#二、Hive表类型" class="headerlink" title="二、Hive表类型"></a>二、Hive表类型</h2><h3 id="2-1-Hive-数据类型"><a href="#2-1-Hive-数据类型" class="headerlink" title="2.1 Hive 数据类型"></a>2.1 Hive 数据类型</h3><p>Hive的基本数据类型有：<code>TINYINT，SAMLLINT，INT，BIGINT，BOOLEAN，FLOAT，DOUBLE，STRING，TIMESTAMP(V0.8.0+)和BINARY(V0.8.0+)</code>。</p>
<p>Hive的集合类型有：<code>STRUCT，MAP和ARRAY</code>。</p>
<p>Hive主要有四种数据模型(即表)：内部表、外部表、分区表和桶表。</p>
<p>表的元数据保存传统的数据库的表中，<strong>当前hive只支持Derby和MySQL数据库</strong>。</p>
<h3 id="2-2-Hive-内部表"><a href="#2-2-Hive-内部表" class="headerlink" title="2.2 Hive 内部表"></a>2.2 Hive 内部表</h3><p>Hive中的内部表和传统数据库中的表在概念上是类似的，Hive的每个表都有自己的存储目录，除了外部表外，所有的表数据都存放在配置在<code>hive-site.xml</code>文件的<code>$&#123;hive.metastore.warehouse.dir&#125;/table_name</code>目录下。</p>
<p>创建内部表：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> students(user_no <span class="type">INT</span>,name STRING,sex STRING,  </span><br><span class="line">         grade STRING COMMOT <span class="string">&#x27;班级&#x27;</span>）COMMONT <span class="string">&#x27;学生表&#x27;</span>  </span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED </span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">STORE <span class="keyword">AS</span> TEXTFILE;      </span><br></pre></td></tr></table></figure>

<h3 id="2-3-Hive-外部表"><a href="#2-3-Hive-外部表" class="headerlink" title="2.3 Hive 外部表"></a>2.3 Hive 外部表</h3><p>被external修饰的为外部表（external table），外部表指向已经存在在Hadoop HDFS上的数据，除了在删除外部表时只删除元数据而不会删除表数据外，其他和内部表很像。</p>
<p>创建外部表：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> students(user_no <span class="type">INT</span>,name STRING,sex STRING,  </span><br><span class="line">         class STRING COMMOT <span class="string">&#x27;班级&#x27;</span>）COMMONT <span class="string">&#x27;学生表&#x27;</span>  </span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED  </span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>  </span><br><span class="line">STORE <span class="keyword">AS</span> SEQUENCEFILE </span><br><span class="line">LOCATION <span class="string">&#x27;/usr/test/data/students.txt&#x27;</span>;   </span><br></pre></td></tr></table></figure>

<h3 id="2-4-Hive-分区表"><a href="#2-4-Hive-分区表" class="headerlink" title="2.4 Hive 分区表"></a>2.4 Hive 分区表</h3><p>分区表的每一个分区都对应数据库中相应分区列的一个索引，但是其组织方式和传统的关系型数据库不同。在Hive中，分区表的每一个分区都对应表下的一个目录，所有的分区的数据都存储在对应的目录中。</p>
<p>比如说，分区表partitinTable有包含nation(国家)、ds(日期)和city(城市)3个分区，其中nation &#x3D; china，ds &#x3D; 20130506，city &#x3D; Shanghai则对应HDFS上的目录为：</p>
<p><code>/datawarehouse/partitinTable/nation=china/city=Shanghai/ds=20130506/</code>。</p>
<p><strong>分区中定义的变量名不能和表中的列相同</strong>。</p>
<p>创建分区表：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> students(user_no <span class="type">INT</span>,name STRING,sex STRING,</span><br><span class="line">         class STRING COMMOT <span class="string">&#x27;班级&#x27;</span>）COMMONT <span class="string">&#x27;学生表&#x27;</span>  </span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (ds STRING,country STRING)  </span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED  </span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>  </span><br><span class="line">STORE <span class="keyword">AS</span> SEQUENCEFILE;</span><br></pre></td></tr></table></figure>

<h3 id="2-5-Hive-分桶表"><a href="#2-5-Hive-分桶表" class="headerlink" title="2.5 Hive 分桶表"></a>2.5 Hive 分桶表</h3><p>桶表就是对指定列进行哈希(hash)计算，然后会根据hash值进行切分数据，将具有不同hash值的数据写到每个桶对应的文件中。</p>
<p>将数据按照指定的字段进行分成多个桶中去，说白了就是将数据按照字段进行划分，可以将数据按照字段划分到<strong>多个文件</strong>当中去。</p>
<p>创建分桶表：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> students(user_no <span class="type">INT</span>,name STRING,sex STRING,  </span><br><span class="line">         class STRING COMMOT <span class="string">&#x27;班级&#x27;</span>,score <span class="type">SMALLINT</span> COMMOT <span class="string">&#x27;总分&#x27;</span>）COMMONT <span class="string">&#x27;学生表&#x27;</span>  </span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (ds STRING,country STRING)  </span><br><span class="line">CLUSTERED <span class="keyword">BY</span>(user_no) SORTED <span class="keyword">BY</span>(score) <span class="keyword">INTO</span> <span class="number">32</span> BUCKETS  </span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED  </span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>  </span><br><span class="line">STORE <span class="keyword">AS</span> SEQUENCEFILE;      </span><br></pre></td></tr></table></figure>

<h3 id="2-6-Hive-视图"><a href="#2-6-Hive-视图" class="headerlink" title="2.6 Hive 视图"></a>2.6 Hive 视图</h3><p>在 Hive 中，视图是逻辑数据结构，可以通过隐藏复杂数据操作（Joins, 子查询, 过滤,数据扁平化）来于简化查询操作。</p>
<p>与关系数据库不同的是，Hive视图并不存储数据或者实例化。一旦创建 HIve 视图，它的 schema 也会立刻确定下来。对底层表后续的更改(如 增加新列)并不会影响视图的 schema。如果底层表被删除或者改变，之后对视图的查询将会 failed。基于以上 Hive view 的特性，我们在ETL和数据仓库中<strong>对于经常变化的表应慎重使用视图</strong>。</p>
<p>创建视图：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> employee_skills</span><br><span class="line"> <span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> name, skills_score[<span class="string">&#x27;DB&#x27;</span>] <span class="keyword">AS</span> DB,</span><br><span class="line">skills_score[<span class="string">&#x27;Perl&#x27;</span>] <span class="keyword">AS</span> Perl, </span><br><span class="line">skills_score[<span class="string">&#x27;Python&#x27;</span>] <span class="keyword">AS</span> Python,</span><br><span class="line">skills_score[<span class="string">&#x27;Sales&#x27;</span>] <span class="keyword">as</span> Sales, </span><br><span class="line">skills_score[<span class="string">&#x27;HR&#x27;</span>] <span class="keyword">as</span> HR </span><br><span class="line"><span class="keyword">FROM</span> employee;</span><br></pre></td></tr></table></figure>

<p>创建视图的时候是不会触发 MapReduce 的 Job，因为只存在元数据的改变。</p>
<p>但是，当对视图进行查询的时候依然会触发一个 MapReduce Job 进程：SHOW CREATE TABLE 或者 DESC FORMATTED TABLE 语句来显示通过  CREATE VIEW  语句创建的视图。以下是对Hive 视图的 DDL操作：</p>
<p>更改视图的属性：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">VIEW</span> employee_skills </span><br><span class="line"><span class="keyword">SET</span> TBLPROPERTIES (<span class="string">&#x27;comment&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;This is a view&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>重新定义视图：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">VIEW</span> employee_skills <span class="keyword">AS</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">from</span> employee ;</span><br></pre></td></tr></table></figure>

<p>删除视图：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">VIEW</span> employee_skills; </span><br></pre></td></tr></table></figure>

<h2 id="三、Hive数据抽样"><a href="#三、Hive数据抽样" class="headerlink" title="三、Hive数据抽样"></a>三、Hive数据抽样</h2><p>当数据规模不断膨胀时，我们需要找到一个数据的子集来加快数据分析效率。因此我们就需要通过筛选和分析数据集为了进行<strong>模式 &amp; 趋势识别</strong>。目前来说有三种方式来进行抽样：随机抽样，桶表抽样，和块抽样。</p>
<h3 id="3-1-随机抽样"><a href="#3-1-随机抽样" class="headerlink" title="3.1 随机抽样"></a>3.1 随机抽样</h3><p>关键词：<strong>rand()函数</strong>。</p>
<p>使用rand()函数进行随机抽样，limit关键字限制抽样返回的数据，其中rand函数前的distribute和sort关键字可以保证数据在mapper和reducer阶段是随机分布的。</p>
<p>案例如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> table_name </span><br><span class="line"><span class="keyword">where</span> col<span class="operator">=</span>xxx </span><br><span class="line">distribute <span class="keyword">by</span> rand() sort <span class="keyword">by</span> rand() </span><br><span class="line">limit num; </span><br></pre></td></tr></table></figure>

<p>使用order 关键词:</p>
<p>案例如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> table_name </span><br><span class="line"><span class="keyword">where</span> col<span class="operator">=</span>xxx </span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> rand() </span><br><span class="line">limit num; </span><br></pre></td></tr></table></figure>

<p>经测试对比，千万级数据中进行随机抽样 order by方式耗时更长，大约多30秒左右。</p>
<h3 id="3-2-块抽样"><a href="#3-2-块抽样" class="headerlink" title="3.2 块抽样"></a>3.2 块抽样</h3><p>关键词：<strong>tablesample()函数</strong>。</p>
<ol>
<li>tablesample(n percent) 根据hive表数据的大小按比例抽取数据，并保存到新的hive表中。如：抽取原hive表中10%的数据</li>
</ol>
<blockquote>
<p>注意：测试过程中发现，select语句不能带where条件且不支持子查询，可通过新建中间表或使用随机抽样解决。</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> xxx <span class="keyword">tablesample</span>(<span class="number">10</span> <span class="keyword">percent</span>) 数字与<span class="keyword">percent</span>之间要有空格</span><br></pre></td></tr></table></figure>

<ol>
<li>tablesample(nM) 指定抽样数据的大小，单位为M。</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> xxx <span class="keyword">tablesample</span>(<span class="number">20</span>M) 数字与M之间不要有空格</span><br></pre></td></tr></table></figure>

<ol>
<li>tablesample(n rows) 指定抽样数据的行数，其中n代表每个map任务均取n行数据，map数量可通过hive表的简单查询语句确认（关键词：number of mappers: x)</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> xxx <span class="keyword">tablesample</span>(<span class="number">100</span> <span class="keyword">rows</span>) 数字与<span class="keyword">rows</span>之间要有空格</span><br></pre></td></tr></table></figure>

<h3 id="3-3-桶表抽样"><a href="#3-3-桶表抽样" class="headerlink" title="3.3 桶表抽样"></a>3.3 桶表抽样</h3><p>关键词：**tablesample (bucket x out of y [on colname])**。</p>
<p>其中x是要抽样的桶编号，桶编号从1开始，colname表示抽样的列，y表示桶的数量。</p>
<p>hive中分桶其实就是根据某一个字段Hash取模，放入指定数据的桶中，比如将表table_1按照ID分成100个桶，其算法是hash(id) % 100，这样，hash(id) % 100 &#x3D; 0的数据被放到第一个桶中，hash(id) % 100 &#x3D; 1的记录被放到第二个桶中。创建分桶表的关键语句为：CLUSTER BY语句。</p>
<p>例如：将表随机分成10组，抽取其中的第一个桶的数据：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> table_01 </span><br><span class="line"><span class="keyword">tablesample</span>(bucket <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">10</span> <span class="keyword">on</span> rand())</span><br></pre></td></tr></table></figure>

<h2 id="四、Hive计算引擎"><a href="#四、Hive计算引擎" class="headerlink" title="四、Hive计算引擎"></a>四、Hive计算引擎</h2><p>目前Hive支持MapReduce、Tez和Spark 三种计算引擎。</p>
<h3 id="4-1-MR计算引擎"><a href="#4-1-MR计算引擎" class="headerlink" title="4.1 MR计算引擎"></a>4.1 MR计算引擎</h3><p>MR运行的完整过程：</p>
<p>Map在读取数据时，先将数据拆分成若干数据，并读取到Map方法中被处理。数据在输出的时候，被分成若干分区并写入内存缓存（buffer）中，内存缓存被数据填充到一定程度会溢出到磁盘并排序，当Map执行完后会将一个机器上输出的临时文件进行归并存入到HDFS中。</p>
<p>当Reduce启动时，会启动一个线程去读取Map输出的数据，并写入到启动Reduce机器的内存中，在数据溢出到磁盘时会对数据进行再次排序。当读取数据完成后会将临时文件进行合并，作为Reduce函数的数据源。</p>
<h3 id="4-2-Tez计算引擎"><a href="#4-2-Tez计算引擎" class="headerlink" title="4.2 Tez计算引擎"></a>4.2 Tez计算引擎</h3><p>Apache Tez是进行大规模数据处理且支持DAG作业的计算框架，它直接源于MapReduce框架，除了能够支持MapReduce特性，还支持新的作业形式，并允许不同类型的作业能够在一个集群中运行。</p>
<p>Tez将原有的Map和Reduce两个操作简化为一个概念——Vertex，并将原有的计算处理节点拆分成多个组成部分：Vertex Input、Vertex Output、Sorting、Shuffling和Merging。计算节点之间的数据通信被统称为Edge，这些分解后的元操作可以任意灵活组合，产生新的操作，这些操作经过一些控制程序组装后，可形成一个大的DAG作业。</p>
<p>通过允许Apache Hive运行复杂的DAG任务，Tez可以用来处理数据，之前需要多个MR jobs，现在一个Tez任务中。</p>
<div align=center><img src="Tez计算引擎.png"></div>

<p><strong>Tez和MapReduce作业的比较</strong>：</p>
<ul>
<li>Tez绕过了MapReduce很多不必要的中间的数据存储和读取的过程，直接在一个作业中表达了MapReduce需要多个作业共同协作才能完成的事情。</li>
<li>Tez和MapReduce一样都运行使用YARN作为资源调度和管理。但与MapReduce on YARN不同，Tez on YARN并不是将作业提交到ResourceManager，而是提交到AMPoolServer的服务上，AMPoolServer存放着若干已经预先启动ApplicationMaster的服务。</li>
<li>当用户提交一个作业上来后，AMPoolServer从中选择一个ApplicationMaster用于管理用户提交上来的作业，这样既可以节省ResourceManager创建ApplicationMaster的时间，而又能够重用每个ApplicationMaster的资源，节省了资源释放和创建时间。</li>
</ul>
<p><strong>Tez相比于MapReduce有几点重大改进</strong>：</p>
<ul>
<li>当查询需要有多个reduce逻辑时，Hive的MapReduce引擎会将计划分解，每个Redcue提交一个MR作业。这个链中的所有MR作业都需要逐个调度，每个作业都必须从HDFS中重新读取上一个作业的输出并重新洗牌。而在Tez中，几个reduce接收器可以直接连接，数据可以流水线传输，而不需要临时HDFS文件，这种模式称为MRR（Map-reduce-reduce*）。</li>
<li>Tez还允许一次发送整个查询计划，实现应用程序动态规划，从而使框架能够更智能地分配资源，并通过各个阶段流水线传输数据。对于更复杂的查询来说，这是一个巨大的改进，因为它消除了IO&#x2F;sync障碍和各个阶段之间的调度开销。</li>
<li>在MapReduce计算引擎中，无论数据大小，在洗牌阶段都以相同的方式执行，将数据序列化到磁盘，再由下游的程序去拉取，并反序列化。Tez可以允许小数据集完全在内存中处理，而MapReduce中没有这样的优化。仓库查询经常需要在处理完大量的数据后对小型数据集进行排序或聚合，Tez的优化也能极大地提升效率。</li>
</ul>
<h3 id="4-3-Spark计算引擎"><a href="#4-3-Spark计算引擎" class="headerlink" title="4.3 Spark计算引擎"></a>4.3 Spark计算引擎</h3><p>Apache Spark是专为大规模数据处理而设计的快速、通用支持DAG（有向无环图）作业的计算引擎，类似于Hadoop MapReduce的通用并行框架，可用来构建大型的、低延迟的数据分析应用程序。</p>
<p>Spark是用于<strong>大规模数据处理</strong>的统一分析引擎，基于内存计算，提高了在大数据环境下数据处理的实时性，同时保证了<strong>高容错性</strong>和<strong>高可伸缩性</strong>，允许用户将Spark部署在大量硬件之上，形成集群。</p>
<p><strong>Spark运行流程</strong></p>
<div align=center><img src="Spark运行流程.png"></div>

<p>Spark具有以下几个特性。</p>
<p>1．<strong>高效性</strong></p>
<p>Spark会将作业构成一个DAG，优化了大型作业一些重复且浪费资源的操作，对查询进行了优化，重新编写了物理执行引擎，如可以实现MRR模式。</p>
<p>2．<strong>易用性</strong></p>
<p>Spark不同于MapReducer只提供两种简单的编程接口，它提供了多种编程接口去操作数据，这些操作接口如果使用MapReduce去实现，需要更多的代码。Spark的操作接口可以分为两类：transformation（转换）和action（执行）。Transformation包含map、flatmap、distinct、reduceByKey和join等转换操作；Action包含reduce、collect、count和first等操作。</p>
<p>3．<strong>通用性</strong></p>
<p>Spark针对实时计算、批处理、交互式查询，提供了统一的解决方案。但在批处理方面相比于MapReduce处理同样的数据，Spark所要求的硬件设施更高，MapReduce在相同的设备下所能处理的数据量会比Spark多。所以在实际工作中，Spark在批处理方面只能算是MapReduce的一种补充。</p>
<p>4．<strong>兼容性</strong></p>
<p>Spark和MapReduce一样有丰富的产品生态做支撑。例如Spark可以使用YARN作为资源管理器，Spark也可以处理Hbase和HDFS上的数据。</p>
<h2 id="五、存储与压缩"><a href="#五、存储与压缩" class="headerlink" title="五、存储与压缩"></a>五、存储与压缩</h2><h3 id="5-1-Hive存储格式"><a href="#5-1-Hive存储格式" class="headerlink" title="5.1 Hive存储格式"></a>5.1 Hive存储格式</h3><p>Hive支持的存储数的格式主要有：TEXTFILE（行式存储） 、SEQUENCEFILE(行式存储)、ORC（列式存储）、PARQUET（列式存储）。</p>
<h4 id="5-1-1-行式存储和列式存储"><a href="#5-1-1-行式存储和列式存储" class="headerlink" title="5.1.1 行式存储和列式存储"></a>5.1.1 行式存储和列式存储</h4><div align=center><img src="行式存储和列式存储.png"></div>

<p>上图左边为逻辑表，右边第一个为行式存储，第二个为列式存储。</p>
<p><strong>行存储的特点：</strong> 查询满足条件的一整行数据的时候，列存储则需要去每个聚集的字段找到对应的每个列的值，行存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度更快。select  *</p>
<p><strong>列存储的特点：</strong> 因为每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量；每个字段的数据类型一定是相同的，列式存储可以针对性的设计更好的设计压缩算法。select  某些字段效率更高。</p>
<h4 id="5-1-2-TEXTFILE"><a href="#5-1-2-TEXTFILE" class="headerlink" title="5.1.2 TEXTFILE"></a>5.1.2 TEXTFILE</h4><p>默认格式，数据不做压缩，磁盘开销大，数据解析开销大。可结合Gzip、Bzip2使用(系统自动检查，执行查询时自动解压)，但使用这种方式，hive不会对数据进行切分，从而无法对数据进行并行操作。</p>
<h4 id="5-1-3-ORC格式"><a href="#5-1-3-ORC格式" class="headerlink" title="5.1.3 ORC格式"></a>5.1.3 ORC格式</h4><p>Orc (Optimized Row Columnar)是hive 0.11版里引入的新的存储格式。</p>
<p>可以看到每个Orc文件由1个或多个stripe组成，每个stripe250MB大小，这个Stripe实际相当于RowGroup概念，不过大小由4MB-&gt;250MB，这样能提升顺序读的吞吐率。每个Stripe里有三部分组成，分别是Index Data,Row Data,Stripe Footer：</p>
<div align=center><img src="ORC格式.png"></div>

<ol>
<li>Index Data：一个轻量级的index，默认是每隔1W行做一个索引。这里做的索引只是记录某行的各字段在Row Data中的offset。</li>
<li>Row Data：存的是具体的数据，先取部分行，然后对这些行按列进行存储。对每个列进行了编码，分成多个Stream来存储。</li>
<li>Stripe Footer：存的是各个stripe的元数据信息</li>
</ol>
<p>每个文件有一个File Footer，这里面存的是每个Stripe的行数，每个Column的数据类型信息等；每个文件的尾部是一个PostScript，这里面记录了整个文件的压缩类型以及FileFooter的长度信息等。在读取文件时，会seek到文件尾部读PostScript，从里面解析到File Footer长度，再读FileFooter，从里面解析到各个Stripe信息，再读各个Stripe，即从后往前读。</p>
<h4 id="5-1-4-PARQUET格式"><a href="#5-1-4-PARQUET格式" class="headerlink" title="5.1.4 PARQUET格式"></a>5.1.4 PARQUET格式</h4><p>Parquet是面向分析型业务的列式存储格式，由Twitter和Cloudera合作开发，2015年5月从Apache的孵化器里毕业成为Apache顶级项目。</p>
<p>Parquet文件是以二进制方式存储的，所以是不可以直接读取的，文件中包括该文件的数据和元数据，因此Parquet格式文件是自解析的。</p>
<p>通常情况下，在存储Parquet数据的时候会按照Block大小设置行组的大小，由于一般情况下每一个Mapper任务处理数据的最小单位是一个Block，这样可以把每一个行组由一个Mapper任务处理，增大任务执行并行度。Parquet文件的格式如下图所示。</p>
<div align=center><img src="PARQUET格式.png"></div>

<p>上图展示了一个Parquet文件的内容，一个文件中可以存储多个行组，文件的首位都是该文件的Magic Code，用于校验它是否是一个Parquet文件，Footer length记录了文件元数据的大小，通过该值和文件长度可以计算出元数据的偏移量，文件的元数据中包括每一个行组的元数据信息和该文件存储数据的Schema信息。除了文件中每一个行组的元数据，每一页的开始都会存储该页的元数据，在Parquet中，有三种类型的页：数据页、字典页和索引页。数据页用于存储当前行组中该列的值，字典页存储该列值的编码字典，每一个列块中最多包含一个字典页，索引页用来存储当前行组下该列的索引，目前Parquet中还不支持索引页。</p>
<h3 id="5-2-Hive压缩格式"><a href="#5-2-Hive压缩格式" class="headerlink" title="5.2 Hive压缩格式"></a>5.2 Hive压缩格式</h3><p>在实际工作当中，hive当中处理的数据，一般都需要经过压缩，前期我们在学习hadoop的时候，已经配置过hadoop的压缩，我们这里的hive也是一样的可以使用压缩来节省我们的MR处理的网络带宽</p>
<p>mr支持的压缩格式:</p>
<table>
<thead>
<tr>
<th align="left">压缩格式</th>
<th align="left">工具</th>
<th align="left">算法</th>
<th align="left">文件扩展名</th>
<th align="left">是否可切分</th>
</tr>
</thead>
<tbody><tr>
<td align="left">DEFAULT</td>
<td align="left">无</td>
<td align="left">DEFAULT</td>
<td align="left">.deflate</td>
<td align="left">否</td>
</tr>
<tr>
<td align="left">Gzip</td>
<td align="left">gzip</td>
<td align="left">DEFAULT</td>
<td align="left">.gz</td>
<td align="left">否</td>
</tr>
<tr>
<td align="left">bzip2</td>
<td align="left">bzip2</td>
<td align="left">bzip2</td>
<td align="left">.bz2</td>
<td align="left">是</td>
</tr>
<tr>
<td align="left">LZO</td>
<td align="left">lzop</td>
<td align="left">LZO</td>
<td align="left">.lzo</td>
<td align="left">否</td>
</tr>
<tr>
<td align="left">LZ4</td>
<td align="left">无</td>
<td align="left">LZ4</td>
<td align="left">.lz4</td>
<td align="left">否</td>
</tr>
<tr>
<td align="left">Snappy</td>
<td align="left">无</td>
<td align="left">Snappy</td>
<td align="left">.snappy</td>
<td align="left">否</td>
</tr>
</tbody></table>
<p>hadoop支持的解压缩的类：</p>
<table>
<thead>
<tr>
<th align="left">压缩格式</th>
<th align="left">对应的编码&#x2F;解码器</th>
</tr>
</thead>
<tbody><tr>
<td align="left">DEFLATE</td>
<td align="left">org.apache.hadoop.io.compress.DefaultCodec</td>
</tr>
<tr>
<td align="left">gzip</td>
<td align="left">org.apache.hadoop.io.compress.GzipCodec</td>
</tr>
<tr>
<td align="left">bzip2</td>
<td align="left">org.apache.hadoop.io.compress.BZip2Codec</td>
</tr>
<tr>
<td align="left">LZO</td>
<td align="left">com.hadoop.compression.lzo.LzopCodec</td>
</tr>
<tr>
<td align="left">LZ4</td>
<td align="left">org.apache.hadoop.io.compress.Lz4Codec</td>
</tr>
<tr>
<td align="left">Snappy</td>
<td align="left">org.apache.hadoop.io.compress.SnappyCodec</td>
</tr>
</tbody></table>
<p>压缩性能的比较：</p>
<table>
<thead>
<tr>
<th align="left">压缩算法</th>
<th align="left">原始文件大小</th>
<th align="left">压缩文件大小</th>
<th align="left">压缩速度</th>
<th align="left">解压速度</th>
</tr>
</thead>
<tbody><tr>
<td align="left">gzip</td>
<td align="left">8.3GB</td>
<td align="left">1.8GB</td>
<td align="left">17.5MB&#x2F;s</td>
<td align="left">58MB&#x2F;s</td>
</tr>
<tr>
<td align="left">bzip2</td>
<td align="left">8.3GB</td>
<td align="left">1.1GB</td>
<td align="left">2.4MB&#x2F;s</td>
<td align="left">9.5MB&#x2F;s</td>
</tr>
<tr>
<td align="left">LZO</td>
<td align="left">8.3GB</td>
<td align="left">2.9GB</td>
<td align="left">49.3MB&#x2F;s</td>
<td align="left">74.6MB&#x2F;s</td>
</tr>
</tbody></table>
<p>Snappy生成的压缩文件要大20%到100%。在64位模式下的core i7处理器的单内核上，Snappy以250 MB&#x2F;秒或更多的速度压缩，并以500 MB&#x2F;秒或更多的速度解压。</p>
<p>实现压缩hadoop需要配置的压缩参数:</p>
<div align=center><img src="实现压缩hadoop需要配置的压缩参数.png"></div>

<p>hive配置压缩的方式:</p>
<ol>
<li>开启map端的压缩方式:</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.1</span>）开启hive中间传输数据压缩功能</span><br><span class="line"> hive (<span class="keyword">default</span>)<span class="operator">&gt;</span><span class="keyword">set</span> hive.exec.compress.intermediate<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="number">1.2</span>）开启mapreduce中map输出压缩功能</span><br><span class="line"> hive (<span class="keyword">default</span>)<span class="operator">&gt;</span><span class="keyword">set</span> mapreduce.map.output.compress<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="number">1.3</span>）设置mapreduce中map输出数据的压缩方式</span><br><span class="line"> hive (<span class="keyword">default</span>)<span class="operator">&gt;</span><span class="keyword">set</span> mapreduce.map.output.compress.codec<span class="operator">=</span> org.apache.hadoop.io.compress.SnappyCodec;</span><br><span class="line"><span class="number">1.4</span>）执行查询语句</span><br><span class="line"> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> score;</span><br></pre></td></tr></table></figure>

<ol>
<li>开启reduce端的压缩方式</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>）开启hive最终输出数据压缩功能</span><br><span class="line"> hive (<span class="keyword">default</span>)<span class="operator">&gt;</span><span class="keyword">set</span> hive.exec.compress.output<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="number">2</span>）开启mapreduce最终输出数据压缩</span><br><span class="line"> hive (<span class="keyword">default</span>)<span class="operator">&gt;</span><span class="keyword">set</span> mapreduce.output.fileoutputformat.compress<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="number">3</span>）设置mapreduce最终数据输出压缩方式</span><br><span class="line"> hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.output.fileoutputformat.compress.codec <span class="operator">=</span> org.apache.hadoop.io.compress.SnappyCodec;</span><br><span class="line"><span class="number">4</span>）设置mapreduce最终数据输出压缩为块压缩</span><br><span class="line"> hive (<span class="keyword">default</span>)<span class="operator">&gt;</span><span class="keyword">set</span> mapreduce.output.fileoutputformat.compress.type<span class="operator">=</span>BLOCK;</span><br><span class="line"><span class="number">5</span>）测试一下输出结果是否是压缩文件</span><br><span class="line"> <span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/export/servers/snappy&#x27;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> score distribute <span class="keyword">by</span> s_id sort <span class="keyword">by</span> s_id <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>

<h3 id="5-3-存储和压缩相结合"><a href="#5-3-存储和压缩相结合" class="headerlink" title="5.3  存储和压缩相结合"></a>5.3  存储和压缩相结合</h3><p>ORC存储方式的压缩：</p>
<table>
<thead>
<tr>
<th align="left">Key</th>
<th align="left">Default</th>
<th align="left">Notes</th>
</tr>
</thead>
<tbody><tr>
<td align="left">orc.compress</td>
<td align="left">ZLIB</td>
<td align="left">高级压缩(可选: NONE, ZLIB, SNAPPY)</td>
</tr>
<tr>
<td align="left">orc.compress.size</td>
<td align="left">262,144</td>
<td align="left">每个压缩块中的字节数</td>
</tr>
<tr>
<td align="left">orc.stripe.size</td>
<td align="left">67,108,864</td>
<td align="left">每条stripe中的字节数</td>
</tr>
<tr>
<td align="left">orc.row.index.stride</td>
<td align="left">10,000</td>
<td align="left">索引条目之间的行数(必须是&gt;&#x3D; 1000)</td>
</tr>
<tr>
<td align="left">orc.create.index</td>
<td align="left">true</td>
<td align="left">是否创建行索引</td>
</tr>
<tr>
<td align="left">orc.bloom.filter.columns</td>
<td align="left">“”</td>
<td align="left">逗号分隔的列名列表，应该为其创建bloom过滤器</td>
</tr>
<tr>
<td align="left">orc.bloom.filter.fpp</td>
<td align="left">0.05</td>
<td align="left">bloom过滤器的假阳性概率(必须是&gt;0.0和&lt;1.0)</td>
</tr>
</tbody></table>
<p>创建一个非压缩的ORC存储方式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>）建表语句</span><br><span class="line">    <span class="keyword">create</span> <span class="keyword">table</span> log_orc_none(</span><br><span class="line">    track_time string,</span><br><span class="line">    url string,</span><br><span class="line">    session_id string,</span><br><span class="line">    referer string,</span><br><span class="line">    ip string,</span><br><span class="line">    end_user_id string,</span><br><span class="line">    city_id string</span><br><span class="line">    )<span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span> STORED <span class="keyword">AS</span> orc tblproperties (&quot;orc.compress&quot;<span class="operator">=</span>&quot;NONE&quot;);</span><br><span class="line"><span class="number">2</span>）插入数据</span><br><span class="line"> <span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> log_orc_none <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> log_text ;</span><br><span class="line"><span class="number">3</span>）查看插入后数据</span><br><span class="line"> dfs <span class="operator">-</span>du <span class="operator">-</span>h <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>myhive.db<span class="operator">/</span>log_orc_none;</span><br><span class="line"> 结果显示:</span><br><span class="line"> <span class="number">7.7</span> M  <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>log_orc_none<span class="operator">/</span><span class="number">123456</span>_0</span><br></pre></td></tr></table></figure>

<p>创建一个SNAPPY压缩的ORC存储方式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>）建表语句</span><br><span class="line">    <span class="keyword">create</span> <span class="keyword">table</span> log_orc_snappy(</span><br><span class="line">    track_time string,</span><br><span class="line">    url string,</span><br><span class="line">    session_id string,</span><br><span class="line">    referer string,</span><br><span class="line">    ip string,</span><br><span class="line">    end_user_id string,</span><br><span class="line">    city_id string</span><br><span class="line">    )<span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span> STORED <span class="keyword">AS</span> orc tblproperties (&quot;orc.compress&quot;<span class="operator">=</span>&quot;SNAPPY&quot;);</span><br><span class="line"><span class="number">2</span>）插入数据</span><br><span class="line"> <span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> log_orc_snappy <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> log_text ;</span><br><span class="line"><span class="number">3</span>）查看插入后数据</span><br><span class="line"> dfs <span class="operator">-</span>du <span class="operator">-</span>h <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>myhive.db<span class="operator">/</span>log_orc_snappy ;</span><br><span class="line"> 结果显示: </span><br><span class="line"> <span class="number">3.8</span> M  <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>log_orc_snappy<span class="operator">/</span><span class="number">123456</span>_0</span><br><span class="line"><span class="number">4</span>）上一节中默认创建的ORC存储方式，导入数据后的大小为</span><br><span class="line"> <span class="number">2.8</span> M  <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>log_orc<span class="operator">/</span><span class="number">123456</span>_0</span><br><span class="line"> 比Snappy压缩的还小。原因是orc存储文件默认采用ZLIB压缩。比snappy压缩的小。</span><br><span class="line"><span class="number">5</span>）存储方式和压缩总结：</span><br><span class="line"> 在实际的项目开发当中，hive表的数据存储格式一般选择：orc或parquet。压缩方式一般选择snappy。</span><br></pre></td></tr></table></figure>

<h3 id="5-4-主流存储文件性能对比"><a href="#5-4-主流存储文件性能对比" class="headerlink" title="5.4 主流存储文件性能对比"></a>5.4 主流存储文件性能对比</h3><p>从存储文件的压缩比和查询速度两个角度对比。</p>
<p>压缩比比较：</p>
<ul>
<li>TextFile</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">1</span>）创建表，存储数据格式为TEXTFILE</span><br><span class="line">    <span class="keyword">create</span> <span class="keyword">table</span> log_text (</span><br><span class="line">    track_time string,</span><br><span class="line">    url string,</span><br><span class="line">    session_id string,</span><br><span class="line">    referer string,</span><br><span class="line">    ip string,</span><br><span class="line">    end_user_id string,</span><br><span class="line">    city_id string</span><br><span class="line">    )<span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span> STORED <span class="keyword">AS</span> TEXTFILE ;</span><br><span class="line"></span><br><span class="line">（<span class="number">2</span>）向表中加载数据</span><br><span class="line"> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/export/servers/hivedatas/log.data&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> log_text ;</span><br><span class="line"></span><br><span class="line">（<span class="number">3</span>）查看表中数据大小，大小为<span class="number">18.1</span>M</span><br><span class="line"> dfs <span class="operator">-</span>du <span class="operator">-</span>h <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>myhive.db<span class="operator">/</span>log_text;</span><br><span class="line"> 结果显示: </span><br><span class="line"> <span class="number">18.1</span> M  <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>log_text<span class="operator">/</span>log.data</span><br></pre></td></tr></table></figure>

<ul>
<li>ORC</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">1</span>）创建表，存储数据格式为ORC</span><br><span class="line">    <span class="keyword">create</span> <span class="keyword">table</span> log_orc(</span><br><span class="line">    track_time string,</span><br><span class="line">    url string,</span><br><span class="line">    session_id string,</span><br><span class="line">    referer string,</span><br><span class="line">    ip string,</span><br><span class="line">    end_user_id string,</span><br><span class="line">    city_id string</span><br><span class="line">    )<span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span> STORED <span class="keyword">AS</span> orc ;</span><br><span class="line"></span><br><span class="line">（<span class="number">2</span>）向表中加载数据</span><br><span class="line"> <span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> log_orc <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> log_text ;</span><br><span class="line"></span><br><span class="line">（<span class="number">3</span>）查看表中数据大小</span><br><span class="line"> dfs <span class="operator">-</span>du <span class="operator">-</span>h <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>myhive.db<span class="operator">/</span>log_orc;</span><br><span class="line"> 结果显示:</span><br><span class="line"> <span class="number">2.8</span> M  <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>log_orc<span class="operator">/</span><span class="number">123456</span>_0</span><br></pre></td></tr></table></figure>

<ul>
<li>Parquet</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>）创建表，存储数据格式为parquet</span><br><span class="line">    <span class="keyword">create</span> <span class="keyword">table</span> log_parquet(</span><br><span class="line">    track_time string,</span><br><span class="line">    url string,</span><br><span class="line">    session_id string,</span><br><span class="line">    referer string,</span><br><span class="line">    ip string,</span><br><span class="line">    end_user_id string,</span><br><span class="line">    city_id string</span><br><span class="line">    )<span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span> STORED <span class="keyword">AS</span> PARQUET ; </span><br><span class="line"></span><br><span class="line"><span class="number">2</span>）向表中加载数据</span><br><span class="line"> <span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> log_parquet <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> log_text ;</span><br><span class="line"></span><br><span class="line"><span class="number">3</span>）查看表中数据大小</span><br><span class="line"> dfs <span class="operator">-</span>du <span class="operator">-</span>h <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>myhive.db<span class="operator">/</span>log_parquet;</span><br><span class="line"> 结果显示:</span><br><span class="line"> <span class="number">13.1</span> M  <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>log_parquet<span class="operator">/</span><span class="number">123456</span>_0</span><br></pre></td></tr></table></figure>

<p>数据压缩比结论:</p>
<p><strong>ORC &gt;  Parquet &gt;  textFile</strong></p>
<p>存储文件的查询效率测试</p>
<ul>
<li>textFile</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> log_text;</span><br><span class="line">_c0</span><br><span class="line"><span class="number">100000</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">21.54</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)  </span><br></pre></td></tr></table></figure>

<ul>
<li>ORC</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> log_orc;</span><br><span class="line">_c0</span><br><span class="line"><span class="number">100000</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">20.867</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s) </span><br></pre></td></tr></table></figure>

<ul>
<li>Parquet</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> log_parquet; </span><br><span class="line">_c0</span><br><span class="line"><span class="number">100000</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">22.922</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure>

<p>存储文件的查询效率比较:</p>
<p><strong>ORC &gt; TextFile &gt; Parquet</strong></p>
<h2 id="六、Hive-Sql-大全"><a href="#六、Hive-Sql-大全" class="headerlink" title="六、Hive Sql 大全"></a>六、Hive Sql 大全</h2><blockquote>
<p>本节基本涵盖了Hive日常使用的所有SQL，因为SQL太多，所以将SQL进行了如下分类：一、DDL语句（数据定义语句）：<br>对数据库的操作：包含创建、修改数据库<br>对数据表的操作：分为内部表及外部表，分区表和分桶表<br>二、DQL语句（数据查询语句）：<br>单表查询、关联查询<br>hive函数：包含聚合函数，条件函数，日期函数，字符串函数等<br>行转列及列转行：lateral view 与 explode 以及 reflect<br>窗口函数与分析函数<br>其他一些窗口函数</p>
</blockquote>
<h3 id="hive的DDL语法"><a href="#hive的DDL语法" class="headerlink" title="hive的DDL语法"></a>hive的DDL语法</h3><h3 id="对数据库的操作"><a href="#对数据库的操作" class="headerlink" title="对数据库的操作"></a>对数据库的操作</h3><ul>
<li>创建数据库:</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> myhive;</span><br><span class="line">说明：hive的表存放位置模式是由hive<span class="operator">-</span>site.xml当中的一个属性指定的 :hive.metastore.warehouse.dir</span><br><span class="line"></span><br><span class="line">创建数据库并指定hdfs存储位置 :</span><br><span class="line"><span class="keyword">create</span> database myhive2 location <span class="string">&#x27;/myhive2&#x27;</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>修改数据库:</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span>  database  myhive2  <span class="keyword">set</span>  dbproperties(<span class="string">&#x27;createtime&#x27;</span><span class="operator">=</span><span class="string">&#x27;20210329&#x27;</span>);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>说明：可以使用alter  database 命令来修改数据库的一些属性。但是数据库的元数据信息是不可更改的，包括数据库的名称以及数据库所在的位置</p>
</blockquote>
<ul>
<li>查看数据库详细信息</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">查看数据库基本信息</span><br><span class="line">hive (myhive)<span class="operator">&gt;</span> <span class="keyword">desc</span>  database  myhive2;</span><br><span class="line"></span><br><span class="line">查看数据库更多详细信息</span><br><span class="line">hive (myhive)<span class="operator">&gt;</span> <span class="keyword">desc</span> database extended  myhive2;</span><br></pre></td></tr></table></figure>

<ul>
<li>删除数据库</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">删除一个空数据库，如果数据库下面有数据表，那么就会报错</span><br><span class="line"><span class="keyword">drop</span>  database  myhive2;</span><br><span class="line"></span><br><span class="line">强制删除数据库，包含数据库下面的表一起删除</span><br><span class="line"><span class="keyword">drop</span>  database  myhive  cascade; </span><br></pre></td></tr></table></figure>

<h3 id="对数据表的操作"><a href="#对数据表的操作" class="headerlink" title="对数据表的操作"></a>对数据表的操作</h3><h4 id="对管理表-内部表-的操作"><a href="#对管理表-内部表-的操作" class="headerlink" title="对管理表(内部表)的操作:"></a>对管理表(内部表)的操作:</h4><ul>
<li>建内部表:</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (myhive)<span class="operator">&gt;</span> use myhive; <span class="comment">-- 使用myhive数据库</span></span><br><span class="line">hive (myhive)<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> stu(id <span class="type">int</span>,name string);</span><br><span class="line">hive (myhive)<span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> stu <span class="keyword">values</span> (<span class="number">1</span>,&quot;zhangsan&quot;);</span><br><span class="line">hive (myhive)<span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> stu <span class="keyword">values</span> (<span class="number">1</span>,&quot;zhangsan&quot;),(<span class="number">2</span>,&quot;lisi&quot;);  <span class="comment">-- 一次插入多条数据</span></span><br><span class="line">hive (myhive)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu;</span><br></pre></td></tr></table></figure>

<ul>
<li>hive建表时候的字段类型:</li>
</ul>
<table>
<thead>
<tr>
<th align="left"><strong>分类</strong></th>
<th align="left"><strong>类型</strong></th>
<th align="left"><strong>描述</strong></th>
<th align="left"><strong>字面量示例</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left">原始类型</td>
<td align="left">BOOLEAN</td>
<td align="left">true&#x2F;false</td>
<td align="left">TRUE</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">TINYINT</td>
<td align="left">1字节的有符号整数 -128~127</td>
<td align="left">1Y</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">SMALLINT</td>
<td align="left">2个字节的有符号整数，-32768~32767</td>
<td align="left">1S</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>INT</strong></td>
<td align="left">4个字节的带符号整数</td>
<td align="left">1</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">BIGINT</td>
<td align="left">8字节带符号整数</td>
<td align="left">1L</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">FLOAT</td>
<td align="left">4字节单精度浮点数1.0</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"></td>
<td align="left">DOUBLE</td>
<td align="left">8字节双精度浮点数</td>
<td align="left">1.0</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">DEICIMAL</td>
<td align="left">任意精度的带符号小数</td>
<td align="left">1.0</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>STRING</strong></td>
<td align="left">字符串，变长</td>
<td align="left">“a”,’b’</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">VARCHAR</td>
<td align="left">变长字符串</td>
<td align="left">“a”,’b’</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">CHAR</td>
<td align="left">固定长度字符串</td>
<td align="left">“a”,’b’</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">BINARY</td>
<td align="left">字节数组</td>
<td align="left">无法表示</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">TIMESTAMP</td>
<td align="left">时间戳，毫秒值精度</td>
<td align="left">122327493795</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><strong>DATE</strong></td>
<td align="left">日期</td>
<td align="left">‘2016-03-29’</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">INTERVAL</td>
<td align="left">时间频率间隔</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">复杂类型</td>
<td align="left">ARRAY</td>
<td align="left">有序的的同类型的集合</td>
<td align="left">array(1,2)</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">MAP</td>
<td align="left">key-value,key必须为原始类型，value可以任意类型</td>
<td align="left">map(‘a’,1,’b’,2)</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">STRUCT</td>
<td align="left">字段集合,类型可以不同</td>
<td align="left">struct(‘1’,1,1.0), named_stract(‘col1’,’1’,’col2’,1,’clo3’,1.0)</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">UNION</td>
<td align="left">在有限取值范围内的一个值</td>
<td align="left">create_union(1,’a’,63)</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>对decimal类型简单解释下</strong>：<br>用法：decimal(11,2) 代表最多有11位数字，其中后2位是小数，整数部分是9位；如果整数部分超过9位，则这个字段就会变成null；如果小数部分不足2位，则后面用0补齐两位，如果小数部分超过两位，则超出部分四舍五入<br>也可直接写 decimal，后面不指定位数，默认是 decimal(10,0)  整数10位，没有小数</p>
</blockquote>
<ul>
<li>创建表并指定字段之间的分隔符</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span>  <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> stu2(id <span class="type">int</span> ,name string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span> stored <span class="keyword">as</span> textfile location <span class="string">&#x27;/user/stu2&#x27;</span>;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>row format delimited fields terminated by ‘\t’  指定字段分隔符，默认分隔符为 ‘\001’<br>stored as 指定存储格式<br>location 指定存储位置</p>
</blockquote>
<ul>
<li>根据查询结果创建表</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> stu3 <span class="keyword">as</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu2;</span><br></pre></td></tr></table></figure>

<ul>
<li>根据已经存在的表结构创建表</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> stu4 <span class="keyword">like</span> stu2;</span><br></pre></td></tr></table></figure>

<ul>
<li>查询表的结构</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">只查询表内字段及属性</span><br><span class="line"><span class="keyword">desc</span> stu2;</span><br><span class="line"></span><br><span class="line">详细查询</span><br><span class="line"><span class="keyword">desc</span> formatted  stu2;</span><br></pre></td></tr></table></figure>

<ul>
<li>查询创建表的语句</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">create</span> <span class="keyword">table</span> stu2;</span><br></pre></td></tr></table></figure>

<h4 id="对外部表操作"><a href="#对外部表操作" class="headerlink" title="对外部表操作"></a>对外部表操作</h4><blockquote>
<p>外部表因为是指定其他的hdfs路径的数据加载到表当中来，所以hive表会认为自己不完全独占这份数据，所以删除hive表的时候，数据仍然存放在hdfs当中，不会删掉，只会删除表的元数据</p>
</blockquote>
<ul>
<li>构建外部表</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> student (s_id string,s_name string) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>从本地文件系统向表中加载数据</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">追加操作</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/export/servers/hivedatas/student.csv&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> student;</span><br><span class="line"></span><br><span class="line">覆盖操作</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/export/servers/hivedatas/student.csv&#x27;</span> overwrite  <span class="keyword">into</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure>

<ul>
<li>从hdfs文件系统向表中加载数据</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">load data inpath <span class="string">&#x27;/hivedatas/techer.csv&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> techer;</span><br><span class="line"></span><br><span class="line">加载数据到指定分区</span><br><span class="line">load data inpath <span class="string">&#x27;/hivedatas/techer.csv&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> techer <span class="keyword">partition</span>(cur_date<span class="operator">=</span><span class="number">20201210</span>);</span><br></pre></td></tr></table></figure>

<blockquote>
<ul>
<li><strong>注意</strong>：<br>1.使用 load data local 表示从本地文件系统加载，文件会拷贝到hdfs上<br>2.使用 load data 表示从hdfs文件系统加载，文件会直接移动到hive相关目录下，注意不是拷贝过去，因为hive认为hdfs文件已经有3副本了，没必要再次拷贝了<br>3.如果表是分区表，load 时不指定分区会报错<br>4.如果加载相同文件名的文件，会被自动重命名</li>
</ul>
</blockquote>
<h4 id="对分区表的操作"><a href="#对分区表的操作" class="headerlink" title="对分区表的操作"></a>对分区表的操作</h4><ul>
<li>创建分区表的语法</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> score(s_id string, s_score <span class="type">int</span>) partitioned <span class="keyword">by</span> (<span class="keyword">month</span> string);</span><br></pre></td></tr></table></figure>

<ul>
<li>创建一个表带多个分区</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> score2 (s_id string, s_score <span class="type">int</span>) partitioned <span class="keyword">by</span> (<span class="keyword">year</span> string,<span class="keyword">month</span> string,<span class="keyword">day</span> string);</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意：<br>hive表创建的时候可以用 location 指定一个文件或者文件夹，当指定文件夹时，hive会加载文件夹下的所有文件，当表中无分区时，这个文件夹下不能再有文件夹，否则报错<br>当表是分区表时，比如 partitioned by (day string)， 则这个文件夹下的每一个文件夹就是一个分区，且文件夹名为 day&#x3D;20201123 这种格式，然后使用：msck  repair  table  score; 修复表结构，成功之后即可看到数据已经全部加载到表当中去了</strong></p>
</blockquote>
<ul>
<li>加载数据到一个分区的表中</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/export/servers/hivedatas/score.csv&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> score <span class="keyword">partition</span> (<span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201806&#x27;</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li>加载数据到一个多分区的表中去</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/export/servers/hivedatas/score.csv&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> score2 <span class="keyword">partition</span>(<span class="keyword">year</span><span class="operator">=</span><span class="string">&#x27;2018&#x27;</span>,<span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;06&#x27;</span>,<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;01&#x27;</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li>查看分区</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span>  partitions  score;</span><br></pre></td></tr></table></figure>

<ul>
<li>添加一个分区</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> score <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201805&#x27;</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li>同时添加多个分区</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> score <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201804&#x27;</span>) <span class="keyword">partition</span>(<span class="keyword">month</span> <span class="operator">=</span> <span class="string">&#x27;201803&#x27;</span>);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：添加分区之后就可以在hdfs文件系统当中看到表下面多了一个文件夹</p>
</blockquote>
<ul>
<li>删除分区</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> score <span class="keyword">drop</span> <span class="keyword">partition</span>(<span class="keyword">month</span> <span class="operator">=</span> <span class="string">&#x27;201806&#x27;</span>);</span><br></pre></td></tr></table></figure>

<h4 id="对分桶表操作"><a href="#对分桶表操作" class="headerlink" title="对分桶表操作"></a>对分桶表操作</h4><blockquote>
<p>将数据按照指定的字段进行分成多个桶中去，就是按照分桶字段进行哈希划分到多个文件当中去<br>分区就是分文件夹，分桶就是分文件</p>
</blockquote>
<blockquote>
<p>分桶优点：<br>\1. 提高join查询效率<br>\2. 提高抽样效率</p>
</blockquote>
<ul>
<li>开启hive的捅表功能</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.enforce.bucketing<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>设置reduce的个数</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">3</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>创建桶表</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> course (c_id string,c_name string) clustered <span class="keyword">by</span>(c_id) <span class="keyword">into</span> <span class="number">3</span> buckets;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>桶表的数据加载：由于桶表的数据加载通过hdfs  dfs  -put文件或者通过load  data均不可以，只能通过insert  overwrite 进行加载<br>所以把文件加载到桶表中，需要先创建普通表，并通过insert  overwrite的方式将普通表的数据通过查询的方式加载到桶表当中去</p>
</blockquote>
<ul>
<li>通过insert  overwrite给桶表中加载数据</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> course <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> course_common cluster <span class="keyword">by</span>(c_id);  <span class="comment">-- 最后指定桶字段</span></span><br></pre></td></tr></table></figure>

<h4 id="修改表和删除表"><a href="#修改表和删除表" class="headerlink" title="修改表和删除表"></a>修改表和删除表</h4><ul>
<li>修改表名称</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span>  <span class="keyword">table</span>  old_table_name  rename  <span class="keyword">to</span>  new_table_name;</span><br></pre></td></tr></table></figure>

<ul>
<li>增加&#x2F;修改列信息</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">查询表结构</span><br><span class="line"><span class="keyword">desc</span> score5;</span><br><span class="line"></span><br><span class="line">添加列</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> score5 <span class="keyword">add</span> columns (mycol string, mysco string);</span><br><span class="line"></span><br><span class="line">更新列</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> score5 change <span class="keyword">column</span> mysco mysconew <span class="type">int</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>删除表操作</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> score5;</span><br></pre></td></tr></table></figure>

<ul>
<li>清空表操作</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">truncate</span> <span class="keyword">table</span> score6;</span><br><span class="line"></span><br><span class="line">说明：只能清空管理表，也就是内部表；清空外部表，会产生错误</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意：truncate 和 drop：<br>如果 hdfs 开启了回收站，drop 删除的表数据是可以从回收站恢复的，表结构恢复不了，需要自己重新创建；truncate 清空的表是不进回收站的，所以无法恢复truncate清空的表<br>所以 truncate 一定慎用，一旦清空将无力回天</strong></p>
</blockquote>
<h4 id="向hive表中加载数据"><a href="#向hive表中加载数据" class="headerlink" title="向hive表中加载数据"></a>向hive表中加载数据</h4><ul>
<li>直接向分区表中插入数据</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> score <span class="keyword">partition</span>(<span class="keyword">month</span> <span class="operator">=</span><span class="string">&#x27;201807&#x27;</span>) <span class="keyword">values</span> (<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;002&#x27;</span>,<span class="string">&#x27;100&#x27;</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li>通过load方式加载数据</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/export/servers/hivedatas/score.csv&#x27;</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> score <span class="keyword">partition</span>(<span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201806&#x27;</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li>通过查询方式加载数据</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> score2 <span class="keyword">partition</span>(<span class="keyword">month</span> <span class="operator">=</span> <span class="string">&#x27;201806&#x27;</span>) <span class="keyword">select</span> s_id,c_id,s_score <span class="keyword">from</span> score1;</span><br></pre></td></tr></table></figure>

<ul>
<li>查询语句中创建表并加载数据</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> score2 <span class="keyword">as</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> score1;</span><br></pre></td></tr></table></figure>

<ul>
<li>在创建表是通过location指定加载数据的路径</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> score6 (s_id string,c_id string,s_score <span class="type">int</span>) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> location <span class="string">&#x27;/myscore&#x27;</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>export导出与import 导入 hive表数据（内部表操作）</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> techer2 <span class="keyword">like</span> techer; <span class="comment">--依据已有表结构创建表</span></span><br><span class="line"></span><br><span class="line">export <span class="keyword">table</span> techer <span class="keyword">to</span>  <span class="string">&#x27;/export/techer&#x27;</span>;</span><br><span class="line"></span><br><span class="line">import <span class="keyword">table</span> techer2 <span class="keyword">from</span> <span class="string">&#x27;/export/techer&#x27;</span>;</span><br></pre></td></tr></table></figure>

<h4 id="hive表中数据导出"><a href="#hive表中数据导出" class="headerlink" title="hive表中数据导出"></a>hive表中数据导出</h4><ul>
<li>insert导出</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">将查询的结果导出到本地</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/export/servers/exporthive&#x27;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> score;</span><br><span class="line"></span><br><span class="line">将查询的结果格式化导出到本地</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/export/servers/exporthive&#x27;</span> <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span> collection items terminated <span class="keyword">by</span> <span class="string">&#x27;#&#x27;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br><span class="line"></span><br><span class="line">将查询的结果导出到HDFS上(没有<span class="keyword">local</span>)</span><br><span class="line"><span class="keyword">insert</span> overwrite directory <span class="string">&#x27;/export/servers/exporthive&#x27;</span> <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span> collection items terminated <span class="keyword">by</span> <span class="string">&#x27;#&#x27;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> score;</span><br></pre></td></tr></table></figure>

<ul>
<li>Hadoop命令导出到本地</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfs <span class="operator">-</span><span class="keyword">get</span> <span class="operator">/</span>export<span class="operator">/</span>servers<span class="operator">/</span>exporthive<span class="operator">/</span><span class="number">000000</span>_0 <span class="operator">/</span>export<span class="operator">/</span>servers<span class="operator">/</span>exporthive<span class="operator">/</span>local.txt;</span><br></pre></td></tr></table></figure>

<ul>
<li>hive shell 命令导出</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">基本语法：（hive <span class="operator">-</span>f<span class="operator">/</span><span class="operator">-</span>e 执行语句或者脚本 <span class="operator">&gt;</span> file）</span><br><span class="line"></span><br><span class="line">hive <span class="operator">-</span>e &quot;select * from myhive.score;&quot; <span class="operator">&gt;</span> <span class="operator">/</span>export<span class="operator">/</span>servers<span class="operator">/</span>exporthive<span class="operator">/</span>score.txt</span><br><span class="line"></span><br><span class="line">hive <span class="operator">-</span>f export.sh <span class="operator">&gt;</span> <span class="operator">/</span>export<span class="operator">/</span>servers<span class="operator">/</span>exporthive<span class="operator">/</span>score.txt</span><br></pre></td></tr></table></figure>

<ul>
<li>export导出到HDFS上</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export <span class="keyword">table</span> score <span class="keyword">to</span> <span class="string">&#x27;/export/exporthive/score&#x27;</span>;</span><br></pre></td></tr></table></figure>

<h3 id="hive的DQL查询语法"><a href="#hive的DQL查询语法" class="headerlink" title="hive的DQL查询语法"></a>hive的DQL查询语法</h3><h3 id="单表查询"><a href="#单表查询" class="headerlink" title="单表查询"></a>单表查询</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>] select_expr, select_expr, ... </span><br><span class="line"><span class="keyword">FROM</span> table_reference</span><br><span class="line">[<span class="keyword">WHERE</span> where_condition] </span><br><span class="line">[<span class="keyword">GROUP</span> <span class="keyword">BY</span> col_list [<span class="keyword">HAVING</span> <span class="keyword">condition</span>]] </span><br><span class="line">[CLUSTER <span class="keyword">BY</span> col_list </span><br><span class="line">  <span class="operator">|</span> [DISTRIBUTE <span class="keyword">BY</span> col_list] [SORT <span class="keyword">BY</span><span class="operator">|</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> col_list] </span><br><span class="line">] </span><br><span class="line">[LIMIT number]</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：<br>1、order by 会对输入做全局排序，因此只有一个reducer，会导致当输入规模较大时，需要较长的计算时间。<br>2、sort by不是全局排序，其在数据进入reducer前完成排序。因此，如果用sort by进行排序，并且设置mapred.reduce.tasks&gt;1，则sort by只保证每个reducer的输出有序，不保证全局有序。<br>3、distribute by(字段)根据指定的字段将数据分到不同的reducer，且分发算法是hash散列。<br>4、Cluster by(字段) 除了具有Distribute by的功能外，还会对该字段进行排序。<br>因此，如果分桶和sort字段是同一个时，此时，cluster by &#x3D; distribute by + sort by</p>
</blockquote>
<ul>
<li>WHERE语句</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> score <span class="keyword">where</span> s_score <span class="operator">&lt;</span> <span class="number">60</span>;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：<br>小于某个值是不包含null的，如上查询结果是把 s_score 为 null 的行剔除的</p>
</blockquote>
<ul>
<li>GROUP BY 分组</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> s_id ,<span class="built_in">avg</span>(s_score) <span class="keyword">from</span> score <span class="keyword">group</span> <span class="keyword">by</span> s_id;</span><br><span class="line"></span><br><span class="line">分组后对数据进行筛选，使用<span class="keyword">having</span></span><br><span class="line"> <span class="keyword">select</span> s_id ,<span class="built_in">avg</span>(s_score) avgscore <span class="keyword">from</span> score <span class="keyword">group</span> <span class="keyword">by</span> s_id <span class="keyword">having</span> avgscore <span class="operator">&gt;</span> <span class="number">85</span>;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：<br>如果使用 group by 分组，则 select 后面只能写分组的字段或者聚合函数<br>where和having区别：<br>1 having是在 group by 分完组之后再对数据进行筛选，所以having 要筛选的字段只能是分组字段或者聚合函数<br>2 where 是从数据表中的字段直接进行的筛选的，所以不能跟在gruop by后面，也不能使用聚合函数</p>
</blockquote>
<ul>
<li>join 连接</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INNER</span> <span class="keyword">JOIN</span> 内连接：只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> techer t [<span class="keyword">inner</span>] <span class="keyword">join</span> course c <span class="keyword">on</span> t.t_id <span class="operator">=</span> c.t_id; <span class="comment">-- inner 可省略</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> 左外连接：左边所有数据会被返回，右边符合条件的被返回</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> techer t <span class="keyword">left</span> <span class="keyword">join</span> course c <span class="keyword">on</span> t.t_id <span class="operator">=</span> c.t_id; <span class="comment">-- outer可省略</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RIGHT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> 右外连接：右边所有数据会被返回，左边符合条件的被返回、</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> techer t <span class="keyword">right</span> <span class="keyword">join</span> course c <span class="keyword">on</span> t.t_id <span class="operator">=</span> c.t_id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">FULL</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> 满外(全外)连接: 将会返回所有表中符合条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用<span class="keyword">NULL</span>值替代。</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> techer t <span class="keyword">FULL</span> <span class="keyword">JOIN</span> course c <span class="keyword">ON</span> t.t_id <span class="operator">=</span> c.t_id ;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：1. hive2版本已经支持不等值连接，就是 join on条件后面可以使用大于小于符号了;并且也支持 join on 条件后跟or (早前版本 on 后只支持 &#x3D; 和 and，不支持 &gt; &lt; 和 or)<br>2.如hive执行引擎使用MapReduce，一个join就会启动一个job，一条sql语句中如有多个join，则会启动多个job</p>
</blockquote>
<blockquote>
<p>注意：表之间用逗号(,)连接和 inner join 是一样的<br>select * from table_a,table_b where table_a.id&#x3D;table_b.id;<br>它们的执行效率没有区别，只是书写方式不同，用逗号是sql 89标准，join 是sql 92标准。用逗号连接后面过滤条件用 where ，用 join 连接后面过滤条件是 on。</p>
</blockquote>
<ul>
<li>order by 排序</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">全局排序，只会有一个reduce</span><br><span class="line"><span class="keyword">ASC</span>（ascend）: 升序（默认） <span class="keyword">DESC</span>（descend）: 降序</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> student s <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> score sco <span class="keyword">ON</span> s.s_id <span class="operator">=</span> sco.s_id <span class="keyword">ORDER</span> <span class="keyword">BY</span> sco.s_score <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：order by 是全局排序，所以最后只有一个reduce，也就是在一个节点执行，如果数据量太大，就会耗费较长时间</p>
</blockquote>
<ul>
<li>sort by 局部排序</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">每个MapReduce内部进行排序，对全局结果集来说不是排序。</span><br><span class="line"></span><br><span class="line">设置reduce个数</span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">查看设置reduce个数</span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces;</span><br><span class="line"></span><br><span class="line">查询成绩按照成绩降序排列</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> score sort <span class="keyword">by</span> s_score;</span><br><span class="line"></span><br><span class="line">将查询结果导入到文件中（按照成绩降序排列）</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/export/servers/hivedatas/sort&#x27;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> score sort <span class="keyword">by</span> s_score;</span><br></pre></td></tr></table></figure>

<ul>
<li>distribute by  分区排序</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">distribute <span class="keyword">by</span>：类似MR中<span class="keyword">partition</span>，进行分区，结合sort <span class="keyword">by</span>使用</span><br><span class="line"></span><br><span class="line">设置reduce的个数，将我们对应的s_id划分到对应的reduce当中去</span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">7</span>;</span><br><span class="line"></span><br><span class="line">通过distribute <span class="keyword">by</span>  进行数据的分区</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> score distribute <span class="keyword">by</span> s_id sort <span class="keyword">by</span> s_score;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：Hive要求 distribute by 语句要写在 sort by 语句之前</p>
</blockquote>
<ul>
<li>cluster by</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">当distribute <span class="keyword">by</span>和sort <span class="keyword">by</span>字段相同时，可以使用cluster <span class="keyword">by</span>方式.</span><br><span class="line">cluster <span class="keyword">by</span>除了具有distribute <span class="keyword">by</span>的功能外还兼具sort <span class="keyword">by</span>的功能。但是排序只能是正序排序，不能指定排序规则为<span class="keyword">ASC</span>或者<span class="keyword">DESC</span>。</span><br><span class="line"></span><br><span class="line">以下两种写法等价</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> score cluster <span class="keyword">by</span> s_id;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> score distribute <span class="keyword">by</span> s_id sort <span class="keyword">by</span> s_id;</span><br></pre></td></tr></table></figure>

<h2 id="Hive函数"><a href="#Hive函数" class="headerlink" title="Hive函数"></a>Hive函数</h2><h3 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive支持 <span class="built_in">count</span>(),<span class="built_in">max</span>(),<span class="built_in">min</span>(),<span class="built_in">sum</span>(),<span class="built_in">avg</span>() 等常用的聚合函数</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：<br>聚合操作时要注意null值<br>count(*) 包含null值，统计所有行数<br>count(id) 不包含null值<br>min 求最小值是不包含null，除非所有值都是null<br>avg 求平均值也是不包含null</p>
</blockquote>
<ul>
<li>非空集合总体变量函数: var_pop</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="built_in">var_pop</span>(col)</span><br><span class="line">返回值: <span class="keyword">double</span></span><br><span class="line">说明: 统计结果集中col非空集合的总体变量（忽略<span class="keyword">null</span>）</span><br></pre></td></tr></table></figure>

<ul>
<li>非空集合样本变量函数: var_samp</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="built_in">var_samp</span> (col)</span><br><span class="line">返回值: <span class="keyword">double</span></span><br><span class="line">说明: 统计结果集中col非空集合的样本变量（忽略<span class="keyword">null</span>）</span><br></pre></td></tr></table></figure>

<ul>
<li>总体标准偏离函数: stddev_pop</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="built_in">stddev_pop</span>(col)</span><br><span class="line">返回值: <span class="keyword">double</span></span><br><span class="line">说明: 该函数计算总体标准偏离，并返回总体变量的平方根，其返回值与VAR_POP函数的平方根相同</span><br></pre></td></tr></table></figure>

<ul>
<li>中位数函数: percentile</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法: percentile(<span class="type">BIGINT</span> col, p)</span><br><span class="line">返回值: <span class="keyword">double</span></span><br><span class="line">说明: 求准确的第pth个百分位数，p必须介于<span class="number">0</span>和<span class="number">1</span>之间，但是col字段目前只支持整数，不支持浮点数类型</span><br></pre></td></tr></table></figure>

<h3 id="关系运算"><a href="#关系运算" class="headerlink" title="关系运算"></a>关系运算</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">支持：等值(<span class="operator">=</span>)、不等值(<span class="operator">!=</span> 或 <span class="operator">&lt;&gt;</span>)、小于(<span class="operator">&lt;</span>)、小于等于(<span class="operator">&lt;=</span>)、大于(<span class="operator">&gt;</span>)、大于等于(<span class="operator">&gt;=</span>)</span><br><span class="line"></span><br><span class="line">空值判断(<span class="keyword">is</span> <span class="keyword">null</span>)、非空判断(<span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>LIKE比较: LIKE</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法: A <span class="keyword">LIKE</span> B</span><br><span class="line">操作类型: strings</span><br><span class="line">描述: 如果字符串A或者字符串B为<span class="keyword">NULL</span>，则返回<span class="keyword">NULL</span>；如果字符串A符合表达式B 的正则语法，则为<span class="literal">TRUE</span>；否则为<span class="literal">FALSE</span>。B中字符”_”表示任意单个字符，而字符”<span class="operator">%</span>”表示任意数量的字符。</span><br></pre></td></tr></table></figure>

<ul>
<li>JAVA的LIKE操作: RLIKE</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法: A RLIKE B</span><br><span class="line">操作类型: strings</span><br><span class="line">描述: 如果字符串A或者字符串B为<span class="keyword">NULL</span>，则返回<span class="keyword">NULL</span>；如果字符串A符合JAVA正则表达式B的正则语法，则为<span class="literal">TRUE</span>；否则为<span class="literal">FALSE</span>。</span><br></pre></td></tr></table></figure>

<ul>
<li>REGEXP操作: REGEXP</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: A REGEXP B</span><br><span class="line">操作类型: strings</span><br><span class="line">描述: 功能与RLIKE相同</span><br><span class="line">示例：<span class="keyword">select</span> <span class="number">1</span> <span class="keyword">from</span> tableName <span class="keyword">where</span> <span class="string">&#x27;footbar&#x27;</span> REGEXP <span class="string">&#x27;^f.*r$&#x27;</span>;</span><br><span class="line">结果：<span class="number">1</span></span><br></pre></td></tr></table></figure>

<h3 id="数学运算"><a href="#数学运算" class="headerlink" title="数学运算"></a>数学运算</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">支持所有数值类型：加(<span class="operator">+</span>)、减(<span class="operator">-</span>)、乘(<span class="operator">*</span>)、除(<span class="operator">/</span>)、取余(<span class="operator">%</span>)、位与(<span class="operator">&amp;</span>)、位或(<span class="operator">|</span>)、位异或(<span class="operator">^</span>)、位取反(<span class="operator">~</span>)</span><br></pre></td></tr></table></figure>

<h3 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">支持：逻辑与(<span class="keyword">and</span>)、逻辑或(<span class="keyword">or</span>)、逻辑非(<span class="keyword">not</span>)</span><br></pre></td></tr></table></figure>

<h3 id="数值运算"><a href="#数值运算" class="headerlink" title="数值运算"></a>数值运算</h3><ul>
<li>取整函数: round</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: round(<span class="keyword">double</span> a)</span><br><span class="line">返回值: <span class="type">BIGINT</span></span><br><span class="line">说明: 返回<span class="keyword">double</span>类型的整数值部分 （遵循四舍五入）</span><br><span class="line">示例：<span class="keyword">select</span> round(<span class="number">3.1415926</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">结果：<span class="number">3</span></span><br></pre></td></tr></table></figure>

<ul>
<li>指定精度取整函数: round</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: round(<span class="keyword">double</span> a, <span class="type">int</span> d)</span><br><span class="line">返回值: <span class="keyword">DOUBLE</span></span><br><span class="line">说明: 返回指定精度d的<span class="keyword">double</span>类型</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> round(<span class="number">3.1415926</span>,<span class="number">4</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">3.1416</span></span><br></pre></td></tr></table></figure>

<ul>
<li>向下取整函数: floor</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="built_in">floor</span>(<span class="keyword">double</span> a)</span><br><span class="line">返回值: <span class="type">BIGINT</span></span><br><span class="line">说明: 返回等于或者小于该<span class="keyword">double</span>变量的最大的整数</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">floor</span>(<span class="number">3.641</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure>

<ul>
<li>向上取整函数: ceil</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="built_in">ceil</span>(<span class="keyword">double</span> a)</span><br><span class="line">返回值: <span class="type">BIGINT</span></span><br><span class="line">说明: 返回等于或者大于该<span class="keyword">double</span>变量的最小的整数</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">ceil</span>(<span class="number">3.1415926</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure>

<ul>
<li>取随机数函数: rand</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">语法: rand(),rand(<span class="type">int</span> seed)</span><br><span class="line">返回值: <span class="keyword">double</span></span><br><span class="line">说明: 返回一个<span class="number">0</span>到<span class="number">1</span>范围内的随机数。如果指定种子seed，则会等到一个稳定的随机数序列</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> rand() <span class="keyword">from</span> tableName; <span class="comment">-- 每次执行此语句得到的结果都不同</span></span><br><span class="line"><span class="number">0.5577432776034763</span></span><br><span class="line"></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> rand(<span class="number">100</span>) ;  <span class="comment">-- 只要指定种子，每次执行此语句得到的结果一样的</span></span><br><span class="line"><span class="number">0.7220096548596434</span></span><br></pre></td></tr></table></figure>

<ul>
<li>自然指数函数: exp</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="built_in">exp</span>(<span class="keyword">double</span> a)</span><br><span class="line">返回值: <span class="keyword">double</span></span><br><span class="line">说明: 返回自然对数e的a次方</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">exp</span>(<span class="number">2</span>) ;</span><br><span class="line"><span class="number">7.38905609893065</span></span><br></pre></td></tr></table></figure>

<ul>
<li>以10为底对数函数: log10</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="built_in">log10</span>(<span class="keyword">double</span> a)</span><br><span class="line">返回值: <span class="keyword">double</span></span><br><span class="line">说明: 返回以<span class="number">10</span>为底的a的对数</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">log10</span>(<span class="number">100</span>) ;</span><br><span class="line"><span class="number">2.0</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>此外还有：以2为底对数函数: log2()、对数函数: log()</p>
</blockquote>
<ul>
<li>幂运算函数: pow</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: pow(<span class="keyword">double</span> a, <span class="keyword">double</span> p)</span><br><span class="line">返回值: <span class="keyword">double</span></span><br><span class="line">说明: 返回a的p次幂</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> pow(<span class="number">2</span>,<span class="number">4</span>) ;</span><br><span class="line"><span class="number">16.0</span></span><br></pre></td></tr></table></figure>

<ul>
<li>开平方函数: sqrt</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="built_in">sqrt</span>(<span class="keyword">double</span> a)</span><br><span class="line">返回值: <span class="keyword">double</span></span><br><span class="line">说明: 返回a的平方根</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">sqrt</span>(<span class="number">16</span>) ;</span><br><span class="line"><span class="number">4.0</span></span><br></pre></td></tr></table></figure>

<ul>
<li>二进制函数: bin</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: bin(<span class="type">BIGINT</span> a)</span><br><span class="line">返回值: string</span><br><span class="line">说明: 返回a的二进制代码表示</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> bin(<span class="number">7</span>) ;</span><br><span class="line"><span class="number">111</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>十六进制函数: hex()、将十六进制转化为字符串函数: unhex()<br>进制转换函数: conv(bigint num, int from_base, int to_base) 说明: 将数值num从from_base进制转化到to_base进制</p>
</blockquote>
<blockquote>
<p>此外还有很多数学函数：绝对值函数: abs()、正取余函数: pmod()、正弦函数: sin()、反正弦函数: asin()、余弦函数: cos()、反余弦函数: acos()、positive函数: positive()、negative函数: negative()</p>
</blockquote>
<h3 id="条件函数"><a href="#条件函数" class="headerlink" title="条件函数"></a>条件函数</h3><ul>
<li>If函数: if</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: if(<span class="type">boolean</span> testCondition, T valueTrue, T valueFalseOrNull)</span><br><span class="line">返回值: T</span><br><span class="line">说明: 当条件testCondition为<span class="literal">TRUE</span>时，返回valueTrue；否则返回valueFalseOrNull</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> if(<span class="number">1</span><span class="operator">=</span><span class="number">2</span>,<span class="number">100</span>,<span class="number">200</span>) ;</span><br><span class="line"><span class="number">200</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> if(<span class="number">1</span><span class="operator">=</span><span class="number">1</span>,<span class="number">100</span>,<span class="number">200</span>) ;</span><br><span class="line"><span class="number">100</span></span><br></pre></td></tr></table></figure>

<ul>
<li>非空查找函数: coalesce</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="built_in">coalesce</span>(T v1, T v2, …)</span><br><span class="line">返回值: T</span><br><span class="line">说明: 返回参数中的第一个非空值；如果所有值都为<span class="keyword">NULL</span>，那么返回<span class="keyword">NULL</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">coalesce</span>(<span class="keyword">null</span>,<span class="string">&#x27;100&#x27;</span>,<span class="string">&#x27;50&#x27;</span>) ;</span><br><span class="line"><span class="number">100</span></span><br></pre></td></tr></table></figure>

<ul>
<li>条件判断函数：case when (两种写法，其一)</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="keyword">case</span> <span class="keyword">when</span> a <span class="keyword">then</span> b [<span class="keyword">when</span> c <span class="keyword">then</span> d]<span class="operator">*</span> [<span class="keyword">else</span> e] <span class="keyword">end</span></span><br><span class="line">返回值: T</span><br><span class="line">说明：如果a为<span class="literal">TRUE</span>,则返回b；如果c为<span class="literal">TRUE</span>，则返回d；否则返回e</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="keyword">case</span> <span class="keyword">when</span> <span class="number">1</span><span class="operator">=</span><span class="number">2</span> <span class="keyword">then</span> <span class="string">&#x27;tom&#x27;</span> <span class="keyword">when</span> <span class="number">2</span><span class="operator">=</span><span class="number">2</span> <span class="keyword">then</span> <span class="string">&#x27;mary&#x27;</span> <span class="keyword">else</span> <span class="string">&#x27;tim&#x27;</span> <span class="keyword">end</span> <span class="keyword">from</span> tableName;</span><br><span class="line">mary</span><br></pre></td></tr></table></figure>

<ul>
<li>条件判断函数：case when (两种写法，其二)</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="keyword">case</span> a <span class="keyword">when</span> b <span class="keyword">then</span> c [<span class="keyword">when</span> d <span class="keyword">then</span> e]<span class="operator">*</span> [<span class="keyword">else</span> f] <span class="keyword">end</span></span><br><span class="line">返回值: T</span><br><span class="line">说明：如果a等于b，那么返回c；如果a等于d，那么返回e；否则返回f</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">Select</span> <span class="keyword">case</span> <span class="number">100</span> <span class="keyword">when</span> <span class="number">50</span> <span class="keyword">then</span> <span class="string">&#x27;tom&#x27;</span> <span class="keyword">when</span> <span class="number">100</span> <span class="keyword">then</span> <span class="string">&#x27;mary&#x27;</span> <span class="keyword">else</span> <span class="string">&#x27;tim&#x27;</span> <span class="keyword">end</span> <span class="keyword">from</span> tableName;</span><br><span class="line">mary</span><br></pre></td></tr></table></figure>

<h3 id="日期函数"><a href="#日期函数" class="headerlink" title="日期函数"></a>日期函数</h3><blockquote>
<p>注：以下SQL语句中的 from tableName 可去掉，不影响查询结果</p>
</blockquote>
<p>- </p>
<ul>
<li><ol>
<li>获取当前UNIX时间戳函数: unix_timestamp</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: unix_timestamp()</span><br><span class="line">返回值: <span class="type">bigint</span></span><br><span class="line">说明: 获得当前时区的UNIX时间戳</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> unix_timestamp() <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">1616906976</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>UNIX时间戳转日期函数: from_unixtime</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: from_unixtime(<span class="type">bigint</span> unixtime[, string format])</span><br><span class="line">返回值: string</span><br><span class="line">说明: 转化UNIX时间戳（从<span class="number">1970</span><span class="number">-01</span><span class="number">-01</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> UTC到指定时间的秒数）到当前时区的时间格式</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> from_unixtime(<span class="number">1616906976</span>,<span class="string">&#x27;yyyyMMdd&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">20210328</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>日期转UNIX时间戳函数: unix_timestamp</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: unix_timestamp(string <span class="type">date</span>)</span><br><span class="line">返回值: <span class="type">bigint</span></span><br><span class="line">说明: 转换格式为&quot;yyyy-MM-dd HH:mm:ss&quot;的日期到UNIX时间戳。如果转化失败，则返回<span class="number">0</span>。</span><br><span class="line">hive<span class="operator">&gt;</span>  <span class="keyword">select</span> unix_timestamp(<span class="string">&#x27;2021-03-08 14:21:15&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">1615184475</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>指定格式日期转UNIX时间戳函数: unix_timestamp</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: unix_timestamp(string <span class="type">date</span>, string <span class="keyword">pattern</span>)</span><br><span class="line">返回值: <span class="type">bigint</span></span><br><span class="line">说明: 转换<span class="keyword">pattern</span>格式的日期到UNIX时间戳。如果转化失败，则返回<span class="number">0</span>。</span><br><span class="line">hive<span class="operator">&gt;</span>  <span class="keyword">select</span> unix_timestamp(<span class="string">&#x27;2021-03-08 14:21:15&#x27;</span>,<span class="string">&#x27;yyyyMMdd HH:mm:ss&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">1615184475</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>日期时间转日期函数: to_date</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: to_date(string <span class="type">timestamp</span>)</span><br><span class="line">返回值: string</span><br><span class="line">说明: 返回日期时间字段中的日期部分。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> to_date(<span class="string">&#x27;2021-03-28 14:03:01&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">2021</span><span class="number">-03</span><span class="number">-28</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>日期转年函数: year</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="keyword">year</span>(string <span class="type">date</span>)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明: 返回日期中的年。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="keyword">year</span>(<span class="string">&#x27;2021-03-28 10:03:01&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">2021</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="keyword">year</span>(<span class="string">&#x27;2021-03-28&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">2021</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>日期转月函数: month</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="keyword">month</span> (string <span class="type">date</span>)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明: 返回日期中的月份。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="keyword">month</span>(<span class="string">&#x27;2020-12-28 12:03:01&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">12</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="keyword">month</span>(<span class="string">&#x27;2021-03-08&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>日期转天函数: day</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="keyword">day</span> (string <span class="type">date</span>)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明: 返回日期中的天。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="keyword">day</span>(<span class="string">&#x27;2020-12-08 10:03:01&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">8</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="keyword">day</span>(<span class="string">&#x27;2020-12-24&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">24</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>日期转小时函数: hour</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="keyword">hour</span> (string <span class="type">date</span>)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明: 返回日期中的小时。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="keyword">hour</span>(<span class="string">&#x27;2020-12-08 10:03:01&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>日期转分钟函数: minute</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="keyword">minute</span> (string <span class="type">date</span>)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明: 返回日期中的分钟。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="keyword">minute</span>(<span class="string">&#x27;2020-12-08 10:03:01&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>日期转秒函数: second</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="keyword">second</span> (string <span class="type">date</span>)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明: 返回日期中的秒。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="keyword">second</span>(<span class="string">&#x27;2020-12-08 10:03:01&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>日期转周函数: weekofyear</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: weekofyear (string <span class="type">date</span>)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明: 返回日期在当前的周数。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> weekofyear(<span class="string">&#x27;2020-12-08 10:03:01&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">49</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>日期比较函数: datediff</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: datediff(string enddate, string startdate)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明: 返回结束日期减去开始日期的天数。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> datediff(<span class="string">&#x27;2020-12-08&#x27;</span>,<span class="string">&#x27;2012-05-09&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">213</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>日期增加函数: date_add</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: date_add(string startdate, <span class="type">int</span> days)</span><br><span class="line">返回值: string</span><br><span class="line">说明: 返回开始日期startdate增加days天后的日期。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> date_add(<span class="string">&#x27;2020-12-08&#x27;</span>,<span class="number">10</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">2020</span><span class="number">-12</span><span class="number">-18</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>日期减少函数: date_sub</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: date_sub (string startdate, <span class="type">int</span> days)</span><br><span class="line">返回值: string</span><br><span class="line">说明: 返回开始日期startdate减少days天后的日期。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> date_sub(<span class="string">&#x27;2020-12-08&#x27;</span>,<span class="number">10</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">2020</span><span class="number">-11</span><span class="number">-28</span></span><br></pre></td></tr></table></figure>

<h3 id="字符串函数"><a href="#字符串函数" class="headerlink" title="字符串函数"></a>字符串函数</h3><p>- </p>
<ul>
<li><ol>
<li>字符串长度函数：length</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: length(string A)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明：返回字符串A的长度</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> length(<span class="string">&#x27;abcedfg&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">7</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>字符串反转函数：reverse</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: reverse(string A)</span><br><span class="line">返回值: string</span><br><span class="line">说明：返回字符串A的反转结果</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> reverse(<span class="string">&#x27;abcedfg&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">gfdecba</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>字符串连接函数：concat</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: concat(string A, string B…)</span><br><span class="line">返回值: string</span><br><span class="line">说明：返回输入字符串连接后的结果，支持任意个输入字符串</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> concat(<span class="string">&#x27;abc&#x27;</span>,<span class="string">&#x27;def’,&#x27;</span>gh<span class="string">&#x27;)from tableName;</span></span><br><span class="line"><span class="string">abcdefgh</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>带分隔符字符串连接函数：concat_ws</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: concat_ws(string SEP, string A, string B…)</span><br><span class="line">返回值: string</span><br><span class="line">说明：返回输入字符串连接后的结果，SEP表示各个字符串间的分隔符</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> concat_ws(<span class="string">&#x27;,&#x27;</span>,<span class="string">&#x27;abc&#x27;</span>,<span class="string">&#x27;def&#x27;</span>,<span class="string">&#x27;gh&#x27;</span>)<span class="keyword">from</span> tableName;</span><br><span class="line">abc,def,gh</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>字符串截取函数：substr,substring</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">语法: substr(string A, <span class="type">int</span> <span class="keyword">start</span>),<span class="built_in">substring</span>(string A, <span class="type">int</span> <span class="keyword">start</span>)</span><br><span class="line">返回值: string</span><br><span class="line">说明：返回字符串A从<span class="keyword">start</span>位置到结尾的字符串</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> substr(<span class="string">&#x27;abcde&#x27;</span>,<span class="number">3</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">cde</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">substring</span>(<span class="string">&#x27;abcde&#x27;</span>,<span class="number">3</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">cde</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> substr(<span class="string">&#x27;abcde&#x27;</span>,<span class="number">-1</span>) <span class="keyword">from</span> tableName; （和ORACLE相同）</span><br><span class="line">e</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>字符串截取函数：substr,substring</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">语法: substr(string A, <span class="type">int</span> <span class="keyword">start</span>, <span class="type">int</span> len),<span class="built_in">substring</span>(string A, <span class="type">int</span> <span class="keyword">start</span>, <span class="type">int</span> len)</span><br><span class="line">返回值: string</span><br><span class="line">说明：返回字符串A从<span class="keyword">start</span>位置开始，长度为len的字符串</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> substr(<span class="string">&#x27;abcde&#x27;</span>,<span class="number">3</span>,<span class="number">2</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">cd</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">substring</span>(<span class="string">&#x27;abcde&#x27;</span>,<span class="number">3</span>,<span class="number">2</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">cd</span><br><span class="line">hive<span class="operator">&gt;</span><span class="keyword">select</span> <span class="built_in">substring</span>(<span class="string">&#x27;abcde&#x27;</span>,<span class="number">-2</span>,<span class="number">2</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">de</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>字符串转大写函数：upper,ucase</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="built_in">upper</span>(string A) ucase(string A)</span><br><span class="line">返回值: string</span><br><span class="line">说明：返回字符串A的大写格式</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">upper</span>(<span class="string">&#x27;abSEd&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">ABSED</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> ucase(<span class="string">&#x27;abSEd&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">ABSED</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>字符串转小写函数：lower,lcase</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="built_in">lower</span>(string A) lcase(string A)</span><br><span class="line">返回值: string</span><br><span class="line">说明：返回字符串A的小写格式</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">lower</span>(<span class="string">&#x27;abSEd&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">absed</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> lcase(<span class="string">&#x27;abSEd&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">absed</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>去空格函数：trim</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="built_in">trim</span>(string A)</span><br><span class="line">返回值: string</span><br><span class="line">说明：去除字符串两边的空格</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">trim</span>(<span class="string">&#x27; abc &#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">abc</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>左边去空格函数：ltrim</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: ltrim(string A)</span><br><span class="line">返回值: string</span><br><span class="line">说明：去除字符串左边的空格</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> ltrim(<span class="string">&#x27; abc &#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">abc</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>右边去空格函数：rtrim</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: rtrim(string A)</span><br><span class="line">返回值: string</span><br><span class="line">说明：去除字符串右边的空格</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> rtrim(<span class="string">&#x27; abc &#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">abc</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>正则表达式替换函数：regexp_replace</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: regexp_replace(string A, string B, string C)</span><br><span class="line">返回值: string</span><br><span class="line">说明：将字符串A中的符合java正则表达式B的部分替换为C。注意，在有些情况下要使用转义字符,类似oracle中的regexp_replace函数。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> regexp_replace(<span class="string">&#x27;foobar&#x27;</span>, <span class="string">&#x27;oo|ar&#x27;</span>, <span class="string">&#x27;&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">fb</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>正则表达式解析函数：regexp_extract</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">语法: regexp_extract(string subject, string <span class="keyword">pattern</span>, <span class="type">int</span> index)</span><br><span class="line">返回值: string</span><br><span class="line">说明：将字符串subject按照<span class="keyword">pattern</span>正则表达式的规则拆分，返回index指定的字符。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> regexp_extract(<span class="string">&#x27;foothebar&#x27;</span>, <span class="string">&#x27;foo(.*?)(bar)&#x27;</span>, <span class="number">1</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">the</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> regexp_extract(<span class="string">&#x27;foothebar&#x27;</span>, <span class="string">&#x27;foo(.*?)(bar)&#x27;</span>, <span class="number">2</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">bar</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> regexp_extract(<span class="string">&#x27;foothebar&#x27;</span>, <span class="string">&#x27;foo(.*?)(bar)&#x27;</span>, <span class="number">0</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">foothebar</span><br><span class="line">strong<span class="operator">&gt;</span>注意，在有些情况下要使用转义字符，下面的等号要用双竖线转义，这是java正则表达式的规则。</span><br><span class="line"><span class="keyword">select</span> data_field,</span><br><span class="line">regexp_extract(data_field,<span class="string">&#x27;.*?bgStart\\=([^&amp;]+)&#x27;</span>,<span class="number">1</span>) <span class="keyword">as</span> aaa,</span><br><span class="line">regexp_extract(data_field,<span class="string">&#x27;.*?contentLoaded_headStart\\=([^&amp;]+)&#x27;</span>,<span class="number">1</span>) <span class="keyword">as</span> bbb,</span><br><span class="line">regexp_extract(data_field,<span class="string">&#x27;.*?AppLoad2Req\\=([^&amp;]+)&#x27;</span>,<span class="number">1</span>) <span class="keyword">as</span> ccc </span><br><span class="line"><span class="keyword">from</span> pt_nginx_loginlog_st </span><br><span class="line"><span class="keyword">where</span> pt <span class="operator">=</span> <span class="string">&#x27;2021-03-28&#x27;</span> limit <span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>URL解析函数：parse_url</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">语法: parse_url(string urlString, string partToExtract [, string keyToExtract])</span><br><span class="line">返回值: string</span><br><span class="line">说明：返回URL中指定的部分。partToExtract的有效值为：HOST, PATH, QUERY, <span class="keyword">REF</span>, PROTOCOL, AUTHORITY, FILE, <span class="keyword">and</span> USERINFO.</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> parse_url</span><br><span class="line">(<span class="string">&#x27;https://www.tableName.com/path1/p.php?k1=v1&amp;k2=v2#Ref1&#x27;</span>, <span class="string">&#x27;HOST&#x27;</span>) </span><br><span class="line"><span class="keyword">from</span> tableName;</span><br><span class="line">www.tableName.com </span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> parse_url</span><br><span class="line">(<span class="string">&#x27;https://www.tableName.com/path1/p.php?k1=v1&amp;k2=v2#Ref1&#x27;</span>, <span class="string">&#x27;QUERY&#x27;</span>, <span class="string">&#x27;k1&#x27;</span>)</span><br><span class="line"> <span class="keyword">from</span> tableName;</span><br><span class="line">v1</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>json解析函数：get_json_object</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">语法: get_json_object(string json_string, string path)</span><br><span class="line">返回值: string</span><br><span class="line">说明：解析json的字符串json_string,返回path指定的内容。如果输入的json字符串无效，那么返回<span class="keyword">NULL</span>。</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span>  get_json_object(<span class="string">&#x27;&#123;&quot;store&quot;:&#123;&quot;fruit&quot;:\[&#123;&quot;weight&quot;:8,&quot;type&quot;:&quot;apple&quot;&#125;,&#123;&quot;weight&quot;:9,&quot;type&quot;:&quot;pear&quot;&#125;], &quot;bicycle&quot;:&#123;&quot;price&quot;:19.95,&quot;color&quot;:&quot;red&quot;&#125; &#125;,&quot;email&quot;:&quot;amy@only_for_json_udf_test.net&quot;,&quot;owner&quot;:&quot;amy&quot;&#125;&#x27;</span>,<span class="string">&#x27;$.owner&#x27;</span>) <span class="keyword">from</span> tableName;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>空格字符串函数：space</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">语法: space(<span class="type">int</span> n)</span><br><span class="line">返回值: string</span><br><span class="line">说明：返回长度为n的字符串</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> space(<span class="number">10</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> length(space(<span class="number">10</span>)) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>重复字符串函数：repeat</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: repeat(string str, <span class="type">int</span> n)</span><br><span class="line">返回值: string</span><br><span class="line">说明：返回重复n次后的str字符串</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> repeat(<span class="string">&#x27;abc&#x27;</span>,<span class="number">5</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">abcabcabcabcabc</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>首字符ascii函数：ascii</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: ascii(string str)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明：返回字符串str第一个字符的ascii码</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> ascii(<span class="string">&#x27;abcde&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">97</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>左补足函数：lpad</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">语法: lpad(string str, <span class="type">int</span> len, string pad)</span><br><span class="line">返回值: string</span><br><span class="line">说明：将str进行用pad进行左补足到len位</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> lpad(<span class="string">&#x27;abc&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;td&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">tdtdtdtabc</span><br><span class="line">注意：与GP，ORACLE不同，pad 不能默认</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>右补足函数：rpad</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: rpad(string str, <span class="type">int</span> len, string pad)</span><br><span class="line">返回值: string</span><br><span class="line">说明：将str进行用pad进行右补足到len位</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> rpad(<span class="string">&#x27;abc&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;td&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">abctdtdtdt</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>分割字符串函数: split</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: split(string str, string pat)</span><br><span class="line">返回值: <span class="keyword">array</span></span><br><span class="line">说明: 按照pat字符串分割str，会返回分割后的字符串数组</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> split(<span class="string">&#x27;abtcdtef&#x27;</span>,<span class="string">&#x27;t&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line">[&quot;ab&quot;,&quot;cd&quot;,&quot;ef&quot;]</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>集合查找函数: find_in_set</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: find_in_set(string str, string strList)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明: 返回str在strlist第一次出现的位置，strlist是用逗号分割的字符串。如果没有找该str字符，则返回<span class="number">0</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> find_in_set(<span class="string">&#x27;ab&#x27;</span>,<span class="string">&#x27;ef,ab,de&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">2</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> find_in_set(<span class="string">&#x27;at&#x27;</span>,<span class="string">&#x27;ef,ab,de&#x27;</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure>

<h3 id="复合类型构建操作"><a href="#复合类型构建操作" class="headerlink" title="复合类型构建操作"></a>复合类型构建操作</h3><ul>
<li>Map类型构建: map</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: map (key1, value1, key2, value2, …)</span><br><span class="line">说明：根据输入的key和<span class="keyword">value</span>对构建map类型</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">Create</span> <span class="keyword">table</span> mapTable <span class="keyword">as</span> <span class="keyword">select</span> map(<span class="string">&#x27;100&#x27;</span>,<span class="string">&#x27;tom&#x27;</span>,<span class="string">&#x27;200&#x27;</span>,<span class="string">&#x27;mary&#x27;</span>) <span class="keyword">as</span> t <span class="keyword">from</span> tableName;</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">describe</span> mapTable;</span><br><span class="line">t       map<span class="operator">&lt;</span>string ,string<span class="operator">&gt;</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> t <span class="keyword">from</span> tableName;</span><br><span class="line">&#123;&quot;100&quot;:&quot;tom&quot;,&quot;200&quot;:&quot;mary&quot;&#125;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>Struct类型构建: struct</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: struct(val1, val2, val3, …)</span><br><span class="line">说明：根据输入的参数构建结构体struct类型</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> struct_table <span class="keyword">as</span> <span class="keyword">select</span> struct(<span class="string">&#x27;tom&#x27;</span>,<span class="string">&#x27;mary&#x27;</span>,<span class="string">&#x27;tim&#x27;</span>) <span class="keyword">as</span> t <span class="keyword">from</span> tableName;</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">describe</span> struct_table;</span><br><span class="line">t       struct<span class="operator">&lt;</span>col1:string ,col2:string,col3:string<span class="operator">&gt;</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> t <span class="keyword">from</span> tableName;</span><br><span class="line">&#123;&quot;col1&quot;:&quot;tom&quot;,&quot;col2&quot;:&quot;mary&quot;,&quot;col3&quot;:&quot;tim&quot;&#125;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>array类型构建: array</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: <span class="keyword">array</span>(val1, val2, …)</span><br><span class="line">说明：根据输入的参数构建数组<span class="keyword">array</span>类型</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> arr_table <span class="keyword">as</span> <span class="keyword">select</span> <span class="keyword">array</span>(&quot;tom&quot;,&quot;mary&quot;,&quot;tim&quot;) <span class="keyword">as</span> t <span class="keyword">from</span> tableName;</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">describe</span> tableName;</span><br><span class="line">t       <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> t <span class="keyword">from</span> tableName;</span><br><span class="line">[&quot;tom&quot;,&quot;mary&quot;,&quot;tim&quot;]</span><br></pre></td></tr></table></figure>

<h3 id="复杂类型访问操作"><a href="#复杂类型访问操作" class="headerlink" title="复杂类型访问操作"></a>复杂类型访问操作</h3><p>- </p>
<ul>
<li><ol>
<li>array类型访问: A[n]</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: A[n]</span><br><span class="line">操作类型: A为<span class="keyword">array</span>类型，n为<span class="type">int</span>类型</span><br><span class="line">说明：返回数组A中的第n个变量值。数组的起始下标为<span class="number">0</span>。比如，A是个值为[<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>]的数组类型，那么A[<span class="number">0</span>]将返回<span class="string">&#x27;foo&#x27;</span>,而A[<span class="number">1</span>]将返回<span class="string">&#x27;bar&#x27;</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> arr_table2 <span class="keyword">as</span> <span class="keyword">select</span> <span class="keyword">array</span>(&quot;tom&quot;,&quot;mary&quot;,&quot;tim&quot;) <span class="keyword">as</span> t</span><br><span class="line"> <span class="keyword">from</span> tableName;</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> t[<span class="number">0</span>],t[<span class="number">1</span>] <span class="keyword">from</span> arr_table2;</span><br><span class="line">tom     mary    tim</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>map类型访问: M[key]</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">语法: M[key]</span><br><span class="line">操作类型: M为map类型，key为map中的key值</span><br><span class="line">说明：返回map类型M中，key值为指定值的<span class="keyword">value</span>值。比如，M是值为&#123;<span class="string">&#x27;f&#x27;</span> <span class="operator">-</span><span class="operator">&gt;</span> <span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;b&#x27;</span> <span class="operator">-</span><span class="operator">&gt;</span> <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;all&#x27;</span> <span class="operator">-</span><span class="operator">&gt;</span> <span class="string">&#x27;foobar&#x27;</span>&#125;的map类型，那么M[<span class="string">&#x27;all&#x27;</span>]将会返回<span class="string">&#x27;foobar&#x27;</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">Create</span> <span class="keyword">table</span> map_table2 <span class="keyword">as</span> <span class="keyword">select</span> map(<span class="string">&#x27;100&#x27;</span>,<span class="string">&#x27;tom&#x27;</span>,<span class="string">&#x27;200&#x27;</span>,<span class="string">&#x27;mary&#x27;</span>) <span class="keyword">as</span> t <span class="keyword">from</span> tableName;</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> t[<span class="string">&#x27;200&#x27;</span>],t[<span class="string">&#x27;100&#x27;</span>] <span class="keyword">from</span> map_table2;</span><br><span class="line">mary    tom</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>struct类型访问: S.x</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">语法: S.x</span><br><span class="line">操作类型: S为struct类型</span><br><span class="line">说明：返回结构体S中的x字段。比如，对于结构体struct foobar &#123;<span class="type">int</span> foo, <span class="type">int</span> bar&#125;，foobar.foo返回结构体中的foo字段</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> str_table2 <span class="keyword">as</span> <span class="keyword">select</span> struct(<span class="string">&#x27;tom&#x27;</span>,<span class="string">&#x27;mary&#x27;</span>,<span class="string">&#x27;tim&#x27;</span>) <span class="keyword">as</span> t <span class="keyword">from</span> tableName;</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">describe</span> tableName;</span><br><span class="line">t       struct<span class="operator">&lt;</span>col1:string ,col2:string,col3:string<span class="operator">&gt;</span></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> t.col1,t.col3 <span class="keyword">from</span> str_table2;</span><br><span class="line">tom     tim</span><br></pre></td></tr></table></figure>

<h3 id="复杂类型长度统计函数"><a href="#复杂类型长度统计函数" class="headerlink" title="复杂类型长度统计函数"></a>复杂类型长度统计函数</h3><p>- </p>
<ul>
<li><ol>
<li>Map类型长度函数: size(Map&lt;k .V&gt;)</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: size(Map<span class="operator">&lt;</span>k .V<span class="operator">&gt;</span>)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明: 返回map类型的长度</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> size(t) <span class="keyword">from</span> map_table2;</span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>array类型长度函数: size(Array)</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">语法: size(<span class="keyword">Array</span><span class="operator">&lt;</span>T<span class="operator">&gt;</span>)</span><br><span class="line">返回值: <span class="type">int</span></span><br><span class="line">说明: 返回<span class="keyword">array</span>类型的长度</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> size(t) <span class="keyword">from</span> arr_table2;</span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>类型转换函数  ***</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">类型转换函数: cast</span><br><span class="line">语法: <span class="built_in">cast</span>(expr <span class="keyword">as</span> <span class="operator">&lt;</span>type<span class="operator">&gt;</span>)</span><br><span class="line">返回值: Expected &quot;=&quot; <span class="keyword">to</span> follow &quot;type&quot;</span><br><span class="line">说明: 返回转换后的数据类型</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">cast</span>(<span class="string">&#x27;1&#x27;</span> <span class="keyword">as</span> <span class="type">bigint</span>) <span class="keyword">from</span> tableName;</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>

<h2 id="hive当中的lateral-view-与-explode以及reflect和窗口函数"><a href="#hive当中的lateral-view-与-explode以及reflect和窗口函数" class="headerlink" title="hive当中的lateral view 与 explode以及reflect和窗口函数"></a>hive当中的lateral view 与 explode以及reflect和窗口函数</h2><h3 id="使用explode函数将hive表中的Map和Array字段数据进行拆分"><a href="#使用explode函数将hive表中的Map和Array字段数据进行拆分" class="headerlink" title="使用explode函数将hive表中的Map和Array字段数据进行拆分"></a>使用explode函数将hive表中的Map和Array字段数据进行拆分</h3><p>lateral view用于和split、explode等UDTF一起使用的，能将一行数据拆分成多行数据，在此基础上可以对拆分的数据进行聚合，lateral view首先为原始表的每行调用UDTF，UDTF会把一行拆分成一行或者多行，lateral view在把结果组合，产生一个支持别名表的虚拟表。</p>
<p>其中explode还可以用于将hive一列中复杂的array或者map结构拆分成多行</p>
<p>需求：现在有数据格式如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">zhangsan child1,child2,child3,child4 k1:v1,k2:v2</span><br><span class="line"></span><br><span class="line">lisi child5,child6,child7,child8 k3:v3,k4:v4</span><br></pre></td></tr></table></figure>

<p>字段之间使用\t分割，需求将所有的child进行拆开成为一列</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">+----------+--+</span><br><span class="line">| mychild  |</span><br><span class="line">+----------+--+</span><br><span class="line">| child1   |</span><br><span class="line">| child2   |</span><br><span class="line">| child3   |</span><br><span class="line">| child4   |</span><br><span class="line">| child5   |</span><br><span class="line">| child6   |</span><br><span class="line">| child7   |</span><br><span class="line">| child8   |</span><br><span class="line">+----------+--+</span><br></pre></td></tr></table></figure>

<p>将map的key和value也进行拆开，成为如下结果</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+-----------+-------------+--+</span><br><span class="line">| mymapkey  | mymapvalue  |</span><br><span class="line">+-----------+-------------+--+</span><br><span class="line">| k1        | v1          |</span><br><span class="line">| k2        | v2          |</span><br><span class="line">| k3        | v3          |</span><br><span class="line">| k4        | v4          |</span><br><span class="line">+-----------+-------------+--+</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>创建hive数据库</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">创建hive数据库</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">create</span> database hive_explode;</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> use hive_explode;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>创建hive表，然后使用explode拆分map和array</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">create</span>  <span class="keyword">table</span> t3(name string,children <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>,address Map<span class="operator">&lt;</span>string,string<span class="operator">&gt;</span>) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>  collection items terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> map keys terminated <span class="keyword">by</span> <span class="string">&#x27;:&#x27;</span> stored <span class="keyword">as</span> textFile;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>加载数据</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">node03执行以下命令创建表数据文件</span><br><span class="line"> mkdir <span class="operator">-</span>p <span class="operator">/</span>export<span class="operator">/</span>servers<span class="operator">/</span>hivedatas<span class="operator">/</span></span><br><span class="line"> cd <span class="operator">/</span>export<span class="operator">/</span>servers<span class="operator">/</span>hivedatas<span class="operator">/</span></span><br><span class="line"> vim maparray</span><br><span class="line">内容如下:</span><br><span class="line">zhangsan child1,child2,child3,child4 k1:v1,k2:v2</span><br><span class="line">lisi child5,child6,child7,child8 k3:v3,k4:v4</span><br><span class="line"></span><br><span class="line">hive表当中加载数据</span><br><span class="line">hive (hive_explode)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/export/servers/hivedatas/maparray&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> t3;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>使用explode将hive当中数据拆开</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">将<span class="keyword">array</span>当中的数据拆分开</span><br><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">SELECT</span> explode(children) <span class="keyword">AS</span> myChild <span class="keyword">FROM</span> t3;</span><br><span class="line"></span><br><span class="line">将map当中的数据拆分开</span><br><span class="line"></span><br><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">SELECT</span> explode(address) <span class="keyword">AS</span> (myMapKey, myMapValue) <span class="keyword">FROM</span> t3;</span><br></pre></td></tr></table></figure>

<h3 id="使用explode拆分json字符串"><a href="#使用explode拆分json字符串" class="headerlink" title="使用explode拆分json字符串"></a>使用explode拆分json字符串</h3><p>需求: 需求：现在有一些数据格式如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a:shandong,b:beijing,c:hebei<span class="operator">|</span><span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span><span class="operator">|</span>[&#123;&quot;source&quot;:&quot;7fresh&quot;,&quot;monthSales&quot;:<span class="number">4900</span>,&quot;userCount&quot;:<span class="number">1900</span>,&quot;score&quot;:&quot;9.9&quot;&#125;,&#123;&quot;source&quot;:&quot;jd&quot;,&quot;monthSales&quot;:<span class="number">2090</span>,&quot;userCount&quot;:<span class="number">78981</span>,&quot;score&quot;:&quot;9.8&quot;&#125;,&#123;&quot;source&quot;:&quot;jdmart&quot;,&quot;monthSales&quot;:<span class="number">6987</span>,&quot;userCount&quot;:<span class="number">1600</span>,&quot;score&quot;:&quot;9.0&quot;&#125;]</span><br></pre></td></tr></table></figure>

<p>其中字段与字段之间的分隔符是 |</p>
<p>我们要解析得到所有的monthSales对应的值为以下这一列（行转列）</p>
<p>4900</p>
<p>2090</p>
<p>6987</p>
<p>- </p>
<ul>
<li><ol>
<li>创建hive表</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> explode_lateral_view</span><br><span class="line">                   <span class="operator">&gt;</span> (`area` string,</span><br><span class="line">                   <span class="operator">&gt;</span> `goods_id` string,</span><br><span class="line">                   <span class="operator">&gt;</span> `sale_info` string)</span><br><span class="line">                   <span class="operator">&gt;</span> <span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">                   <span class="operator">&gt;</span> FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;|&#x27;</span></span><br><span class="line">                   <span class="operator">&gt;</span> STORED <span class="keyword">AS</span> textfile;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>准备数据并加载数据</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">准备数据如下</span><br><span class="line">cd <span class="operator">/</span>export<span class="operator">/</span>servers<span class="operator">/</span>hivedatas</span><br><span class="line">vim explode_json</span><br><span class="line"></span><br><span class="line">a:shandong,b:beijing,c:hebei<span class="operator">|</span><span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span><span class="operator">|</span>[&#123;&quot;source&quot;:&quot;7fresh&quot;,&quot;monthSales&quot;:<span class="number">4900</span>,&quot;userCount&quot;:<span class="number">1900</span>,&quot;score&quot;:&quot;9.9&quot;&#125;,&#123;&quot;source&quot;:&quot;jd&quot;,&quot;monthSales&quot;:<span class="number">2090</span>,&quot;userCount&quot;:<span class="number">78981</span>,&quot;score&quot;:&quot;9.8&quot;&#125;,&#123;&quot;source&quot;:&quot;jdmart&quot;,&quot;monthSales&quot;:<span class="number">6987</span>,&quot;userCount&quot;:<span class="number">1600</span>,&quot;score&quot;:&quot;9.0&quot;&#125;]</span><br><span class="line"></span><br><span class="line">加载数据到hive表当中去</span><br><span class="line">hive (hive_explode)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/export/servers/hivedatas/explode_json&#x27;</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> explode_lateral_view;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>使用explode拆分Array</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">select</span> explode(split(goods_id,<span class="string">&#x27;,&#x27;</span>)) <span class="keyword">as</span> goods_id <span class="keyword">from</span> explode_lateral_view;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>使用explode拆解Map</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">select</span> explode(split(area,<span class="string">&#x27;,&#x27;</span>)) <span class="keyword">as</span> area <span class="keyword">from</span> explode_lateral_view;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>拆解json字段</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">select</span> explode(split(regexp_replace(regexp_replace(sale_info,<span class="string">&#x27;\\[\\&#123;&#x27;</span>,<span class="string">&#x27;&#x27;</span>),<span class="string">&#x27;&#125;]&#x27;</span>,<span class="string">&#x27;&#x27;</span>),<span class="string">&#x27;&#125;,\\&#123;&#x27;</span>)) <span class="keyword">as</span>  sale_info <span class="keyword">from</span> explode_lateral_view;</span><br><span class="line"></span><br><span class="line">然后我们想用get_json_object来获取key为monthSales的数据：</span><br><span class="line"></span><br><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">select</span> get_json_object(explode(split(regexp_replace(regexp_replace(sale_info,<span class="string">&#x27;\\[\\&#123;&#x27;</span>,<span class="string">&#x27;&#x27;</span>),<span class="string">&#x27;&#125;]&#x27;</span>,<span class="string">&#x27;&#x27;</span>),<span class="string">&#x27;&#125;,\\&#123;&#x27;</span>)),<span class="string">&#x27;$.monthSales&#x27;</span>) <span class="keyword">as</span>  sale_info <span class="keyword">from</span> explode_lateral_view;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">然后挂了FAILED: SemanticException [Error <span class="number">10081</span>]: UDTF<span class="string">&#x27;s are not supported outside the SELECT clause, nor nested in expressions</span></span><br><span class="line"><span class="string">UDTF explode不能写在别的函数内</span></span><br><span class="line"><span class="string">如果你这么写，想查两个字段，select explode(split(area,&#x27;</span>,<span class="string">&#x27;)) as area,good_id from explode_lateral_view;</span></span><br><span class="line"><span class="string">会报错FAILED: SemanticException 1:40 Only a single expression in the SELECT clause is supported with UDTF&#x27;</span>s. Error encountered near token <span class="string">&#x27;good_id&#x27;</span></span><br><span class="line">使用UDTF的时候，只支持一个字段，这时候就需要<span class="keyword">LATERAL</span> <span class="keyword">VIEW</span>出场了</span><br></pre></td></tr></table></figure>

<h3 id="配合LATERAL-VIEW使用"><a href="#配合LATERAL-VIEW使用" class="headerlink" title="配合LATERAL  VIEW使用"></a>配合LATERAL  VIEW使用</h3><p>配合lateral view查询多个字段</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">select</span> goods_id2,sale_info <span class="keyword">from</span> explode_lateral_view <span class="keyword">LATERAL</span> <span class="keyword">VIEW</span> explode(split(goods_id,<span class="string">&#x27;,&#x27;</span>))goods <span class="keyword">as</span> goods_id2;</span><br><span class="line"></span><br><span class="line">其中<span class="keyword">LATERAL</span> <span class="keyword">VIEW</span> explode(split(goods_id,<span class="string">&#x27;,&#x27;</span>))goods相当于一个虚拟表，与原表explode_lateral_view笛卡尔积关联</span><br></pre></td></tr></table></figure>

<p>也可以多重使用</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">select</span> goods_id2,sale_info,area2</span><br><span class="line">                    <span class="keyword">from</span> explode_lateral_view </span><br><span class="line">                    <span class="keyword">LATERAL</span> <span class="keyword">VIEW</span> explode(split(goods_id,<span class="string">&#x27;,&#x27;</span>))goods <span class="keyword">as</span> goods_id2 </span><br><span class="line">                    <span class="keyword">LATERAL</span> <span class="keyword">VIEW</span> explode(split(area,<span class="string">&#x27;,&#x27;</span>))area <span class="keyword">as</span> area2;也是三个表笛卡尔积的结果</span><br></pre></td></tr></table></figure>

<p>最终，我们可以通过下面的句子，把这个json格式的一行数据，完全转换成二维表的方式展现</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">select</span> get_json_object(concat(<span class="string">&#x27;&#123;&#x27;</span>,sale_info_1,<span class="string">&#x27;&#125;&#x27;</span>),<span class="string">&#x27;$.source&#x27;</span>) <span class="keyword">as</span> source,get_json_object(concat(<span class="string">&#x27;&#123;&#x27;</span>,sale_info_1,<span class="string">&#x27;&#125;&#x27;</span>),<span class="string">&#x27;$.monthSales&#x27;</span>) <span class="keyword">as</span> monthSales,get_json_object(concat(<span class="string">&#x27;&#123;&#x27;</span>,sale_info_1,<span class="string">&#x27;&#125;&#x27;</span>),<span class="string">&#x27;$.userCount&#x27;</span>) <span class="keyword">as</span> monthSales,get_json_object(concat(<span class="string">&#x27;&#123;&#x27;</span>,sale_info_1,<span class="string">&#x27;&#125;&#x27;</span>),<span class="string">&#x27;$.score&#x27;</span>) <span class="keyword">as</span> monthSales <span class="keyword">from</span> explode_lateral_view <span class="keyword">LATERAL</span> <span class="keyword">VIEW</span> explode(split(regexp_replace(regexp_replace(sale_info,<span class="string">&#x27;\\[\\&#123;&#x27;</span>,<span class="string">&#x27;&#x27;</span>),<span class="string">&#x27;&#125;]&#x27;</span>,<span class="string">&#x27;&#x27;</span>),<span class="string">&#x27;&#125;,\\&#123;&#x27;</span>))sale_info <span class="keyword">as</span> sale_info_1;</span><br></pre></td></tr></table></figure>

<p>总结：</p>
<p>Lateral View通常和UDTF一起出现，为了解决UDTF不允许在select字段的问题。Multiple Lateral View可以实现类似笛卡尔乘积。Outer关键字可以把不输出的UDTF的空结果，输出成NULL，防止丢失数据。</p>
<h3 id="行转列"><a href="#行转列" class="headerlink" title="行转列"></a>行转列</h3><p>相关参数说明:</p>
<p>CONCAT(string A&#x2F;col, string B&#x2F;col…)：返回输入字符串连接后的结果，支持任意个输入字符串;</p>
<p>CONCAT_WS(separator, str1, str2,…)：它是一个特殊形式的 CONCAT()。第一个参数剩余参数间的分隔符。分隔符可以是与剩余参数一样的字符串。如果分隔符是 NULL，返回值也将为 NULL。这个函数会跳过分隔符参数后的任何 NULL 和空字符串。分隔符将被加到被连接的字符串之间;</p>
<p>COLLECT_SET(col)：函数只接受基本数据类型，它的主要作用是将某字段的值进行去重汇总，产生array类型字段。</p>
<p>数据准备:</p>
<table>
<thead>
<tr>
<th align="left">name</th>
<th align="left">constellation</th>
<th align="left">blood_type</th>
</tr>
</thead>
<tbody><tr>
<td align="left">孙悟空</td>
<td align="left">白羊座</td>
<td align="left">A</td>
</tr>
<tr>
<td align="left">老王</td>
<td align="left">射手座</td>
<td align="left">A</td>
</tr>
<tr>
<td align="left">宋宋</td>
<td align="left">白羊座</td>
<td align="left">B</td>
</tr>
<tr>
<td align="left">猪八戒</td>
<td align="left">白羊座</td>
<td align="left">A</td>
</tr>
<tr>
<td align="left">凤姐</td>
<td align="left">射手座</td>
<td align="left">A</td>
</tr>
</tbody></table>
<p>需求: 把星座和血型一样的人归类到一起。结果如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">射手座,A            老王<span class="operator">|</span>凤姐</span><br><span class="line">白羊座,A            孙悟空<span class="operator">|</span>猪八戒</span><br><span class="line">白羊座,B            宋宋</span><br></pre></td></tr></table></figure>

<p>实现步骤:</p>
<p>- </p>
<ul>
<li><ol>
<li>创建本地constellation.txt，导入数据</li>
</ol>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">node03服务器执行以下命令创建文件，注意数据使用\t进行分割</span><br><span class="line"><span class="built_in">cd</span> /export/servers/hivedatas</span><br><span class="line">vim constellation.txt</span><br><span class="line"></span><br><span class="line">数据如下: </span><br><span class="line">孙悟空 白羊座 A</span><br><span class="line">老王 射手座 A</span><br><span class="line">宋宋 白羊座 B       </span><br><span class="line">猪八戒 白羊座 A</span><br><span class="line">凤姐 射手座 A</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>创建hive表并导入数据</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">创建hive表并加载数据</span><br><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> person_info(</span><br><span class="line">                    name string, </span><br><span class="line">                    constellation string, </span><br><span class="line">                    blood_type string) </span><br><span class="line">                    <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> &quot;\t&quot;;</span><br><span class="line"></span><br><span class="line">加载数据</span><br><span class="line">hive (hive_explode)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/export/servers/hivedatas/constellation.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> person_info;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>按需求查询数据</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">select</span></span><br><span class="line">                        t1.base,</span><br><span class="line">                        concat_ws(<span class="string">&#x27;|&#x27;</span>, collect_set(t1.name)) name</span><br><span class="line">                    <span class="keyword">from</span></span><br><span class="line">                        (<span class="keyword">select</span></span><br><span class="line">                            name,</span><br><span class="line">                            concat(constellation, &quot;,&quot; , blood_type) base</span><br><span class="line">                        <span class="keyword">from</span></span><br><span class="line">                            person_info) t1</span><br><span class="line">                    <span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">                        t1.base;</span><br></pre></td></tr></table></figure>

<h3 id="列转行"><a href="#列转行" class="headerlink" title="列转行"></a>列转行</h3><p>所需函数:</p>
<p>EXPLODE(col)：将hive一列中复杂的array或者map结构拆分成多行。</p>
<p>LATERAL VIEW</p>
<p>用法：LATERAL VIEW udtf(expression) tableAlias AS columnAlias</p>
<p>解释：用于和split, explode等UDTF一起使用，它能够将一列数据拆成多行数据，在此基础上可以对拆分后的数据进行聚合。</p>
<p>数据准备:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/servers/hivedatas</span><br><span class="line">vim movie.txt</span><br><span class="line">文件内容如下:  数据字段之间使用\t进行分割</span><br><span class="line">《疑犯追踪》 悬疑,动作,科幻,剧情</span><br><span class="line">《Lie to me》 悬疑,警匪,动作,心理,剧情</span><br><span class="line">《战狼2》 战争,动作,灾难</span><br></pre></td></tr></table></figure>

<p>需求: 将电影分类中的数组数据展开。结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">《疑犯追踪》 悬疑</span><br><span class="line">《疑犯追踪》 动作</span><br><span class="line">《疑犯追踪》 科幻</span><br><span class="line">《疑犯追踪》 剧情</span><br><span class="line">《Lie to me》 悬疑</span><br><span class="line">《Lie to me》 警匪</span><br><span class="line">《Lie to me》 动作</span><br><span class="line">《Lie to me》 心理</span><br><span class="line">《Lie to me》 剧情</span><br><span class="line">《战狼2》 战争</span><br><span class="line">《战狼2》 动作</span><br><span class="line">《战狼2》 灾难</span><br></pre></td></tr></table></figure>

<p>实现步骤:</p>
<p>- </p>
<ul>
<li><ol>
<li>创建hive表</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> movie_info(</span><br><span class="line">    movie string, </span><br><span class="line">    category <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>) </span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> &quot;\t&quot;</span><br><span class="line">collection items terminated <span class="keyword">by</span> &quot;,&quot;;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>加载数据</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath &quot;/export/servers/hivedatas/movie.txt&quot; <span class="keyword">into</span> <span class="keyword">table</span> movie_info;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>按需求查询数据</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    movie,</span><br><span class="line">    category_name</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">    movie_info <span class="keyword">lateral</span> <span class="keyword">view</span> explode(category) table_tmp <span class="keyword">as</span> category_name;</span><br></pre></td></tr></table></figure>

<h3 id="reflect函数"><a href="#reflect函数" class="headerlink" title="reflect函数"></a>reflect函数</h3><p>reflect函数可以支持在sql中调用java中的自带函数，秒杀一切udf函数。</p>
<p>需求1: 使用java.lang.Math当中的Max求两列中最大值</p>
<p>实现步骤:</p>
<p>- </p>
<ul>
<li><ol>
<li>创建hive表</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> test_udf(col1 <span class="type">int</span>,col2 <span class="type">int</span>) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>准备数据并加载数据</li>
</ol>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/servers/hivedatas</span><br><span class="line">vim test_udf </span><br><span class="line"></span><br><span class="line">文件内容如下:</span><br><span class="line">1,2</span><br><span class="line">4,3</span><br><span class="line">6,4</span><br><span class="line">7,5</span><br><span class="line">5,6</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>加载数据</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/export/servers/hivedatas/test_udf&#x27;</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> test_udf;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>使用java.lang.Math当中的Max求两列当中的最大值</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">select</span> reflect(&quot;java.lang.Math&quot;,&quot;max&quot;,col1,col2) <span class="keyword">from</span> test_udf;</span><br></pre></td></tr></table></figure>

<p>需求2: 文件中不同的记录来执行不同的java的内置函数</p>
<p>实现步骤:</p>
<p>- </p>
<ul>
<li><ol>
<li>创建hive表</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> test_udf2(class_name string,method_name string,col1 <span class="type">int</span> , col2 <span class="type">int</span>) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>准备数据</li>
</ol>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/servers/hivedatas</span><br><span class="line">vim test_udf2</span><br><span class="line"></span><br><span class="line">文件内容如下:</span><br><span class="line">java.lang.Math,min,1,2</span><br><span class="line">java.lang.Math,max,2,3</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>加载数据</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/export/servers/hivedatas/test_udf2&#x27;</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> test_udf2;</span><br></pre></td></tr></table></figure>

<p>- </p>
<ul>
<li><ol>
<li>执行查询</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (hive_explode)<span class="operator">&gt;</span> <span class="keyword">select</span> reflect(class_name,method_name,col1,col2) <span class="keyword">from</span> test_udf2;</span><br></pre></td></tr></table></figure>

<p>需求3: 判断是否为数字</p>
<p>实现方式:</p>
<p>使用apache commons中的函数，commons下的jar已经包含在hadoop的classpath中，所以可以直接使用。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> reflect(&quot;org.apache.commons.lang.math.NumberUtils&quot;,&quot;isNumber&quot;,&quot;123&quot;)</span><br></pre></td></tr></table></figure>

<h2 id="窗口函数与分析函数"><a href="#窗口函数与分析函数" class="headerlink" title="窗口函数与分析函数"></a>窗口函数与分析函数</h2><p>在sql中有一类函数叫做聚合函数,例如sum()、avg()、max()等等,这类函数可以将多行数据按照规则聚集为一行,一般来讲聚集后的行数是要少于聚集前的行数的。但是有时我们想要既显示聚集前的数据,又要显示聚集后的数据,这时我们便引入了窗口函数。窗口函数又叫OLAP函数&#x2F;分析函数，窗口函数兼具分组和排序功能。</p>
<p>窗口函数最重要的关键字是 <strong>partition by</strong> 和 <strong>order by。</strong></p>
<p>具体语法如下：<strong>over (partition by xxx order by xxx)</strong></p>
<h3 id="sum、avg、min、max"><a href="#sum、avg、min、max" class="headerlink" title="sum、avg、min、max"></a>sum、avg、min、max</h3><p>准备数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">建表语句:</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> test_t1(</span><br><span class="line">cookieid string,</span><br><span class="line">createtime string,   <span class="comment">--day </span></span><br><span class="line">pv <span class="type">int</span></span><br><span class="line">) <span class="type">row</span> format delimited </span><br><span class="line">fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br><span class="line"></span><br><span class="line">加载数据：</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/root/hivedata/test_t1.dat&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> test_t1;</span><br><span class="line"></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-10</span>,<span class="number">1</span></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-11</span>,<span class="number">5</span></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-12</span>,<span class="number">7</span></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-13</span>,<span class="number">3</span></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-14</span>,<span class="number">2</span></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-15</span>,<span class="number">4</span></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-16</span>,<span class="number">4</span></span><br><span class="line"></span><br><span class="line">开启智能本地模式</span><br><span class="line"><span class="keyword">SET</span> hive.exec.mode.local.auto<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<p>SUM函数和窗口函数的配合使用：结果和ORDER BY相关,默认为升序。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> cookieid,createtime,pv,</span><br><span class="line"><span class="built_in">sum</span>(pv) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> cookieid <span class="keyword">order</span> <span class="keyword">by</span> createtime) <span class="keyword">as</span> pv1 </span><br><span class="line"><span class="keyword">from</span> test_t1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> cookieid,createtime,pv,</span><br><span class="line"><span class="built_in">sum</span>(pv) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> cookieid <span class="keyword">order</span> <span class="keyword">by</span> createtime <span class="keyword">rows</span> <span class="keyword">between</span> unbounded preceding <span class="keyword">and</span> <span class="keyword">current</span> <span class="type">row</span>) <span class="keyword">as</span> pv2</span><br><span class="line"><span class="keyword">from</span> test_t1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> cookieid,createtime,pv,</span><br><span class="line"><span class="built_in">sum</span>(pv) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> cookieid) <span class="keyword">as</span> pv3</span><br><span class="line"><span class="keyword">from</span> test_t1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> cookieid,createtime,pv,</span><br><span class="line"><span class="built_in">sum</span>(pv) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> cookieid <span class="keyword">order</span> <span class="keyword">by</span> createtime <span class="keyword">rows</span> <span class="keyword">between</span> <span class="number">3</span> preceding <span class="keyword">and</span> <span class="keyword">current</span> <span class="type">row</span>) <span class="keyword">as</span> pv4</span><br><span class="line"><span class="keyword">from</span> test_t1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> cookieid,createtime,pv,</span><br><span class="line"><span class="built_in">sum</span>(pv) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> cookieid <span class="keyword">order</span> <span class="keyword">by</span> createtime <span class="keyword">rows</span> <span class="keyword">between</span> <span class="number">3</span> preceding <span class="keyword">and</span> <span class="number">1</span> following) <span class="keyword">as</span> pv5</span><br><span class="line"><span class="keyword">from</span> test_t1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> cookieid,createtime,pv,</span><br><span class="line"><span class="built_in">sum</span>(pv) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> cookieid <span class="keyword">order</span> <span class="keyword">by</span> createtime <span class="keyword">rows</span> <span class="keyword">between</span> <span class="keyword">current</span> <span class="type">row</span> <span class="keyword">and</span> unbounded following) <span class="keyword">as</span> pv6</span><br><span class="line"><span class="keyword">from</span> test_t1;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pv1: 分组内从起点到当前行的pv累积，如，<span class="number">11</span>号的pv1<span class="operator">=</span><span class="number">10</span>号的pv<span class="operator">+</span><span class="number">11</span>号的pv, <span class="number">12</span>号<span class="operator">=</span><span class="number">10</span>号<span class="operator">+</span><span class="number">11</span>号<span class="operator">+</span><span class="number">12</span>号</span><br><span class="line">pv2: 同pv1</span><br><span class="line">pv3: 分组内(cookie1)所有的pv累加</span><br><span class="line">pv4: 分组内当前行<span class="operator">+</span>往前<span class="number">3</span>行，如，<span class="number">11</span>号<span class="operator">=</span><span class="number">10</span>号<span class="operator">+</span><span class="number">11</span>号， <span class="number">12</span>号<span class="operator">=</span><span class="number">10</span>号<span class="operator">+</span><span class="number">11</span>号<span class="operator">+</span><span class="number">12</span>号，</span><br><span class="line">                        <span class="number">13</span>号<span class="operator">=</span><span class="number">10</span>号<span class="operator">+</span><span class="number">11</span>号<span class="operator">+</span><span class="number">12</span>号<span class="operator">+</span><span class="number">13</span>号， <span class="number">14</span>号<span class="operator">=</span><span class="number">11</span>号<span class="operator">+</span><span class="number">12</span>号<span class="operator">+</span><span class="number">13</span>号<span class="operator">+</span><span class="number">14</span>号</span><br><span class="line">pv5: 分组内当前行<span class="operator">+</span>往前<span class="number">3</span>行<span class="operator">+</span>往后<span class="number">1</span>行，如，<span class="number">14</span>号<span class="operator">=</span><span class="number">11</span>号<span class="operator">+</span><span class="number">12</span>号<span class="operator">+</span><span class="number">13</span>号<span class="operator">+</span><span class="number">14</span>号<span class="operator">+</span><span class="number">15</span>号<span class="operator">=</span><span class="number">5</span><span class="operator">+</span><span class="number">7</span><span class="operator">+</span><span class="number">3</span><span class="operator">+</span><span class="number">2</span><span class="operator">+</span><span class="number">4</span><span class="operator">=</span><span class="number">21</span></span><br><span class="line">pv6: 分组内当前行<span class="operator">+</span>往后所有行，如，<span class="number">13</span>号<span class="operator">=</span><span class="number">13</span>号<span class="operator">+</span><span class="number">14</span>号<span class="operator">+</span><span class="number">15</span>号<span class="operator">+</span><span class="number">16</span>号<span class="operator">=</span><span class="number">3</span><span class="operator">+</span><span class="number">2</span><span class="operator">+</span><span class="number">4</span><span class="operator">+</span><span class="number">4</span><span class="operator">=</span><span class="number">13</span>，</span><br><span class="line">        <span class="number">14</span>号<span class="operator">=</span><span class="number">14</span>号<span class="operator">+</span><span class="number">15</span>号<span class="operator">+</span><span class="number">16</span>号<span class="operator">=</span><span class="number">2</span><span class="operator">+</span><span class="number">4</span><span class="operator">+</span><span class="number">4</span><span class="operator">=</span><span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>如果不指定rows between,默认为从起点到当前行;</p>
<p>如果不指定order by，则将分组内所有值累加;</p>
<p>关键是理解rows between含义,也叫做window子句：</p>
<p>preceding：往前</p>
<p>following：往后</p>
<p>current row：当前行</p>
<p>unbounded：起点</p>
<p>unbounded preceding 表示从前面的起点</p>
<p>unbounded following：表示到后面的终点</p>
<p>AVG，MIN，MAX，和SUM用法一样。</p>
<h3 id="row-number、rank、dense-rank、ntile"><a href="#row-number、rank、dense-rank、ntile" class="headerlink" title="row_number、rank、dense_rank、ntile"></a>row_number、rank、dense_rank、ntile</h3><p>准备数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-10</span>,<span class="number">1</span></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-11</span>,<span class="number">5</span></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-12</span>,<span class="number">7</span></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-13</span>,<span class="number">3</span></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-14</span>,<span class="number">2</span></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-15</span>,<span class="number">4</span></span><br><span class="line">cookie1,<span class="number">2020</span><span class="number">-04</span><span class="number">-16</span>,<span class="number">4</span></span><br><span class="line">cookie2,<span class="number">2020</span><span class="number">-04</span><span class="number">-10</span>,<span class="number">2</span></span><br><span class="line">cookie2,<span class="number">2020</span><span class="number">-04</span><span class="number">-11</span>,<span class="number">3</span></span><br><span class="line">cookie2,<span class="number">2020</span><span class="number">-04</span><span class="number">-12</span>,<span class="number">5</span></span><br><span class="line">cookie2,<span class="number">2020</span><span class="number">-04</span><span class="number">-13</span>,<span class="number">6</span></span><br><span class="line">cookie2,<span class="number">2020</span><span class="number">-04</span><span class="number">-14</span>,<span class="number">3</span></span><br><span class="line">cookie2,<span class="number">2020</span><span class="number">-04</span><span class="number">-15</span>,<span class="number">9</span></span><br><span class="line">cookie2,<span class="number">2020</span><span class="number">-04</span><span class="number">-16</span>,<span class="number">7</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_t2 (</span><br><span class="line">cookieid string,</span><br><span class="line">createtime string,   <span class="comment">--day </span></span><br><span class="line">pv <span class="type">INT</span></span><br><span class="line">) <span class="type">ROW</span> FORMAT DELIMITED </span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> </span><br><span class="line">stored <span class="keyword">as</span> textfile;</span><br><span class="line"></span><br><span class="line">加载数据：</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/root/hivedata/test_t2.dat&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> test_t2;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>ROW_NUMBER()使用</p>
<p>ROW_NUMBER()从1开始，按照顺序，生成分组内记录的序列。</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">cookieid,</span><br><span class="line">createtime,</span><br><span class="line">pv,</span><br><span class="line"><span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> pv <span class="keyword">desc</span>) <span class="keyword">AS</span> rn </span><br><span class="line"><span class="keyword">FROM</span> test_t2;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>RANK 和 DENSE_RANK使用</p>
<p>RANK() 生成数据项在分组中的排名，排名相等会在名次中留下空位 。</p>
<p>DENSE_RANK()生成数据项在分组中的排名，排名相等会在名次中不会留下空位。</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">cookieid,</span><br><span class="line">createtime,</span><br><span class="line">pv,</span><br><span class="line"><span class="built_in">RANK</span>() <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> pv <span class="keyword">desc</span>) <span class="keyword">AS</span> rn1,</span><br><span class="line"><span class="built_in">DENSE_RANK</span>() <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> pv <span class="keyword">desc</span>) <span class="keyword">AS</span> rn2,</span><br><span class="line"><span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> pv <span class="keyword">DESC</span>) <span class="keyword">AS</span> rn3 </span><br><span class="line"><span class="keyword">FROM</span> test_t2 </span><br><span class="line"><span class="keyword">WHERE</span> cookieid <span class="operator">=</span> <span class="string">&#x27;cookie1&#x27;</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>NTILE</p>
<p>有时会有这样的需求:如果数据排序后分为三部分，业务人员只关心其中的一部分，如何将这中间的三分之一数据拿出来呢?NTILE函数即可以满足。</p>
<p>ntile可以看成是：把有序的数据集合平均分配到指定的数量（num）个桶中, 将桶号分配给每一行。如果不能平均分配，则优先分配较小编号的桶，并且各个桶中能放的行数最多相差1。</p>
<p>然后可以根据桶号，选取前或后 n分之几的数据。数据会完整展示出来，只是给相应的数据打标签；具体要取几分之几的数据，需要再嵌套一层根据标签取出。</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">cookieid,</span><br><span class="line">createtime,</span><br><span class="line">pv,</span><br><span class="line"><span class="built_in">NTILE</span>(<span class="number">2</span>) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> rn1,</span><br><span class="line"><span class="built_in">NTILE</span>(<span class="number">3</span>) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> rn2,</span><br><span class="line"><span class="built_in">NTILE</span>(<span class="number">4</span>) <span class="keyword">OVER</span>(<span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> rn3</span><br><span class="line"><span class="keyword">FROM</span> test_t2 </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> cookieid,createtime;</span><br></pre></td></tr></table></figure>

<h2 id="其他一些窗口函数"><a href="#其他一些窗口函数" class="headerlink" title="其他一些窗口函数"></a>其他一些窗口函数</h2><h3 id="lag-lead-first-value-last-value"><a href="#lag-lead-first-value-last-value" class="headerlink" title="lag,lead,first_value,last_value"></a>lag,lead,first_value,last_value</h3><ul>
<li>LAG<br><strong>LAG(col,n,DEFAULT) 用于统计窗口内往上第n行值</strong>第一个参数为列名，第二个参数为往上第n行（可选，默认为1），第三个参数为默认值（当往上第n行为NULL时候，取默认值，如不指定，则为NULL）</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> cookieid,</span><br><span class="line">createtime,</span><br><span class="line">url,</span><br><span class="line"><span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> rn,</span><br><span class="line"><span class="built_in">LAG</span>(createtime,<span class="number">1</span>,<span class="string">&#x27;1970-01-01 00:00:00&#x27;</span>) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> last_1_time,</span><br><span class="line"><span class="built_in">LAG</span>(createtime,<span class="number">2</span>) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> last_2_time </span><br><span class="line"><span class="keyword">FROM</span> test_t4;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">last_1_time: 指定了往上第<span class="number">1</span>行的值，<span class="keyword">default</span>为<span class="string">&#x27;1970-01-01 00:00:00&#x27;</span>  </span><br><span class="line">                 cookie1第一行，往上<span class="number">1</span>行为<span class="keyword">NULL</span>,因此取默认值 <span class="number">1970</span><span class="number">-01</span><span class="number">-01</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line">                 cookie1第三行，往上<span class="number">1</span>行值为第二行值，<span class="number">2015</span><span class="number">-04</span><span class="number">-10</span> <span class="number">10</span>:<span class="number">00</span>:<span class="number">02</span></span><br><span class="line">                 cookie1第六行，往上<span class="number">1</span>行值为第五行值，<span class="number">2015</span><span class="number">-04</span><span class="number">-10</span> <span class="number">10</span>:<span class="number">50</span>:<span class="number">01</span></span><br><span class="line">last_2_time: 指定了往上第<span class="number">2</span>行的值，为指定默认值</span><br><span class="line">         cookie1第一行，往上<span class="number">2</span>行为<span class="keyword">NULL</span></span><br><span class="line">         cookie1第二行，往上<span class="number">2</span>行为<span class="keyword">NULL</span></span><br><span class="line">         cookie1第四行，往上<span class="number">2</span>行为第二行值，<span class="number">2015</span><span class="number">-04</span><span class="number">-10</span> <span class="number">10</span>:<span class="number">00</span>:<span class="number">02</span></span><br><span class="line">         cookie1第七行，往上<span class="number">2</span>行为第五行值，<span class="number">2015</span><span class="number">-04</span><span class="number">-10</span> <span class="number">10</span>:<span class="number">50</span>:<span class="number">01</span></span><br></pre></td></tr></table></figure>

<ul>
<li>LEAD</li>
</ul>
<p>与LAG相反<strong>LEAD(col,n,DEFAULT) 用于统计窗口内往下第n行值</strong>第一个参数为列名，第二个参数为往下第n行（可选，默认为1），第三个参数为默认值（当往下第n行为NULL时候，取默认值，如不指定，则为NULL）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> cookieid,</span><br><span class="line">createtime,</span><br><span class="line">url,</span><br><span class="line"><span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> rn,</span><br><span class="line"><span class="built_in">LEAD</span>(createtime,<span class="number">1</span>,<span class="string">&#x27;1970-01-01 00:00:00&#x27;</span>) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> next_1_time,</span><br><span class="line"><span class="built_in">LEAD</span>(createtime,<span class="number">2</span>) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> next_2_time </span><br><span class="line"><span class="keyword">FROM</span> test_t4;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>FIRST_VALUE</p>
<p>取分组内排序后，截止到当前行，第一个值</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> cookieid,</span><br><span class="line">createtime,</span><br><span class="line">url,</span><br><span class="line"><span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> rn,</span><br><span class="line"><span class="built_in">FIRST_VALUE</span>(url) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> first1 </span><br><span class="line"><span class="keyword">FROM</span> test_t4;</span><br></pre></td></tr></table></figure>

<ul>
<li>LAST_VALUE</li>
</ul>
<p>取分组内排序后，截止到当前行，最后一个值</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> cookieid,</span><br><span class="line">createtime,</span><br><span class="line">url,</span><br><span class="line"><span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> rn,</span><br><span class="line"><span class="built_in">LAST_VALUE</span>(url) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> last1 </span><br><span class="line"><span class="keyword">FROM</span> test_t4;</span><br></pre></td></tr></table></figure>

<p>如果想要取分组内排序后最后一个值，则需要变通一下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> cookieid,</span><br><span class="line">createtime,</span><br><span class="line">url,</span><br><span class="line"><span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> rn,</span><br><span class="line"><span class="built_in">LAST_VALUE</span>(url) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> last1,</span><br><span class="line"><span class="built_in">FIRST_VALUE</span>(url) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime <span class="keyword">DESC</span>) <span class="keyword">AS</span> last2 </span><br><span class="line"><span class="keyword">FROM</span> test_t4 </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> cookieid,createtime;</span><br></pre></td></tr></table></figure>

<p><strong>特别注意order  by</strong></p>
<p>如果不指定ORDER BY，则进行排序混乱，会出现错误的结果</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> cookieid,</span><br><span class="line">createtime,</span><br><span class="line">url,</span><br><span class="line"><span class="built_in">FIRST_VALUE</span>(url) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid) <span class="keyword">AS</span> first2  </span><br><span class="line"><span class="keyword">FROM</span> test_t4;</span><br></pre></td></tr></table></figure>

<h3 id="cume-dist-percent-rank"><a href="#cume-dist-percent-rank" class="headerlink" title="cume_dist,percent_rank"></a>cume_dist,percent_rank</h3><p>这两个序列分析函数不是很常用，<strong>注意：序列函数不支持WINDOW子句</strong></p>
<ul>
<li>数据准备</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">d1,user1,<span class="number">1000</span></span><br><span class="line">d1,user2,<span class="number">2000</span></span><br><span class="line">d1,user3,<span class="number">3000</span></span><br><span class="line">d2,user4,<span class="number">4000</span></span><br><span class="line">d2,user5,<span class="number">5000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> test_t3 (</span><br><span class="line">dept STRING,</span><br><span class="line">userid string,</span><br><span class="line">sal <span class="type">INT</span></span><br><span class="line">) <span class="type">ROW</span> FORMAT DELIMITED </span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> </span><br><span class="line">stored <span class="keyword">as</span> textfile;</span><br><span class="line"></span><br><span class="line">加载数据：</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/root/hivedata/test_t3.dat&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> test_t3;</span><br></pre></td></tr></table></figure>

<hr>
<ul>
<li><p>CUME_DIST  和order byd的排序顺序有关系</p>
<p>CUME_DIST 小于等于当前值的行数&#x2F;分组内总行数  order 默认顺序 正序 升序 比如，统计小于等于当前薪水的人数，所占总人数的比例</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">dept,</span><br><span class="line">userid,</span><br><span class="line">sal,</span><br><span class="line"><span class="built_in">CUME_DIST</span>() <span class="keyword">OVER</span>(<span class="keyword">ORDER</span> <span class="keyword">BY</span> sal) <span class="keyword">AS</span> rn1,</span><br><span class="line"><span class="built_in">CUME_DIST</span>() <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> dept <span class="keyword">ORDER</span> <span class="keyword">BY</span> sal) <span class="keyword">AS</span> rn2 </span><br><span class="line"><span class="keyword">FROM</span> test_t3;</span><br><span class="line"></span><br><span class="line">rn1: 没有<span class="keyword">partition</span>,所有数据均为<span class="number">1</span>组，总行数为<span class="number">5</span>，</span><br><span class="line">     第一行：小于等于<span class="number">1000</span>的行数为<span class="number">1</span>，因此，<span class="number">1</span><span class="operator">/</span><span class="number">5</span><span class="operator">=</span><span class="number">0.2</span></span><br><span class="line">     第三行：小于等于<span class="number">3000</span>的行数为<span class="number">3</span>，因此，<span class="number">3</span><span class="operator">/</span><span class="number">5</span><span class="operator">=</span><span class="number">0.6</span></span><br><span class="line">rn2: 按照部门分组，dpet<span class="operator">=</span>d1的行数为<span class="number">3</span>,</span><br><span class="line">     第二行：小于等于<span class="number">2000</span>的行数为<span class="number">2</span>，因此，<span class="number">2</span><span class="operator">/</span><span class="number">3</span><span class="operator">=</span><span class="number">0.6666666666666666</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>PERCENT_RANK</p>
<p>PERCENT_RANK 分组内当前行的RANK值-1&#x2F;分组内总行数-1</p>
<p>经调研 该函数显示现实意义不明朗 有待于继续考证</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">dept,</span><br><span class="line">userid,</span><br><span class="line">sal,</span><br><span class="line"><span class="built_in">PERCENT_RANK</span>() <span class="keyword">OVER</span>(<span class="keyword">ORDER</span> <span class="keyword">BY</span> sal) <span class="keyword">AS</span> rn1,   <span class="comment">--分组内</span></span><br><span class="line"><span class="built_in">RANK</span>() <span class="keyword">OVER</span>(<span class="keyword">ORDER</span> <span class="keyword">BY</span> sal) <span class="keyword">AS</span> rn11,          <span class="comment">--分组内RANK值</span></span><br><span class="line"><span class="built_in">SUM</span>(<span class="number">1</span>) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">NULL</span>) <span class="keyword">AS</span> rn12,     <span class="comment">--分组内总行数</span></span><br><span class="line"><span class="built_in">PERCENT_RANK</span>() <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> dept <span class="keyword">ORDER</span> <span class="keyword">BY</span> sal) <span class="keyword">AS</span> rn2 </span><br><span class="line"><span class="keyword">FROM</span> test_t3;</span><br><span class="line"></span><br><span class="line">rn1: rn1 <span class="operator">=</span> (rn11<span class="number">-1</span>) <span class="operator">/</span> (rn12<span class="number">-1</span>) </span><br><span class="line">    第一行,(<span class="number">1</span><span class="number">-1</span>)<span class="operator">/</span>(<span class="number">5</span><span class="number">-1</span>)<span class="operator">=</span><span class="number">0</span><span class="operator">/</span><span class="number">4</span><span class="operator">=</span><span class="number">0</span></span><br><span class="line">    第二行,(<span class="number">2</span><span class="number">-1</span>)<span class="operator">/</span>(<span class="number">5</span><span class="number">-1</span>)<span class="operator">=</span><span class="number">1</span><span class="operator">/</span><span class="number">4</span><span class="operator">=</span><span class="number">0.25</span></span><br><span class="line">    第四行,(<span class="number">4</span><span class="number">-1</span>)<span class="operator">/</span>(<span class="number">5</span><span class="number">-1</span>)<span class="operator">=</span><span class="number">3</span><span class="operator">/</span><span class="number">4</span><span class="operator">=</span><span class="number">0.75</span></span><br><span class="line">rn2: 按照dept分组，</span><br><span class="line">     dept<span class="operator">=</span>d1的总行数为<span class="number">3</span></span><br><span class="line">     第一行，(<span class="number">1</span><span class="number">-1</span>)<span class="operator">/</span>(<span class="number">3</span><span class="number">-1</span>)<span class="operator">=</span><span class="number">0</span></span><br><span class="line">     第三行，(<span class="number">3</span><span class="number">-1</span>)<span class="operator">/</span>(<span class="number">3</span><span class="number">-1</span>)<span class="operator">=</span><span class="number">1</span></span><br></pre></td></tr></table></figure>

<h3 id="grouping-sets-grouping-id-cube-rollup"><a href="#grouping-sets-grouping-id-cube-rollup" class="headerlink" title="grouping sets,grouping__id,cube,rollup"></a>grouping sets,grouping__id,cube,rollup</h3><p>这几个分析函数通常用于OLAP中，不能累加，而且需要根据不同维度上钻和下钻的指标统计，比如，分小时、天、月的UV数。</p>
<ul>
<li>数据准备</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020</span><span class="number">-03</span>,<span class="number">2020</span><span class="number">-03</span><span class="number">-10</span>,cookie1</span><br><span class="line"><span class="number">2020</span><span class="number">-03</span>,<span class="number">2020</span><span class="number">-03</span><span class="number">-10</span>,cookie5</span><br><span class="line"><span class="number">2020</span><span class="number">-03</span>,<span class="number">2020</span><span class="number">-03</span><span class="number">-12</span>,cookie7</span><br><span class="line"><span class="number">2020</span><span class="number">-04</span>,<span class="number">2020</span><span class="number">-04</span><span class="number">-12</span>,cookie3</span><br><span class="line"><span class="number">2020</span><span class="number">-04</span>,<span class="number">2020</span><span class="number">-04</span><span class="number">-13</span>,cookie2</span><br><span class="line"><span class="number">2020</span><span class="number">-04</span>,<span class="number">2020</span><span class="number">-04</span><span class="number">-13</span>,cookie4</span><br><span class="line"><span class="number">2020</span><span class="number">-04</span>,<span class="number">2020</span><span class="number">-04</span><span class="number">-16</span>,cookie4</span><br><span class="line"><span class="number">2020</span><span class="number">-03</span>,<span class="number">2020</span><span class="number">-03</span><span class="number">-10</span>,cookie2</span><br><span class="line"><span class="number">2020</span><span class="number">-03</span>,<span class="number">2020</span><span class="number">-03</span><span class="number">-10</span>,cookie3</span><br><span class="line"><span class="number">2020</span><span class="number">-04</span>,<span class="number">2020</span><span class="number">-04</span><span class="number">-12</span>,cookie5</span><br><span class="line"><span class="number">2020</span><span class="number">-04</span>,<span class="number">2020</span><span class="number">-04</span><span class="number">-13</span>,cookie6</span><br><span class="line"><span class="number">2020</span><span class="number">-04</span>,<span class="number">2020</span><span class="number">-04</span><span class="number">-15</span>,cookie3</span><br><span class="line"><span class="number">2020</span><span class="number">-04</span>,<span class="number">2020</span><span class="number">-04</span><span class="number">-15</span>,cookie2</span><br><span class="line"><span class="number">2020</span><span class="number">-04</span>,<span class="number">2020</span><span class="number">-04</span><span class="number">-16</span>,cookie1</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_t5 (</span><br><span class="line"><span class="keyword">month</span> STRING,</span><br><span class="line"><span class="keyword">day</span> STRING, </span><br><span class="line">cookieid STRING </span><br><span class="line">) <span class="type">ROW</span> FORMAT DELIMITED </span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> </span><br><span class="line">stored <span class="keyword">as</span> textfile;</span><br><span class="line"></span><br><span class="line">加载数据：</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/root/hivedata/test_t5.dat&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> test_t5;</span><br></pre></td></tr></table></figure>

<hr>
<ul>
<li>GROUPING SETS</li>
</ul>
<p>grouping sets是一种将多个group by 逻辑写在一个sql语句中的便利写法。</p>
<p>等价于将不同维度的GROUP BY结果集进行UNION ALL。</p>
<p><strong>GROUPING__ID</strong>，表示结果属于哪一个分组集合。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line"><span class="keyword">month</span>,</span><br><span class="line"><span class="keyword">day</span>,</span><br><span class="line"><span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,</span><br><span class="line">GROUPING__ID </span><br><span class="line"><span class="keyword">FROM</span> test_t5 </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span>,<span class="keyword">day</span> </span><br><span class="line"><span class="keyword">GROUPING</span> SETS (<span class="keyword">month</span>,<span class="keyword">day</span>) </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> GROUPING__ID;</span><br><span class="line"></span><br><span class="line">grouping_id表示这一组结果属于哪个分组集合，</span><br><span class="line">根据<span class="keyword">grouping</span> sets中的分组条件<span class="keyword">month</span>，<span class="keyword">day</span>，<span class="number">1</span>是代表<span class="keyword">month</span>，<span class="number">2</span>是代表<span class="keyword">day</span></span><br><span class="line"></span><br><span class="line">等价于 </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">month</span>,<span class="keyword">NULL</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">1</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test_t5 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span> <span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">NULL</span> <span class="keyword">as</span> <span class="keyword">month</span>,<span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">2</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test_t5 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">day</span>;</span><br></pre></td></tr></table></figure>

<p>再如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line"><span class="keyword">month</span>,</span><br><span class="line"><span class="keyword">day</span>,</span><br><span class="line"><span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,</span><br><span class="line">GROUPING__ID </span><br><span class="line"><span class="keyword">FROM</span> test_t5 </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span>,<span class="keyword">day</span> </span><br><span class="line"><span class="keyword">GROUPING</span> SETS (<span class="keyword">month</span>,<span class="keyword">day</span>,(<span class="keyword">month</span>,<span class="keyword">day</span>)) </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> GROUPING__ID;</span><br><span class="line"></span><br><span class="line">等价于</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">month</span>,<span class="keyword">NULL</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">1</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test_t5 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span> </span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">NULL</span>,<span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">2</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test_t5 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">day</span></span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">month</span>,<span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">3</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test_t5 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span>,<span class="keyword">day</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>CUBE</li>
</ul>
<p>根据GROUP BY的维度的所有组合进行聚合。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line"><span class="keyword">month</span>,</span><br><span class="line"><span class="keyword">day</span>,</span><br><span class="line"><span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,</span><br><span class="line">GROUPING__ID </span><br><span class="line"><span class="keyword">FROM</span> test_t5 </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span>,<span class="keyword">day</span> </span><br><span class="line"><span class="keyword">WITH</span> <span class="keyword">CUBE</span> </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> GROUPING__ID;</span><br><span class="line"></span><br><span class="line">等价于</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">NULL</span>,<span class="keyword">NULL</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">0</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test_t5</span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">month</span>,<span class="keyword">NULL</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">1</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test_t5 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span> </span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">NULL</span>,<span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">2</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test_t5 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">day</span></span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">month</span>,<span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">3</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test_t5 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span>,<span class="keyword">day</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>ROLLUP</li>
</ul>
<p>是CUBE的子集，以最左侧的维度为主，从该维度进行层级聚合。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">比如，以<span class="keyword">month</span>维度进行层级聚合：</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line"><span class="keyword">month</span>,</span><br><span class="line"><span class="keyword">day</span>,</span><br><span class="line"><span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,</span><br><span class="line">GROUPING__ID  </span><br><span class="line"><span class="keyword">FROM</span> test_t5 </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span>,<span class="keyword">day</span></span><br><span class="line"><span class="keyword">WITH</span> <span class="keyword">ROLLUP</span> </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> GROUPING__ID;</span><br><span class="line"></span><br><span class="line"><span class="comment">--把month和day调换顺序，则以day维度进行层级聚合：</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line"><span class="keyword">day</span>,</span><br><span class="line"><span class="keyword">month</span>,</span><br><span class="line"><span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,</span><br><span class="line">GROUPING__ID  </span><br><span class="line"><span class="keyword">FROM</span> test_t5 </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">day</span>,<span class="keyword">month</span> </span><br><span class="line"><span class="keyword">WITH</span> <span class="keyword">ROLLUP</span> </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> GROUPING__ID;</span><br><span class="line">（这里，根据天和月进行聚合，和根据天聚合结果一样，因为有父子关系，如果是其他维度组合的话，就会不一样）</span><br></pre></td></tr></table></figure>

<h2 id="七、Hive执行计划"><a href="#七、Hive执行计划" class="headerlink" title="七、Hive执行计划"></a>七、Hive执行计划</h2><p>Hive SQL的执行计划描述SQL实际执行的整体轮廓，通过执行计划能了解SQL程序在转换成相应计算引擎的执行逻辑，掌握了执行逻辑也就能更好地把握程序出现的瓶颈点，从而能够实现更有针对性的优化。此外还能帮助开发者识别看似等价的SQL其实是不等价的，看似不等价的SQL其实是等价的SQL。<strong>可以说执行计划是打开SQL优化大门的一把钥匙</strong>。</p>
<p>要想学SQL执行计划，就需要学习查看执行计划的命令：<code>explain</code>，在查询语句的SQL前面加上关键字explain是查看执行计划的基本方法。</p>
<p>学会explain，能够给我们工作中使用hive带来极大的便利！</p>
<h3 id="查看SQL的执行计划"><a href="#查看SQL的执行计划" class="headerlink" title="查看SQL的执行计划"></a>查看SQL的执行计划</h3><p>Hive提供的执行计划目前可以查看的信息有以下几种：</p>
<ul>
<li><strong>explain</strong>：查看执行计划的基本信息；</li>
<li><strong>explain dependency</strong>：dependency在explain语句中使用会产生有关计划中输入的额外信息。它显示了输入的各种属性；</li>
<li><strong>explain authorization</strong>：查看SQL操作相关权限的信息；</li>
<li><strong>explain vectorization</strong>：查看SQL的向量化描述信息，显示为什么未对Map和Reduce进行矢量化。从 Hive 2.3.0 开始支持；</li>
<li><strong>explain analyze</strong>：用实际的行数注释计划。从 Hive 2.2.0 开始支持；</li>
<li><strong>explain cbo</strong>：输出由Calcite优化器生成的计划。CBO 从 Hive 4.0.0 版本开始支持；</li>
<li><strong>explain locks</strong>：这对于了解系统将获得哪些锁以运行指定的查询很有用。LOCKS 从 Hive 3.2.0 开始支持；</li>
<li><strong>explain ast</strong>：输出查询的抽象语法树。AST 在 Hive 2.1.0 版本删除了，存在bug，转储AST可能会导致OOM错误，将在4.0.0版本修复；</li>
<li><strong>explain extended</strong>：加上 extended 可以输出有关计划的额外信息。这通常是物理信息，例如文件名，这些额外信息对我们用处不大；</li>
</ul>
<h3 id="1-explain-的用法"><a href="#1-explain-的用法" class="headerlink" title="1.  explain 的用法"></a>1.  explain 的用法</h3><p><strong>Hive提供了explain命令来展示一个查询的执行计划</strong>，这个执行计划对于我们了解底层原理，Hive 调优，排查数据倾斜等很有帮助。</p>
<p>使用语法如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain query;</span><br></pre></td></tr></table></figure>

<p>在 hive cli 中输入以下命令(hive 2.3.7)：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="built_in">sum</span>(id) <span class="keyword">from</span> test1;</span><br></pre></td></tr></table></figure>

<p>得到结果：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage<span class="number">-1</span> <span class="keyword">is</span> a root stage</span><br><span class="line">  Stage<span class="number">-0</span> depends <span class="keyword">on</span> stages: Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            alias: test1</span><br><span class="line">            Statistics: Num <span class="keyword">rows</span>: <span class="number">6</span> Data size: <span class="number">75</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">            <span class="keyword">Select</span> Operator</span><br><span class="line">              expressions: id (type: <span class="type">int</span>)</span><br><span class="line">              outputColumnNames: id</span><br><span class="line">              Statistics: Num <span class="keyword">rows</span>: <span class="number">6</span> Data size: <span class="number">75</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">              <span class="keyword">Group</span> <span class="keyword">By</span> Operator</span><br><span class="line">                aggregations: <span class="built_in">sum</span>(id)</span><br><span class="line">                mode: hash</span><br><span class="line">                outputColumnNames: _col0</span><br><span class="line">                Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">8</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">                Reduce Output Operator</span><br><span class="line">                  sort <span class="keyword">order</span>:</span><br><span class="line">                  Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">8</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">                  <span class="keyword">value</span> expressions: _col0 (type: <span class="type">bigint</span>)</span><br><span class="line">      Reduce Operator Tree:</span><br><span class="line">        <span class="keyword">Group</span> <span class="keyword">By</span> Operator</span><br><span class="line">          aggregations: <span class="built_in">sum</span>(VALUE._col0)</span><br><span class="line">          mode: mergepartial</span><br><span class="line">          outputColumnNames: _col0</span><br><span class="line">          Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">8</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">          File Output Operator</span><br><span class="line">            compressed: <span class="literal">false</span></span><br><span class="line">            Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">8</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">            <span class="keyword">table</span>:</span><br><span class="line">                input format: org.apache.hadoop.mapred.SequenceFileInputFormat</span><br><span class="line">                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</span><br><span class="line">                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage: Stage<span class="number">-0</span></span><br><span class="line">    <span class="keyword">Fetch</span> Operator</span><br><span class="line">      limit: <span class="number">-1</span></span><br><span class="line">      Processor Tree:</span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<p>看完以上内容有什么感受，是不是感觉都看不懂，不要着急，下面将会详细讲解每个参数，相信你学完下面的内容之后再看 explain 的查询结果将游刃有余。</p>
<blockquote>
<p><strong>一个HIVE查询被转换为一个由一个或多个stage组成的序列（有向无环图DAG）。这些stage可以是MapReduce stage，也可以是负责元数据存储的stage，也可以是负责文件系统的操作（比如移动和重命名）的stage</strong>。</p>
</blockquote>
<p>我们将上述结果拆分看，先从最外层开始，包含两个大的部分：</p>
<ol>
<li>stage dependencies：各个stage之间的依赖性</li>
<li>stage plan：各个stage的执行计划</li>
</ol>
<p>先看第一部分 stage dependencies ，包含两个 stage，Stage-1 是根stage，说明这是开始的stage，Stage-0 依赖 Stage-1，Stage-1执行完成后执行Stage-0。</p>
<p>再看第二部分 stage plan，里面有一个 Map Reduce，一个MR的执行计划分为两个部分：</p>
<ol>
<li>Map Operator Tree：MAP端的执行计划树</li>
<li>Reduce Operator Tree：Reduce端的执行计划树</li>
</ol>
<p>这两个执行计划树里面包含这条sql语句的 operator：</p>
<ol>
<li><p><strong>TableScan：表扫描操作</strong>，map端第一个操作肯定是加载表，所以就是表扫描操作，常见的属性：</p>
</li>
<li><ul>
<li>alias：表名称</li>
<li>Statistics：表统计信息，包含表中数据条数，数据大小等</li>
</ul>
</li>
<li><p><strong>Select Operator：选取操作</strong>，常见的属性 ：</p>
</li>
<li><ul>
<li>expressions：需要的字段名称及字段类型</li>
<li>outputColumnNames：输出的列名称</li>
<li>Statistics：表统计信息，包含表中数据条数，数据大小等</li>
</ul>
</li>
<li><p><strong>Group By Operator：分组聚合操作</strong>，常见的属性：</p>
</li>
<li><ul>
<li>aggregations：显示聚合函数信息</li>
<li>mode：聚合模式，值有 hash：随机聚合，就是hash partition；partial：局部聚合；final：最终聚合</li>
<li>keys：分组的字段，如果没有分组，则没有此字段</li>
<li>outputColumnNames：聚合之后输出列名</li>
<li>Statistics：表统计信息，包含分组聚合之后的数据条数，数据大小等</li>
</ul>
</li>
<li><p><strong>Reduce Output Operator：输出到reduce操作</strong>，常见属性：</p>
</li>
<li><ul>
<li>sort order：值为空 不排序；值为 + 正序排序，值为 - 倒序排序；值为 +-  排序的列为两列，第一列为正序，第二列为倒序</li>
</ul>
</li>
<li><p><strong>Filter Operator：过滤操作</strong>，常见的属性：</p>
</li>
<li><ul>
<li>predicate：过滤条件，如sql语句中的where id&gt;&#x3D;1，则此处显示(id &gt;&#x3D; 1)</li>
</ul>
</li>
<li><p><strong>Map Join Operator：join 操作</strong>，常见的属性：</p>
</li>
<li><ul>
<li>condition map：join方式 ，如Inner Join 0 to 1 Left Outer Join0 to 2</li>
<li>keys: join 的条件字段</li>
<li>outputColumnNames：join 完成之后输出的字段</li>
<li>Statistics：join 完成之后生成的数据条数，大小等</li>
</ul>
</li>
<li><p><strong>File Output Operator：文件输出操作</strong>，常见的属性</p>
</li>
<li><ul>
<li>compressed：是否压缩</li>
<li>table：表的信息，包含输入输出文件格式化方式，序列化方式等</li>
</ul>
</li>
<li><p><strong>Fetch Operator 客户端获取数据操作</strong>，常见的属性：</p>
</li>
<li><ul>
<li>limit，值为 -1 表示不限制条数，其他值为限制的条数</li>
</ul>
</li>
</ol>
<h3 id="2-explain-的使用场景"><a href="#2-explain-的使用场景" class="headerlink" title="2. explain 的使用场景"></a>2. explain 的使用场景</h3><blockquote>
<p>本节介绍 explain 能够为我们在生产实践中带来哪些便利及解决我们哪些迷惑</p>
</blockquote>
<h4 id="案例一：join-语句会过滤-null-的值吗？"><a href="#案例一：join-语句会过滤-null-的值吗？" class="headerlink" title="案例一：join 语句会过滤 null 的值吗？"></a>案例一：join 语句会过滤 null 的值吗？</h4><p>现在，我们在hive cli 输入以下查询计划语句</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.id,b.user_name <span class="keyword">from</span> test1 a <span class="keyword">join</span> test2 b <span class="keyword">on</span> a.id<span class="operator">=</span>b.id;</span><br></pre></td></tr></table></figure>

<p>问：<strong>上面这条 join 语句会过滤 id 为 null 的值吗</strong></p>
<p>执行下面语句：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">select</span> a.id,b.user_name <span class="keyword">from</span> test1 a <span class="keyword">join</span> test2 b <span class="keyword">on</span> a.id<span class="operator">=</span>b.id;</span><br></pre></td></tr></table></figure>

<p>我们来看结果 (为了适应页面展示，仅截取了部分输出信息)：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">TableScan</span><br><span class="line"> alias: a</span><br><span class="line"> Statistics: Num <span class="keyword">rows</span>: <span class="number">6</span> Data size: <span class="number">75</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line"> <span class="keyword">Filter</span> Operator</span><br><span class="line">    predicate: id <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span> (type: <span class="type">boolean</span>)</span><br><span class="line">    Statistics: Num <span class="keyword">rows</span>: <span class="number">6</span> Data size: <span class="number">75</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">    <span class="keyword">Select</span> Operator</span><br><span class="line">        expressions: id (type: <span class="type">int</span>)</span><br><span class="line">        outputColumnNames: _col0</span><br><span class="line">        Statistics: Num <span class="keyword">rows</span>: <span class="number">6</span> Data size: <span class="number">75</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">        HashTable Sink Operator</span><br><span class="line">           keys:</span><br><span class="line">             <span class="number">0</span> _col0 (type: <span class="type">int</span>)</span><br><span class="line">             <span class="number">1</span> _col0 (type: <span class="type">int</span>)</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure>

<p>从上述结果可以看到 <strong>predicate: id is not null</strong> 这样一行，<strong>说明 join 时会自动过滤掉关联字段为 null 值的情况，但 left join 或 full join 是不会自动过滤null值的</strong>，大家可以自行尝试下。</p>
<h4 id="案例二：group-by-分组语句会进行排序吗？"><a href="#案例二：group-by-分组语句会进行排序吗？" class="headerlink" title="案例二：group by 分组语句会进行排序吗？"></a>案例二：group by 分组语句会进行排序吗？</h4><p>看下面这条sql</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id,<span class="built_in">max</span>(user_name) <span class="keyword">from</span> test1 <span class="keyword">group</span> <span class="keyword">by</span> id;</span><br></pre></td></tr></table></figure>

<p>问：<strong>group by 分组语句会进行排序吗</strong></p>
<p>直接来看 explain 之后结果 (为了适应页面展示，仅截取了部分输出信息)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">TableScan</span><br><span class="line">   alias: test1</span><br><span class="line">   Statistics: Num <span class="keyword">rows</span>: <span class="number">9</span> Data size: <span class="number">108</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">   <span class="keyword">Select</span> Operator</span><br><span class="line">       expressions: id (type: <span class="type">int</span>), user_name (type: string)</span><br><span class="line">       outputColumnNames: id, user_name</span><br><span class="line">       Statistics: Num <span class="keyword">rows</span>: <span class="number">9</span> Data size: <span class="number">108</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">       <span class="keyword">Group</span> <span class="keyword">By</span> Operator</span><br><span class="line">          aggregations: <span class="built_in">max</span>(user_name)</span><br><span class="line">          keys: id (type: <span class="type">int</span>)</span><br><span class="line">          mode: hash</span><br><span class="line">          outputColumnNames: _col0, _col1</span><br><span class="line">          Statistics: Num <span class="keyword">rows</span>: <span class="number">9</span> Data size: <span class="number">108</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">          Reduce Output Operator</span><br><span class="line">            key expressions: _col0 (type: <span class="type">int</span>)</span><br><span class="line">            sort <span class="keyword">order</span>: <span class="operator">+</span></span><br><span class="line">            Map<span class="operator">-</span>reduce <span class="keyword">partition</span> columns: _col0 (type: <span class="type">int</span>)</span><br><span class="line">            Statistics: Num <span class="keyword">rows</span>: <span class="number">9</span> Data size: <span class="number">108</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">            <span class="keyword">value</span> expressions: _col1 (type: string)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>我们看 Group By Operator，里面有 keys: id (type: int) 说明按照 id 进行分组的，再往下看还有 sort order: + ，<strong>说明是按照 id 字段进行正序排序的</strong>。</p>
<h4 id="案例三：哪条sql执行效率高呢？"><a href="#案例三：哪条sql执行效率高呢？" class="headerlink" title="案例三：哪条sql执行效率高呢？"></a>案例三：哪条sql执行效率高呢？</h4><p>观察两条sql语句</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line"> a.id,</span><br><span class="line"> b.user_name</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line"> test1 a</span><br><span class="line"><span class="keyword">JOIN</span> test2 b <span class="keyword">ON</span> a.id <span class="operator">=</span> b.id</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line"> a.id <span class="operator">&gt;</span> <span class="number">2</span>;</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line"> a.id,</span><br><span class="line"> b.user_name</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line"> (<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test1 <span class="keyword">WHERE</span> id <span class="operator">&gt;</span> <span class="number">2</span>) a</span><br><span class="line"><span class="keyword">JOIN</span> test2 b <span class="keyword">ON</span> a.id <span class="operator">=</span> b.id;</span><br></pre></td></tr></table></figure>

<p><strong>这两条sql语句输出的结果是一样的，但是哪条sql执行效率高呢</strong>？</p>
<p>有人说第一条sql执行效率高，因为第二条sql有子查询，子查询会影响性能；</p>
<p>有人说第二条sql执行效率高，因为先过滤之后，在进行join时的条数减少了，所以执行效率就高了。</p>
<p>到底哪条sql效率高呢，我们直接在sql语句前面加上 explain，看下执行计划不就知道了嘛！</p>
<p>在第一条sql语句前加上 explain，得到如下结果</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain <span class="keyword">select</span> a.id,b.user_name <span class="keyword">from</span> test1 a <span class="keyword">join</span> test2 b <span class="keyword">on</span> a.id<span class="operator">=</span>b.id <span class="keyword">where</span> a.id <span class="operator">&gt;</span><span class="number">2</span>;</span><br><span class="line">OK</span><br><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage<span class="number">-4</span> <span class="keyword">is</span> a root stage</span><br><span class="line">  Stage<span class="number">-3</span> depends <span class="keyword">on</span> stages: Stage<span class="number">-4</span></span><br><span class="line">  Stage<span class="number">-0</span> depends <span class="keyword">on</span> stages: Stage<span class="number">-3</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage<span class="number">-4</span></span><br><span class="line">    Map Reduce <span class="keyword">Local</span> Work</span><br><span class="line">      Alias <span class="operator">-</span><span class="operator">&gt;</span> Map <span class="keyword">Local</span> Tables:</span><br><span class="line">        $hdt$_0:a</span><br><span class="line">          <span class="keyword">Fetch</span> Operator</span><br><span class="line">            limit: <span class="number">-1</span></span><br><span class="line">      Alias <span class="operator">-</span><span class="operator">&gt;</span> Map <span class="keyword">Local</span> Operator Tree:</span><br><span class="line">        $hdt$_0:a</span><br><span class="line">          TableScan</span><br><span class="line">            alias: a</span><br><span class="line">            Statistics: Num <span class="keyword">rows</span>: <span class="number">6</span> Data size: <span class="number">75</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">            <span class="keyword">Filter</span> Operator</span><br><span class="line">              predicate: (id <span class="operator">&gt;</span> <span class="number">2</span>) (type: <span class="type">boolean</span>)</span><br><span class="line">              Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">25</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">              <span class="keyword">Select</span> Operator</span><br><span class="line">                expressions: id (type: <span class="type">int</span>)</span><br><span class="line">                outputColumnNames: _col0</span><br><span class="line">                Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">25</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">                HashTable Sink Operator</span><br><span class="line">                  keys:</span><br><span class="line">                    <span class="number">0</span> _col0 (type: <span class="type">int</span>)</span><br><span class="line">                    <span class="number">1</span> _col0 (type: <span class="type">int</span>)</span><br><span class="line"></span><br><span class="line">  Stage: Stage<span class="number">-3</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            alias: b</span><br><span class="line">            Statistics: Num <span class="keyword">rows</span>: <span class="number">6</span> Data size: <span class="number">75</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">            <span class="keyword">Filter</span> Operator</span><br><span class="line">              predicate: (id <span class="operator">&gt;</span> <span class="number">2</span>) (type: <span class="type">boolean</span>)</span><br><span class="line">              Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">25</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">              <span class="keyword">Select</span> Operator</span><br><span class="line">                expressions: id (type: <span class="type">int</span>), user_name (type: string)</span><br><span class="line">                outputColumnNames: _col0, _col1</span><br><span class="line">                Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">25</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">                Map <span class="keyword">Join</span> Operator</span><br><span class="line">                  <span class="keyword">condition</span> map:</span><br><span class="line">                       <span class="keyword">Inner</span> <span class="keyword">Join</span> <span class="number">0</span> <span class="keyword">to</span> <span class="number">1</span></span><br><span class="line">                  keys:</span><br><span class="line">                    <span class="number">0</span> _col0 (type: <span class="type">int</span>)</span><br><span class="line">                    <span class="number">1</span> _col0 (type: <span class="type">int</span>)</span><br><span class="line">                  outputColumnNames: _col0, _col2</span><br><span class="line">                  Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">27</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">                  <span class="keyword">Select</span> Operator</span><br><span class="line">                    expressions: _col0 (type: <span class="type">int</span>), _col2 (type: string)</span><br><span class="line">                    outputColumnNames: _col0, _col1</span><br><span class="line">                    Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">27</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">                    File Output Operator</span><br><span class="line">                      compressed: <span class="literal">false</span></span><br><span class="line">                      Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">27</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">                      <span class="keyword">table</span>:</span><br><span class="line">                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat</span><br><span class="line">                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</span><br><span class="line">                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">      <span class="keyword">Local</span> Work:</span><br><span class="line">        Map Reduce <span class="keyword">Local</span> Work</span><br><span class="line"></span><br><span class="line">  Stage: Stage<span class="number">-0</span></span><br><span class="line">    <span class="keyword">Fetch</span> Operator</span><br><span class="line">      limit: <span class="number">-1</span></span><br><span class="line">      Processor Tree:</span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<p>在第二条sql语句前加上 explain，得到如下结果</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain <span class="keyword">select</span> a.id,b.user_name <span class="keyword">from</span>(<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span>  test1 <span class="keyword">where</span> id<span class="operator">&gt;</span><span class="number">2</span> ) a <span class="keyword">join</span> test2 b <span class="keyword">on</span> a.id<span class="operator">=</span>b.id;</span><br><span class="line">OK</span><br><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage<span class="number">-4</span> <span class="keyword">is</span> a root stage</span><br><span class="line">  Stage<span class="number">-3</span> depends <span class="keyword">on</span> stages: Stage<span class="number">-4</span></span><br><span class="line">  Stage<span class="number">-0</span> depends <span class="keyword">on</span> stages: Stage<span class="number">-3</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage<span class="number">-4</span></span><br><span class="line">    Map Reduce <span class="keyword">Local</span> Work</span><br><span class="line">      Alias <span class="operator">-</span><span class="operator">&gt;</span> Map <span class="keyword">Local</span> Tables:</span><br><span class="line">        $hdt$_0:test1</span><br><span class="line">          <span class="keyword">Fetch</span> Operator</span><br><span class="line">            limit: <span class="number">-1</span></span><br><span class="line">      Alias <span class="operator">-</span><span class="operator">&gt;</span> Map <span class="keyword">Local</span> Operator Tree:</span><br><span class="line">        $hdt$_0:test1</span><br><span class="line">          TableScan</span><br><span class="line">            alias: test1</span><br><span class="line">            Statistics: Num <span class="keyword">rows</span>: <span class="number">6</span> Data size: <span class="number">75</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">            <span class="keyword">Filter</span> Operator</span><br><span class="line">              predicate: (id <span class="operator">&gt;</span> <span class="number">2</span>) (type: <span class="type">boolean</span>)</span><br><span class="line">              Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">25</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">              <span class="keyword">Select</span> Operator</span><br><span class="line">                expressions: id (type: <span class="type">int</span>)</span><br><span class="line">                outputColumnNames: _col0</span><br><span class="line">                Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">25</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">                HashTable Sink Operator</span><br><span class="line">                  keys:</span><br><span class="line">                    <span class="number">0</span> _col0 (type: <span class="type">int</span>)</span><br><span class="line">                    <span class="number">1</span> _col0 (type: <span class="type">int</span>)</span><br><span class="line"></span><br><span class="line">  Stage: Stage<span class="number">-3</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            alias: b</span><br><span class="line">            Statistics: Num <span class="keyword">rows</span>: <span class="number">6</span> Data size: <span class="number">75</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">            <span class="keyword">Filter</span> Operator</span><br><span class="line">              predicate: (id <span class="operator">&gt;</span> <span class="number">2</span>) (type: <span class="type">boolean</span>)</span><br><span class="line">              Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">25</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">              <span class="keyword">Select</span> Operator</span><br><span class="line">                expressions: id (type: <span class="type">int</span>), user_name (type: string)</span><br><span class="line">                outputColumnNames: _col0, _col1</span><br><span class="line">                Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">25</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">                Map <span class="keyword">Join</span> Operator</span><br><span class="line">                  <span class="keyword">condition</span> map:</span><br><span class="line">                       <span class="keyword">Inner</span> <span class="keyword">Join</span> <span class="number">0</span> <span class="keyword">to</span> <span class="number">1</span></span><br><span class="line">                  keys:</span><br><span class="line">                    <span class="number">0</span> _col0 (type: <span class="type">int</span>)</span><br><span class="line">                    <span class="number">1</span> _col0 (type: <span class="type">int</span>)</span><br><span class="line">                  outputColumnNames: _col0, _col2</span><br><span class="line">                  Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">27</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">                  <span class="keyword">Select</span> Operator</span><br><span class="line">                    expressions: _col0 (type: <span class="type">int</span>), _col2 (type: string)</span><br><span class="line">                    outputColumnNames: _col0, _col1</span><br><span class="line">                    Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">27</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">                    File Output Operator</span><br><span class="line">                      compressed: <span class="literal">false</span></span><br><span class="line">                      Statistics: Num <span class="keyword">rows</span>: <span class="number">2</span> Data size: <span class="number">27</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">                      <span class="keyword">table</span>:</span><br><span class="line">                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat</span><br><span class="line">                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</span><br><span class="line">                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">      <span class="keyword">Local</span> Work:</span><br><span class="line">        Map Reduce <span class="keyword">Local</span> Work</span><br><span class="line"></span><br><span class="line">  Stage: Stage<span class="number">-0</span></span><br><span class="line">    <span class="keyword">Fetch</span> Operator</span><br><span class="line">      limit: <span class="number">-1</span></span><br><span class="line">      Processor Tree:</span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<p>大家有什么发现，除了表别名不一样，其他的执行计划完全一样，都是先进行 where 条件过滤，在进行 join 条件关联。<strong>说明 hive 底层会自动帮我们进行优化，所以这两条sql语句执行效率是一样的</strong>。</p>
<p>以上仅列举了3个我们生产中既熟悉又有点迷糊的例子，explain 还有很多其他的用途，如查看stage的依赖情况、排查数据倾斜、hive 调优等，小伙伴们可以自行尝试。</p>
<h3 id="2-explain-dependency的用法"><a href="#2-explain-dependency的用法" class="headerlink" title="2. explain dependency的用法"></a>2. explain dependency的用法</h3><p>explain dependency用于描述一段SQL需要的数据来源，输出是一个json格式的数据，里面包含以下两个部分的内容：</p>
<ul>
<li><strong>input_partitions</strong>：描述一段SQL依赖的数据来源表分区，里面存储的是分区名的列表，如果整段SQL包含的所有表都是非分区表，则显示为空。</li>
<li><strong>input_tables</strong>：描述一段SQL依赖的数据来源表，里面存储的是Hive表名的列表。</li>
</ul>
<p><strong>使用explain dependency查看SQL查询非分区普通表</strong>，在 hive cli 中输入以下命令：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain dependency <span class="keyword">select</span> s_age,<span class="built_in">count</span>(<span class="number">1</span>) num <span class="keyword">from</span> student_orc;</span><br></pre></td></tr></table></figure>

<p>得到结果：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;input_partitions&quot;:[],&quot;input_tables&quot;:[&#123;&quot;tablename&quot;:&quot;default@student_tb _orc&quot;,&quot;tabletype&quot;:&quot;MANAGED_TABLE&quot;&#125;]&#125;</span><br></pre></td></tr></table></figure>

<p><strong>使用explain dependency查看SQL查询分区表</strong>，在 hive cli 中输入以下命令：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain dependency <span class="keyword">select</span> s_age,<span class="built_in">count</span>(<span class="number">1</span>) num <span class="keyword">from</span> student_orc_partition;</span><br></pre></td></tr></table></figure>

<p>得到结果：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;input_partitions&quot;:[&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@ part=0&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=1&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=2&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=3&quot;&#125;,</span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=4&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=5&quot;&#125;,</span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=6&quot;&#125;,</span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=7&quot;&#125;,</span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=8&quot;&#125;,</span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=9&quot;&#125;], </span><br><span class="line">&quot;input_tables&quot;:[&#123;&quot;tablename&quot;:&quot;default@student_orc_partition&quot;, &quot;tabletype&quot;:&quot;MANAGED_TABLE&quot;&#125;]</span><br></pre></td></tr></table></figure>

<p>explain dependency的使用场景有两个：</p>
<ul>
<li><strong>场景一</strong>：快速排除。快速排除因为读取不到相应分区的数据而导致任务数据输出异常。例如，在一个以天分区的任务中，上游任务因为生产过程不可控因素出现异常或者空跑，导致下游任务引发异常。通过这种方式，可以快速查看SQL读取的分区是否出现异常。</li>
<li><strong>场景二</strong>：理清表的输入，帮助理解程序的运行，特别是有助于理解有多重子查询，多表连接的依赖输入。</li>
</ul>
<p>下面通过两个案例来看explain dependency的实际运用：</p>
<h4 id="案例一：识别看似等价的代码"><a href="#案例一：识别看似等价的代码" class="headerlink" title="案例一：识别看似等价的代码"></a>案例一：识别看似等价的代码</h4><p>对于刚接触SQL的程序员，很容易将</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">inner</span> <span class="keyword">join</span> b <span class="keyword">on</span> a.no<span class="operator">=</span>b.no <span class="keyword">and</span> a.f<span class="operator">&gt;</span><span class="number">1</span> <span class="keyword">and</span> a.f<span class="operator">&lt;</span><span class="number">3</span>;</span><br></pre></td></tr></table></figure>

<p>等价于</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">inner</span> <span class="keyword">join</span> b <span class="keyword">on</span> a.no<span class="operator">=</span>b.no <span class="keyword">where</span> a.f<span class="operator">&gt;</span><span class="number">1</span> <span class="keyword">and</span> a.f<span class="operator">&lt;</span><span class="number">3</span>;</span><br></pre></td></tr></table></figure>

<p>我们可以通过案例来查看下它们的区别：</p>
<p>代码1：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">a.s_no </span><br><span class="line"><span class="keyword">from</span> student_orc_partition a </span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> </span><br><span class="line">student_orc_partition_only b </span><br><span class="line"><span class="keyword">on</span> a.s_no<span class="operator">=</span>b.s_no <span class="keyword">and</span> a.part<span class="operator">=</span>b.part <span class="keyword">and</span> a.part<span class="operator">&gt;=</span><span class="number">1</span> <span class="keyword">and</span> a.part<span class="operator">&lt;=</span><span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<p>代码2：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">a.s_no </span><br><span class="line"><span class="keyword">from</span> student_orc_partition a </span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> </span><br><span class="line">student_orc_partition_only b </span><br><span class="line"><span class="keyword">on</span> a.s_no<span class="operator">=</span>b.s_no <span class="keyword">and</span> a.part<span class="operator">=</span>b.part </span><br><span class="line"><span class="keyword">where</span> a.part<span class="operator">&gt;=</span><span class="number">1</span> <span class="keyword">and</span> a.part<span class="operator">&lt;=</span><span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<p>我们看下上述两段代码explain dependency的输出结果：</p>
<p><strong>代码1的explain dependency结果</strong>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;input_partitions&quot;: </span><br><span class="line">[&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=0&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=1&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=2&quot;&#125;,</span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition_only@part=1&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition_only@part=2&quot;&#125;], </span><br><span class="line">&quot;input_tables&quot;: [&#123;&quot;tablename&quot;:&quot;default@student_orc_partition&quot;,&quot;tabletype&quot;:&quot;MANAGED_TABLE&quot;&#125;, &#123;&quot;tablename&quot;:&quot;default@student_orc_partition_only&quot;,&quot;tabletype&quot;:&quot;MANAGED_TABLE&quot;&#125;]&#125;</span><br></pre></td></tr></table></figure>

<p><strong>代码2的explain dependency结果</strong>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;input_partitions&quot;: </span><br><span class="line">[&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=1&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot; : &quot;default@student_orc_partition@part=2&quot;&#125;,</span><br><span class="line">&#123;&quot;partitionName&quot; :&quot;default@student_orc_partition_only@part=1&quot;&#125;,</span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition_only@part=2&quot;&#125;], </span><br><span class="line">&quot;input_tables&quot;: [&#123;&quot;tablename&quot;:&quot;default@student_orc_partition&quot;,&quot;tabletype&quot;:&quot;MANAGED_TABLE&quot;&#125;, &#123;&quot;tablename&quot;:&quot;default@student_orc_partition_only&quot;,&quot;tabletype&quot;:&quot;MANAGED_TABLE&quot;&#125;]&#125;</span><br></pre></td></tr></table></figure>

<p>通过上面的输出结果可以看到，其实上述的两个SQL并不等价，代码1在内连接（inner join）中的连接条件（on）中加入非等值的过滤条件后，并没有将内连接的左右两个表按照过滤条件进行过滤，内连接在执行时会多读取part&#x3D;0的分区数据。而在代码2中，会过滤掉不符合条件的分区。</p>
<h4 id="案例二：识别SQL读取数据范围的差别"><a href="#案例二：识别SQL读取数据范围的差别" class="headerlink" title="案例二：识别SQL读取数据范围的差别"></a>案例二：识别SQL读取数据范围的差别</h4><p>代码1：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">explain dependency</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">a.s_no </span><br><span class="line"><span class="keyword">from</span> student_orc_partition a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> </span><br><span class="line">student_orc_partition_only b </span><br><span class="line"><span class="keyword">on</span> a.s_no<span class="operator">=</span>b.s_no <span class="keyword">and</span> a.part<span class="operator">=</span>b.part <span class="keyword">and</span> b.part<span class="operator">&gt;=</span><span class="number">1</span> <span class="keyword">and</span> b.part<span class="operator">&lt;=</span><span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<p>代码2：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">explain dependency </span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">a.s_no </span><br><span class="line"><span class="keyword">from</span> student_orc_partition a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> </span><br><span class="line">student_orc_partition_only b </span><br><span class="line"><span class="keyword">on</span> a.s_no<span class="operator">=</span>b.s_no <span class="keyword">and</span> a.part<span class="operator">=</span>b.part <span class="keyword">and</span> a.part<span class="operator">&gt;=</span><span class="number">1</span> <span class="keyword">and</span> a.part<span class="operator">&lt;=</span><span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<p>以上两个代码的数据读取范围是一样的吗？答案是不一样，我们通过explain dependency来看下：</p>
<p><strong>代码1的explain dependency结果</strong>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;input_partitions&quot;: </span><br><span class="line">[&#123;&quot;partitionName&quot;: &quot;default@student_orc_partition@part=0&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=1&quot;&#125;, …中间省略<span class="number">7</span>个分区</span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=9&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition_only@part=1&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition_only@part=2&quot;&#125;], </span><br><span class="line">&quot;input_tables&quot;: [&#123;&quot;tablename&quot;:&quot;default@student_orc_partition&quot;,&quot;tabletype&quot;:&quot;MANAGED_TABLE&quot;&#125;, &#123;&quot;tablename&quot;:&quot;default@student_orc_partition_only&quot;,&quot;tabletype&quot;:&quot;MANAGED_TABLE&quot;&#125;]&#125;</span><br></pre></td></tr></table></figure>

<p><strong>代码2的explain dependency结果</strong>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;input_partitions&quot;: </span><br><span class="line">[&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=0&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=1&quot;&#125;, …中间省略<span class="number">7</span>个分区 </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition@part=9&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition_only@part=0&quot;&#125;, </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition_only@part=1&quot;&#125;, …中间省略<span class="number">7</span>个分区 </span><br><span class="line">&#123;&quot;partitionName&quot;:&quot;default@student_orc_partition_only@part=9&quot;&#125;],</span><br><span class="line">&quot;input_tables&quot;: [&#123;&quot;tablename&quot;:&quot;default@student_orc_partition&quot;,&quot;tabletype&quot;:&quot;MANAGED_TABLE&quot;&#125;, &#123;&quot;tablename&quot;:&quot;default@student_orc_partition_only&quot;,&quot;tabletype&quot;:&quot;MANAGED_TABLE&quot;&#125;]&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，对左外连接在连接条件中加入非等值过滤的条件，<strong>如果过滤条件是作用于右表（b表）有起到过滤的效果，则右表只要扫描两个分区即可，但是左表（a表）会进行全表扫描。如果过滤条件是针对左表，则完全没有起到过滤的作用，那么两个表将进行全表扫描</strong>。这时的情况就如同全外连接一样都需要对两个数据进行全表扫描。</p>
<p>在使用过程中，容易认为代码片段2可以像代码片段1一样进行数据过滤，通过查看explain dependency的输出结果，可以知道不是如此。</p>
<h3 id="3-explain-authorization-的用法"><a href="#3-explain-authorization-的用法" class="headerlink" title="3. explain authorization 的用法"></a>3. explain authorization 的用法</h3><p>通过explain authorization可以知道当前SQL访问的数据来源（INPUTS） 和数据输出（OUTPUTS），以及当前Hive的访问用户 （CURRENT_USER）和操作（OPERATION）。</p>
<p>在 hive cli 中输入以下命令：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">authorization</span> </span><br><span class="line"><span class="keyword">select</span> variance(s_score) <span class="keyword">from</span> student_tb_orc;</span><br></pre></td></tr></table></figure>

<p>结果如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">INPUTS: </span><br><span class="line">  <span class="keyword">default</span><span class="variable">@student</span>_tb_orc </span><br><span class="line">OUTPUTS: </span><br><span class="line">  hdfs:<span class="operator">/</span><span class="operator">/</span>node01:<span class="number">8020</span><span class="operator">/</span>tmp<span class="operator">/</span>hive<span class="operator">/</span>hdfs<span class="operator">/</span>cbf182a5<span class="number">-8258</span><span class="number">-4157</span><span class="number">-9194</span><span class="operator">-</span> <span class="number">90</span>f1475a3ed5<span class="operator">/</span><span class="operator">-</span>mr<span class="number">-10000</span> </span><br><span class="line"><span class="built_in">CURRENT_USER</span>: </span><br><span class="line">  hdfs </span><br><span class="line">OPERATION: </span><br><span class="line">  QUERY </span><br><span class="line">AUTHORIZATION_FAILURES: </span><br><span class="line">  <span class="keyword">No</span> privilege <span class="string">&#x27;Select&#x27;</span> found <span class="keyword">for</span> inputs &#123; database:<span class="keyword">default</span>, <span class="keyword">table</span>:student_ tb_orc, columnName:s_score&#125;</span><br></pre></td></tr></table></figure>

<p>从上面的信息可知：</p>
<p>上面案例的数据来源是defalut数据库中的 student_tb_orc表；</p>
<p>数据的输出路径是hdfs:&#x2F;&#x2F;node01:8020&#x2F;tmp&#x2F;hive&#x2F;hdfs&#x2F;cbf182a5-8258-4157-9194-90f1475a3ed5&#x2F;-mr-10000；</p>
<p>当前的操作用户是hdfs，操作是查询；</p>
<p>观察上面的信息我们还会看到AUTHORIZATION_FAILURES信息，提示对当前的输入没有查询权限，但如果运行上面的SQL的话也能够正常运行。为什么会出现这种情况？<strong>Hive在默认不配置权限管理的情况下不进行权限验证，所有的用户在Hive里面都是超级管理员，即使不对特定的用户进行赋权，也能够正常查询</strong>。</p>
<h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>通过上面对explain的介绍，可以发现explain中有很多值得我们去研究的内容，读懂 explain 的执行计划有利于我们优化Hive SQL，同时也能提升我们对SQL的掌控力。</p>
<h2 id="八、Hive-SQL底层执行原理"><a href="#八、Hive-SQL底层执行原理" class="headerlink" title="八、Hive SQL底层执行原理"></a>八、Hive SQL底层执行原理</h2><blockquote>
<p>本节结构采用宏观着眼，微观入手，从整体到细节的方式剖析 Hive SQL 底层原理。第一节先介绍 Hive 底层的整体执行流程，然后第二节介绍执行流程中的 SQL 编译成 MapReduce 的过程，第三节剖析 SQL 编译成 MapReduce 的具体实现原理。</p>
</blockquote>
<h3 id="Hive-底层执行架构"><a href="#Hive-底层执行架构" class="headerlink" title="Hive 底层执行架构"></a>Hive 底层执行架构</h3><p>我们先来看下 Hive 的底层执行架构图， Hive 的主要组件与 Hadoop 交互的过程：</p>
<div align=center><img src="Hive底层执行架构.png"></div>

<p>在 Hive 这一侧，总共有五个组件：</p>
<ol>
<li>UI：用户界面。可看作我们提交SQL语句的命令行界面。</li>
<li>DRIVER：驱动程序。接收查询的组件。该组件实现了会话句柄的概念。</li>
<li>COMPILER：编译器。负责将 SQL 转化为平台可执行的执行计划。对不同的查询块和查询表达式进行语义分析，并最终借助表和从 metastore 查找的分区元数据来生成执行计划。</li>
<li>METASTORE：元数据库。存储 Hive 中各种表和分区的所有结构信息。</li>
<li>EXECUTION ENGINE：执行引擎。负责提交 COMPILER 阶段编译好的执行计划到不同的平台上。</li>
</ol>
<p>上图的基本流程是：</p>
<p><strong>步骤1</strong>：UI 调用 DRIVER 的接口；</p>
<p><strong>步骤2</strong>：DRIVER 为查询创建会话句柄，并将查询发送到 COMPILER(编译器)生成执行计划；</p>
<p><strong>步骤3和4</strong>：编译器从元数据存储中获取本次查询所需要的元数据，该元数据用于对查询树中的表达式进行类型检查，以及基于查询谓词修建分区；</p>
<p><strong>步骤5</strong>：编译器生成的计划是分阶段的DAG，每个阶段要么是 map&#x2F;reduce 作业，要么是一个元数据或者HDFS上的操作。将生成的计划发给 DRIVER。</p>
<p>如果是 map&#x2F;reduce 作业，该计划包括 map operator trees 和一个  reduce operator tree，执行引擎将会把这些作业发送给 MapReduce ：</p>
<p><strong>步骤6、6.1、6.2和6.3</strong>：执行引擎将这些阶段提交给适当的组件。在每个 task(mapper&#x2F;reducer) 中，从HDFS文件中读取与表或中间输出相关联的数据，并通过相关算子树传递这些数据。最终这些数据通过序列化器写入到一个临时HDFS文件中（如果不需要 reduce 阶段，则在 map 中操作）。临时文件用于向计划中后面的 map&#x2F;reduce 阶段提供数据。</p>
<p><strong>步骤7、8和9</strong>：最终的临时文件将移动到表的位置，确保不读取脏数据(文件重命名在HDFS中是原子操作)。对于用户的查询，临时文件的内容由执行引擎直接从HDFS读取，然后通过Driver发送到UI。</p>
<h3 id="Hive-SQL-编译成-MapReduce-过程"><a href="#Hive-SQL-编译成-MapReduce-过程" class="headerlink" title="Hive SQL 编译成 MapReduce 过程"></a>Hive SQL 编译成 MapReduce 过程</h3><p>编译 SQL 的任务是在上节中介绍的 COMPILER（编译器组件）中完成的。Hive将SQL转化为MapReduce任务，整个编译过程分为六个阶段：</p>
<div align=center><img src="Hive SQL 编译成 MapReduce 过程.png"></div>

<ol>
<li><strong>词法、语法解析</strong>: Antlr 定义 SQL 的语法规则，完成 SQL 词法，语法解析，将 SQL 转化为抽象语法树 AST Tree；</li>
</ol>
<blockquote>
<p>Antlr是一种语言识别的工具，可以用来构造领域语言。使用Antlr构造特定的语言只需要编写一个语法文件，定义词法和语法替换规则即可，Antlr完成了词法分析、语法分析、语义分析、中间代码生成的过程。</p>
</blockquote>
<ol>
<li><strong>语义解析</strong>: 遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock；</li>
<li><strong>生成逻辑执行计划</strong>: 遍历 QueryBlock，翻译为执行操作树 OperatorTree；</li>
<li><strong>优化逻辑执行计划</strong>: 逻辑层优化器进行 OperatorTree 变换，合并 Operator，达到减少 MapReduce Job，减少数据传输及 shuffle 数据量；</li>
<li><strong>生成物理执行计划</strong>: 遍历 OperatorTree，翻译为 MapReduce 任务；</li>
<li><strong>优化物理执行计划</strong>: 物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划。</li>
</ol>
<h5 id="下面对这六个阶段详细解析："><a href="#下面对这六个阶段详细解析：" class="headerlink" title="下面对这六个阶段详细解析："></a>下面对这六个阶段详细解析：</h5><p>为便于理解，我们拿一个简单的查询语句进行展示，对5月23号的地区维表进行查询：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dim.dim_region <span class="keyword">where</span> dt <span class="operator">=</span> <span class="string">&#x27;2021-05-23&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><strong>阶段一</strong>：词法、语法解析</p>
<p>根据Antlr定义的sql语法规则，将相关sql进行词法、语法解析，转化为抽象语法树AST Tree：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">ABSTRACT SYNTAX TREE:</span><br><span class="line">TOK_QUERY</span><br><span class="line">    TOK_FROM </span><br><span class="line">    TOK_TABREF</span><br><span class="line">           TOK_TABNAME</span><br><span class="line">               dim</span><br><span class="line">                 dim_region</span><br><span class="line">    TOK_INSERT</span><br><span class="line">      TOK_DESTINATION</span><br><span class="line">          TOK_DIR</span><br><span class="line">              TOK_TMP_FILE</span><br><span class="line">        TOK_SELECT</span><br><span class="line">          TOK_SELEXPR</span><br><span class="line">              TOK_ALLCOLREF</span><br><span class="line">        TOK_WHERE</span><br><span class="line">          <span class="operator">=</span></span><br><span class="line">              TOK_TABLE_OR_COL</span><br><span class="line">                  dt</span><br><span class="line">                    <span class="string">&#x27;2021-05-23&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>阶段二</strong>：语义解析</p>
<p>遍历AST Tree，抽象出查询的基本组成单元QueryBlock：</p>
<p>AST Tree生成后由于其复杂度依旧较高，不便于翻译为mapreduce程序，需要进行进一步抽象和结构化，形成QueryBlock。</p>
<p>QueryBlock是一条SQL最基本的组成单元，包括三个部分：输入源，计算过程，输出。简单来讲一个QueryBlock就是一个子查询。</p>
<p>QueryBlock的生成过程为一个递归过程，先序遍历 AST Tree ，遇到不同的 Token 节点(理解为特殊标记)，保存到相应的属性中。</p>
<p><strong>阶段三</strong>：生成逻辑执行计划</p>
<p>遍历QueryBlock，翻译为执行操作树OperatorTree：</p>
<p>Hive最终生成的MapReduce任务，Map阶段和Reduce阶段均由OperatorTree组成。</p>
<p>基本的操作符包括：</p>
<ul>
<li>TableScanOperator</li>
<li>SelectOperator</li>
<li>FilterOperator</li>
<li>JoinOperator</li>
<li>GroupByOperator</li>
<li>ReduceSinkOperator&#96;</li>
</ul>
<p>Operator在Map Reduce阶段之间的数据传递都是一个流式的过程。每一个Operator对一行数据完成操作后之后将数据传递给childOperator计算。</p>
<p>由于Join&#x2F;GroupBy&#x2F;OrderBy均需要在Reduce阶段完成，所以在生成相应操作的Operator之前都会先生成一个ReduceSinkOperator，将字段组合并序列化为Reduce Key&#x2F;value, Partition Key。</p>
<p><strong>阶段四</strong>：优化逻辑执行计划</p>
<p>Hive中的逻辑查询优化可以大致分为以下几类：</p>
<ul>
<li>投影修剪</li>
<li>推导传递谓词</li>
<li>谓词下推</li>
<li>将Select-Select，Filter-Filter合并为单个操作</li>
<li>多路 Join</li>
<li>查询重写以适应某些列值的Join倾斜</li>
</ul>
<p><strong>阶段五</strong>：生成物理执行计划</p>
<p>生成物理执行计划即是将逻辑执行计划生成的OperatorTree转化为MapReduce Job的过程，主要分为下面几个阶段：</p>
<ol>
<li>对输出表生成MoveTask</li>
<li>从OperatorTree的其中一个根节点向下深度优先遍历</li>
<li>ReduceSinkOperator标示Map&#x2F;Reduce的界限，多个Job间的界限</li>
<li>遍历其他根节点，遇过碰到JoinOperator合并MapReduceTask</li>
<li>生成StatTask更新元数据</li>
<li>剪断Map与Reduce间的Operator的关系</li>
</ol>
<p><strong>阶段六</strong>：优化物理执行计划</p>
<p>Hive中的物理优化可以大致分为以下几类：</p>
<ul>
<li>分区修剪(Partition Pruning)</li>
<li>基于分区和桶的扫描修剪(Scan pruning)</li>
<li>如果查询基于抽样，则扫描修剪</li>
<li>在某些情况下，在 map 端应用 Group By</li>
<li>在 mapper 上执行 Join</li>
<li>优化 Union，使Union只在 map 端执行</li>
<li>在多路 Join 中，根据用户提示决定最后流哪个表</li>
<li>删除不必要的 ReduceSinkOperators</li>
<li>对于带有Limit子句的查询，减少需要为该表扫描的文件数</li>
<li>对于带有Limit子句的查询，通过限制 ReduceSinkOperator 生成的内容来限制来自 mapper 的输出</li>
<li>减少用户提交的SQL查询所需的Tez作业数量</li>
<li>如果是简单的提取查询，避免使用MapReduce作业</li>
<li>对于带有聚合的简单获取查询，执行不带 MapReduce 任务的聚合</li>
<li>重写 Group By 查询使用索引表代替原来的表</li>
<li>当表扫描之上的谓词是相等谓词且谓词中的列具有索引时，使用索引扫描</li>
</ul>
<hr>
<p>经过以上六个阶段，SQL 就被解析映射成了集群上的 MapReduce 任务。</p>
<h3 id="SQL编译成MapReduce具体原理"><a href="#SQL编译成MapReduce具体原理" class="headerlink" title="SQL编译成MapReduce具体原理"></a>SQL编译成MapReduce具体原理</h3><p>在阶段五-生成物理执行计划，即遍历 OperatorTree，翻译为 MapReduce 任务，这个过程具体是怎么转化的呢</p>
<p>我们接下来举几个常用 SQL 语句转化为 MapReduce 的具体步骤：</p>
<h5 id="Join的实现原理"><a href="#Join的实现原理" class="headerlink" title="Join的实现原理"></a>Join的实现原理</h5><p>以下面这个SQL为例，讲解 join 的实现：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> u.name, o.orderid <span class="keyword">from</span> <span class="keyword">order</span> o <span class="keyword">join</span> <span class="keyword">user</span> u <span class="keyword">on</span> o.uid <span class="operator">=</span> u.uid;</span><br></pre></td></tr></table></figure>

<p>在map的输出value中为不同表的数据打上tag标记，在reduce阶段根据tag判断数据来源。MapReduce的过程如下：</p>
<div align=center><img src="MapReduce CommonJoin的实现.png"></div>

<h5 id="Group-By的实现原理"><a href="#Group-By的实现原理" class="headerlink" title="Group By的实现原理"></a>Group By的实现原理</h5><p>以下面这个SQL为例，讲解 group by 的实现：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> rank, isonline, <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> city <span class="keyword">group</span> <span class="keyword">by</span> rank, isonline;</span><br></pre></td></tr></table></figure>

<p>将GroupBy的字段组合为map的输出key值，利用MapReduce的排序，在reduce阶段保存LastKey区分不同的key。MapReduce的过程如下:</p>
<div align=center><img src="Group By的实现原理.png"></div>

<h5 id="Distinct的实现原理"><a href="#Distinct的实现原理" class="headerlink" title="Distinct的实现原理"></a>Distinct的实现原理</h5><p>以下面这个SQL为例，讲解 distinct 的实现：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> dealid, <span class="built_in">count</span>(<span class="keyword">distinct</span> uid) num <span class="keyword">from</span> <span class="keyword">order</span> <span class="keyword">group</span> <span class="keyword">by</span> dealid;</span><br></pre></td></tr></table></figure>

<p>当只有一个distinct字段时，如果不考虑Map阶段的Hash GroupBy，只需要将GroupBy字段和Distinct字段组合为map输出key，利用mapreduce的排序，同时将GroupBy字段作为reduce的key，在reduce阶段保存LastKey即可完成去重:</p>
<div align=center><img src="Distinct的实现原理.png"></div>

<h2 id="九、Hive千亿级数据倾斜"><a href="#九、Hive千亿级数据倾斜" class="headerlink" title="九、Hive千亿级数据倾斜"></a>九、Hive千亿级数据倾斜</h2><h3 id="数据倾斜问题剖析"><a href="#数据倾斜问题剖析" class="headerlink" title="数据倾斜问题剖析"></a>数据倾斜问题剖析</h3><p>数据倾斜是分布式系统不可避免的问题，任何分布式系统都有几率发生数据倾斜，但有些小伙伴在平时工作中感知不是很明显，这里要注意本篇文章的标题—“千亿级数据”，<strong>为什么说千亿级</strong>，因为如果一个任务的数据量只有几百万，它即使发生了数据倾斜，所有数据都跑到一台机器去执行，对于几百万的数据量，一台机器执行起来还是毫无压力的，这时数据倾斜对我们感知不大，只有数据达到一个量级时，一台机器应付不了这么多的数据，这时如果发生数据倾斜，那么最后就很难算出结果。</p>
<p>所以就需要我们对数据倾斜的问题进行优化，尽量避免或减轻数据倾斜带来的影响。</p>
<blockquote>
<p>在解决数据倾斜问题之前，还要再提一句：没有瓶颈时谈论优化，都是自寻烦恼。</p>
</blockquote>
<p>大家想想，在map和reduce两个阶段中，最容易出现数据倾斜的就是reduce阶段，因为map到reduce会经过shuffle阶段，在shuffle中默认会按照key进行hash，<strong>如果相同的key过多，那么hash的结果就是大量相同的key进入到同一个reduce中</strong>，导致数据倾斜。</p>
<p>那么有没有可能在map阶段就发生数据倾斜呢，是有这种可能的。</p>
<p>一个任务中，数据文件在进入map阶段之前会进行切分，默认是128M一个数据块，但是如果<strong>当对文件使用GZIP压缩等不支持文件分割操作的压缩方式</strong>时，MR任务读取压缩后的文件时，是对它切分不了的，该压缩文件只会被一个任务所读取，如果有一个超大的不可切分的压缩文件被一个map读取时，就会发生map阶段的数据倾斜。</p>
<p>所以，从本质上来说，<strong>发生数据倾斜的原因有两种：一是任务中需要处理大量相同的key的数据。二是任务读取不可分割的大文件</strong>。</p>
<h3 id="数据倾斜解决方案"><a href="#数据倾斜解决方案" class="headerlink" title="数据倾斜解决方案"></a>数据倾斜解决方案</h3><p>MapReduce和Spark中的数据倾斜解决方案原理都是类似的，以下讨论Hive使用MapReduce引擎引发的数据倾斜，Spark数据倾斜也可以此为参照。</p>
<h3 id="1-空值引发的数据倾斜"><a href="#1-空值引发的数据倾斜" class="headerlink" title="1. 空值引发的数据倾斜"></a>1. 空值引发的数据倾斜</h3><p>实际业务中有些大量的null值或者一些无意义的数据参与到计算作业中，表中有大量的null值，如果表之间进行join操作，就会有shuffle产生，这样所有的null值都会被分配到一个reduce中，必然产生数据倾斜。</p>
<p>之前有小伙伴问，如果A、B两表join操作，假如A表中需要join的字段为null，但是B表中需要join的字段不为null，这两个字段根本就join不上啊，为什么还会放到一个reduce中呢？</p>
<p>这里我们需要明确一个概念，数据放到同一个reduce中的原因不是因为字段能不能join上，而是因为shuffle阶段的hash操作，只要key的hash结果是一样的，它们就会被拉到同一个reduce中。</p>
<p><strong>解决方案</strong>：</p>
<p>第一种：可以直接不让null值参与join操作，即不让null值有shuffle阶段</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> log a</span><br><span class="line"> <span class="keyword">JOIN</span> users b</span><br><span class="line"> <span class="keyword">ON</span> a.user_id <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">  <span class="keyword">AND</span> a.user_id <span class="operator">=</span> b.user_id</span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> log a</span><br><span class="line"><span class="keyword">WHERE</span> a.user_id <span class="keyword">IS</span> <span class="keyword">NULL</span>;</span><br></pre></td></tr></table></figure>

<p>第二种：因为null值参与shuffle时的hash结果是一样的，那么我们可以给null值随机赋值，这样它们的hash结果就不一样，就会进到不同的reduce中：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> log a</span><br><span class="line"> <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> users b <span class="keyword">ON</span> <span class="keyword">CASE</span> </span><br><span class="line">   <span class="keyword">WHEN</span> a.user_id <span class="keyword">IS</span> <span class="keyword">NULL</span> <span class="keyword">THEN</span> concat(<span class="string">&#x27;hive_&#x27;</span>, rand())</span><br><span class="line">   <span class="keyword">ELSE</span> a.user_id</span><br><span class="line">  <span class="keyword">END</span> <span class="operator">=</span> b.user_id;</span><br></pre></td></tr></table></figure>

<h3 id="2-不同数据类型引发的数据倾斜"><a href="#2-不同数据类型引发的数据倾斜" class="headerlink" title="2. 不同数据类型引发的数据倾斜"></a>2. 不同数据类型引发的数据倾斜</h3><p>对于两个表join，表a中需要join的字段key为int，表b中key字段既有string类型也有int类型。当按照key进行两个表的join操作时，默认的Hash操作会按int型的id来进行分配，这样所有的string类型都被分配成同一个id，结果就是所有的string类型的字段进入到一个reduce中，引发数据倾斜。</p>
<p><strong>解决方案</strong>：</p>
<p>如果key字段既有string类型也有int类型，默认的hash就都会按int类型来分配，那我们直接把int类型都转为string就好了，这样key字段都为string，hash时就按照string类型分配了：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> users a</span><br><span class="line"> <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> logs b <span class="keyword">ON</span> a.usr_id <span class="operator">=</span> <span class="built_in">CAST</span>(b.user_id <span class="keyword">AS</span> string);</span><br></pre></td></tr></table></figure>

<h3 id="3-不可拆分大文件引发的数据倾斜"><a href="#3-不可拆分大文件引发的数据倾斜" class="headerlink" title="3. 不可拆分大文件引发的数据倾斜"></a>3. 不可拆分大文件引发的数据倾斜</h3><p>当集群的数据量增长到一定规模，有些数据需要归档或者转储，这时候往往会对数据进行压缩；<strong>当对文件使用GZIP压缩等不支持文件分割操作的压缩方式，在日后有作业涉及读取压缩后的文件时，该压缩文件只会被一个任务所读取</strong>。如果该压缩文件很大，则处理该文件的Map需要花费的时间会远多于读取普通文件的Map时间，该Map任务会成为作业运行的瓶颈。这种情况也就是Map读取文件的数据倾斜。</p>
<p><strong>解决方案：</strong></p>
<p>这种数据倾斜问题没有什么好的解决方案，只能将使用GZIP压缩等不支持文件分割的文件转为bzip和zip等支持文件分割的压缩方式。</p>
<p>所以，<strong>我们在对文件进行压缩时，为避免因不可拆分大文件而引发数据读取的倾斜，在数据压缩的时候可以采用bzip2和Zip等支持文件分割的压缩算法</strong>。</p>
<h3 id="4-数据膨胀引发的数据倾斜"><a href="#4-数据膨胀引发的数据倾斜" class="headerlink" title="4. 数据膨胀引发的数据倾斜"></a>4. 数据膨胀引发的数据倾斜</h3><p>在多维聚合计算时，如果进行分组聚合的字段过多，如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a，b，c，count（<span class="number">1</span>）<span class="keyword">from</span> log <span class="keyword">group</span> <span class="keyword">by</span> a，b，c <span class="keyword">with</span> <span class="keyword">rollup</span>;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：对于最后的<code>with rollup</code>关键字不知道大家用过没，with rollup是用来在分组统计数据的基础上再进行统计汇总，即用来得到group by的汇总信息。</p>
</blockquote>
<p>如果上面的log表的数据量很大，并且Map端的聚合不能很好地起到数据压缩的情况下，会导致Map端产出的数据急速膨胀，这种情况容易导致作业内存溢出的异常。如果log表含有数据倾斜key，会加剧Shuffle过程的数据倾斜。</p>
<p><strong>解决方案</strong>：</p>
<p>可以拆分上面的sql，将<code>with rollup</code>拆分成如下几个sql：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a, b, c, <span class="built_in">COUNT</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">FROM</span> log</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> a, b, c;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> a, b, <span class="keyword">NULL</span>, <span class="built_in">COUNT</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">FROM</span> log</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> a, b;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> a, <span class="keyword">NULL</span>, <span class="keyword">NULL</span>, <span class="built_in">COUNT</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">FROM</span> log</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> a;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">NULL</span>, <span class="keyword">NULL</span>, <span class="keyword">NULL</span>, <span class="built_in">COUNT</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">FROM</span> log;</span><br></pre></td></tr></table></figure>

<p>但是，上面这种方式不太好，因为现在是对3个字段进行分组聚合，那如果是5个或者10个字段呢，那么需要拆解的SQL语句会更多。</p>
<p>在Hive中可以通过参数 <code>hive.new.job.grouping.set.cardinality</code> 配置的方式自动控制作业的拆解，该参数默认值是30。表示针对grouping sets&#x2F;rollups&#x2F;cubes这类多维聚合的操作，如果最后拆解的键组合大于该值，会启用新的任务去处理大于该值之外的组合。如果在处理数据时，某个分组聚合的列有较大的倾斜，可以适当调小该值。</p>
<h3 id="5-表连接时引发的数据倾斜"><a href="#5-表连接时引发的数据倾斜" class="headerlink" title="5. 表连接时引发的数据倾斜"></a>5. 表连接时引发的数据倾斜</h3><p>两表进行普通的repartition join时，如果表连接的键存在倾斜，那么在 Shuffle 阶段必然会引起数据倾斜。</p>
<p><strong>解决方案</strong>：</p>
<p>通常做法是将倾斜的数据存到分布式缓存中，分发到各个 Map任务所在节点。在Map阶段完成join操作，即MapJoin，这避免了 Shuffle，从而避免了数据倾斜。</p>
<blockquote>
<p>MapJoin是Hive的一种优化操作，<strong>其适用于小表JOIN大表的场景</strong>，由于表的JOIN操作是在Map端且在内存进行的，所以其并不需要启动Reduce任务也就不需要经过shuffle阶段，从而能在一定程度上节省资源提高JOIN效率。</p>
</blockquote>
<p>在Hive 0.11版本之前，如果想在Map阶段完成join操作，必须使用MAPJOIN来标记显示地启动该优化操作，<strong>由于其需要将小表加载进内存所以要注意小表的大小</strong>。</p>
<p>如将a表放到Map端内存中执行，在Hive 0.11版本之前需要这样写：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="comment">/* +mapjoin(a) */</span> a.id , a.name, b.age </span><br><span class="line"><span class="keyword">from</span> a <span class="keyword">join</span> b </span><br><span class="line"><span class="keyword">on</span> a.id <span class="operator">=</span> b.id;</span><br></pre></td></tr></table></figure>

<p>如果想将多个表放到Map端内存中，只需在mapjoin()中写多个表名称即可，用逗号分隔，如将a表和c表放到Map端内存中，则 <code>/* +mapjoin(a,c) */</code> 。</p>
<p>在Hive 0.11版本及之后，Hive默认启动该优化，也就是不在需要显示的使用MAPJOIN标记，其会在必要的时候触发该优化操作将普通JOIN转换成MapJoin，可以通过以下两个属性来设置该优化的触发时机：</p>
<p><code>hive.auto.convert.join=true</code> 默认值为true，自动开启MAPJOIN优化。</p>
<p><code>hive.mapjoin.smalltable.filesize=2500000</code> 默认值为2500000(25M)，通过配置该属性来确定使用该优化的表的大小，如果表的大小小于此值就会被加载进内存中。</p>
<p><strong>注意</strong>：使用默认启动该优化的方式如果出现莫名其妙的BUG(比如MAPJOIN并不起作用)，就将以下两个属性置为fase手动使用MAPJOIN标记来启动该优化:</p>
<p><code>hive.auto.convert.join=false</code> (关闭自动MAPJOIN转换操作)</p>
<p><code>hive.ignore.mapjoin.hint=false</code> (不忽略MAPJOIN标记)</p>
<p>再提一句：将表放到Map端内存时，如果节点的内存很大，但还是出现内存溢出的情况，我们可以通过这个参数 <code>mapreduce.map.memory.mb</code> 调节Map端内存的大小。</p>
<h3 id="6-确实无法减少数据量引发的数据倾斜"><a href="#6-确实无法减少数据量引发的数据倾斜" class="headerlink" title="6. 确实无法减少数据量引发的数据倾斜"></a>6. 确实无法减少数据量引发的数据倾斜</h3><p>在一些操作中，我们没有办法减少数据量，如在使用 collect_list 函数时：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> s_age,collect_list(s_score) list_score</span><br><span class="line"><span class="keyword">from</span> student</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> s_age</span><br></pre></td></tr></table></figure>

<blockquote>
<p>collect_list：将分组中的某列转为一个数组返回。</p>
</blockquote>
<p>在上述sql中，s_age有数据倾斜，但如果数据量大到一定的数量，会导致处理倾斜的Reduce任务产生内存溢出的异常。</p>
<blockquote>
<p>collect_list输出一个数组，中间结果会放到内存中，所以如果collect_list聚合太多数据，会导致内存溢出。</p>
</blockquote>
<p>有小伙伴说这是 group by 分组引起的数据倾斜，可以开启<code>hive.groupby.skewindata</code>参数来优化。我们接下来分析下：</p>
<p>开启该配置会将作业拆解成两个作业，第一个作业会尽可能将Map的数据平均分配到Reduce阶段，并在这个阶段实现数据的预聚合，以减少第二个作业处理的数据量；第二个作业在第一个作业处理的数据基础上进行结果的聚合。</p>
<p><code>hive.groupby.skewindata</code>的核心作用在于生成的第一个作业能够有效减少数量。但是对于collect_list这类要求全量操作所有数据的中间结果的函数来说，明显起不到作用，反而因为引入新的作业增加了磁盘和网络I&#x2F;O的负担，而导致性能变得更为低下。</p>
<p><strong>解决方案</strong>：</p>
<p>这类问题最直接的方式就是调整reduce所执行的内存大小。</p>
<p>调整reduce的内存大小使用<code>mapreduce.reduce.memory.mb</code>这个配置。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过上面的内容我们发现，<strong>shuffle阶段堪称性能的杀手</strong>，为什么这么说，一方面shuffle阶段是最容易引起数据倾斜的；另一方面shuffle的过程中会产生大量的磁盘I&#x2F;O、网络I&#x2F;O 以及压缩、解压缩、序列化和反序列化等。这些操作都是严重影响性能的。</p>
<p>所以围绕shuffle和数据倾斜有很多的调优点：</p>
<ul>
<li>Mapper 端的Buffer 设置为多大？Buffer 设置得大，可提升性能，减少磁盘I&#x2F;O ，但 是对内存有要求，对GC 有压力；Buffer 设置得小，可能不占用那么多内存， 但是可能频繁的磁盘I&#x2F;O 、频繁的网络I&#x2F;O 。</li>
</ul>
<h2 id="十、Hive企业级性能优化"><a href="#十、Hive企业级性能优化" class="headerlink" title="十、Hive企业级性能优化"></a>十、Hive企业级性能优化</h2><h2 id="Hive性能问题排查的方式"><a href="#Hive性能问题排查的方式" class="headerlink" title="Hive性能问题排查的方式"></a>Hive性能问题排查的方式</h2><p>当我们发现一条SQL语句执行时间过长或者不合理时，我们就要考虑对SQL进行优化，优化首先得进行问题排查，那么我们可以通过哪些方式进行排查呢。</p>
<p>经常使用关系型数据库的同学可能知道关系型数据库的优化的诀窍-<strong>看执行计划</strong>。如Oracle数据库，它有多种类型的执行计划，通过多种执行计划的配合使用，可以看到根据统计信息推演的执行计划，即Oracle推断出来的未真正运行的执行计划；还可以看到实际执行任务的执行计划；能够观察到从数据读取到最终呈现的主要过程和中间的量化数据。可以说，在Oracle开发领域，掌握合适的环节，选用不同的执行计划，SQL调优就不是一件难事。</p>
<p>Hive中也有执行计划，但是Hive的执行计划都是预测的，这点不像Oracle和SQL Server有真实的计划，可以看到每个阶段的处理数据、消耗的资源和处理的时间等量化数据。Hive提供的执行计划没有这些数据，这意味着虽然Hive的使用者知道整个SQL的执行逻辑，但是各阶段耗用的资源状况和整个SQL的执行瓶颈在哪里是不清楚的。</p>
<p>想要知道HiveSQL所有阶段的运行信息，可以查看<strong>YARN提供的日志</strong>。查看日志的链接，可以在每个作业执行后，在控制台打印的信息中找到。如下图所示：</p>
<div align=center><img src="YARN提供的日志.png"></div>

<p><strong>Hive提供的执行计划目前可以查看的信息有以下几种</strong>：</p>
<ol>
<li>查看执行计划的基本信息，即explain；</li>
<li>查看执行计划的扩展信息，即explain extended；</li>
<li>查看SQL数据输入依赖的信息，即explain dependency；</li>
<li>查看SQL操作相关权限的信息，即explain authorization；</li>
<li>查看SQL的向量化描述信息，即explain vectorization。</li>
</ol>
<p>在查询语句的SQL前面加上关键字explain是查看执行计划的基本方法。用explain打开的执行计划包含以下两部分：</p>
<ul>
<li>作业的依赖关系图，即STAGE DEPENDENCIES；</li>
<li>每个作业的详细信息，即STAGE PLANS。</li>
</ul>
<p><strong>Hive中的explain执行计划详解可看我之前写的这篇文章</strong>：</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2MzU2MDYzOA==&mid=2247484152&idx=1&sn=7e48aa4a9650481f960c6cac234977a4&scene=21#wechat_redirect">Hive底层原理：explain执行计划详解</a></p>
<blockquote>
<p>注：使用explain查看执行计划是Hive性能调优中非常重要的一种方式，请务必掌握！</p>
</blockquote>
<p><strong>总结：Hive对SQL语句性能问题排查的方式</strong>：</p>
<ol>
<li>使用explain查看执行计划；</li>
<li>查看YARN提供的日志。</li>
</ol>
<h2 id="Hive性能调优的方式"><a href="#Hive性能调优的方式" class="headerlink" title="Hive性能调优的方式"></a>Hive性能调优的方式</h2><p>为什么都说性能优化这项工作是比较难的，因为一项技术的优化，必然是一项综合性的工作，它是多门技术的结合。我们如果只局限于一种技术，那么肯定做不好优化的。</p>
<p>下面将从多个完全不同的角度来介绍Hive优化的多样性，我们先来一起感受下。</p>
<h3 id="1-SQL语句优化"><a href="#1-SQL语句优化" class="headerlink" title="1. SQL语句优化"></a>1. SQL语句优化</h3><p>SQL语句优化涉及到的内容太多，因篇幅有限，不能一一介绍到，所以就拿几个典型举例，让大家学到这种思想，以后遇到类似调优问题可以往这几个方面多思考下。</p>
<h4 id="1-union-all"><a href="#1-union-all" class="headerlink" title="1. union all"></a>1. union all</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> stu <span class="keyword">partition</span>(tp) </span><br><span class="line"><span class="keyword">select</span> s_age,<span class="built_in">max</span>(s_birth) stat,<span class="string">&#x27;max&#x27;</span> tp </span><br><span class="line"><span class="keyword">from</span> stu_ori</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> s_age</span><br><span class="line"></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> stu <span class="keyword">partition</span>(tp) </span><br><span class="line"><span class="keyword">select</span> s_age,<span class="built_in">min</span>(s_birth) stat,<span class="string">&#x27;min&#x27;</span> tp </span><br><span class="line"><span class="keyword">from</span> stu_ori</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> s_age;</span><br></pre></td></tr></table></figure>

<p>我们简单分析上面的SQl语句，就是将每个年龄的最大和最小的生日获取出来放到同一张表中，union all 前后的两个语句都是对同一张表按照s_age进行分组，然后分别取最大值和最小值。对同一张表相同的字段进行两次分组，这造成了极大浪费，我们能不能改造下呢，当然是可以的，为大家介绍一个语法：<code>from ... insert into ...</code> ，这个语法将from前置，作用就是使用一张表，可以进行多次插入操作：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--开启动态分区 </span></span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition<span class="operator">=</span><span class="literal">true</span>; </span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode<span class="operator">=</span>nonstrict; </span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> stu_ori </span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> stu <span class="keyword">partition</span>(tp) </span><br><span class="line"><span class="keyword">select</span> s_age,<span class="built_in">max</span>(s_birth) stat,<span class="string">&#x27;max&#x27;</span> tp </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> s_age</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> stu <span class="keyword">partition</span>(tp) </span><br><span class="line"><span class="keyword">select</span> s_age,<span class="built_in">min</span>(s_birth) stat,<span class="string">&#x27;min&#x27;</span> tp </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> s_age;</span><br></pre></td></tr></table></figure>

<p>上面的SQL就可以对stu_ori表的s_age字段分组一次而进行两次不同的插入操作。</p>
<p><strong>这个例子告诉我们一定要多了解SQL语句，如果我们不知道这种语法，一定不会想到这种方式的</strong>。</p>
<h4 id="2-distinct"><a href="#2-distinct" class="headerlink" title="2. distinct"></a>2. distinct</h4><p>先看一个SQL，去重计数：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) </span><br><span class="line"><span class="keyword">from</span>( </span><br><span class="line">  <span class="keyword">select</span> s_age </span><br><span class="line">  <span class="keyword">from</span> stu </span><br><span class="line">  <span class="keyword">group</span> <span class="keyword">by</span> s_age </span><br><span class="line">) b;</span><br></pre></td></tr></table></figure>

<p>这是简单统计年龄的枚举值个数，为什么不用distinct？</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="keyword">distinct</span> s_age) </span><br><span class="line"><span class="keyword">from</span> stu;</span><br></pre></td></tr></table></figure>

<p>有人说因为在数据量特别大的情况下使用第一种方式能够有效避免Reduce端的数据倾斜，但是事实如此吗？</p>
<p>我们先不管数据量特别大这个问题，<strong>就当前的业务和环境下使用distinct一定会比上面那种子查询的方式效率高</strong>。原因有以下几点：</p>
<ol>
<li>上面进行去重的字段是年龄字段，要知道年龄的枚举值是非常有限的，就算计算1岁到100岁之间的年龄，s_age的最大枚举值才是100，如果转化成MapReduce来解释的话，在Map阶段，每个Map会对s_age去重。由于s_age枚举值有限，因而每个Map得到的s_age也有限，最终得到reduce的数据量也就是map数量*s_age枚举值的个数。</li>
<li>distinct的命令会在内存中构建一个hashtable，查找去重的时间复杂度是O(1)；group by在不同版本间变动比较大，有的版本会用构建hashtable的形式去重，有的版本会通过排序的方式， 排序最优时间复杂度无法到O(1)。另外，第一种方式(group by)去重会转化为两个任务，会消耗更多的磁盘网络I&#x2F;O资源。</li>
<li>最新的Hive 3.0中新增了 count(distinct ) 优化，通过配置 <code>hive.optimize.countdistinct</code>，即使真的出现数据倾斜也可以自动优化，自动改变SQL执行的逻辑。</li>
<li>第二种方式(distinct)比第一种方式(group by)代码简洁，表达的意思简单明了，如果没有特殊的问题，代码简洁就是优！</li>
</ol>
<p><strong>这个例子告诉我们，有时候我们不要过度优化，调优讲究适时调优，过早进行调优有可能做的是无用功甚至产生负效应，在调优上投入的工作成本和回报不成正比。调优需要遵循一定的原则</strong>。</p>
<h3 id="2-数据格式优化"><a href="#2-数据格式优化" class="headerlink" title="2. 数据格式优化"></a>2. 数据格式优化</h3><p>Hive提供了多种数据存储组织格式，不同格式对程序的运行效率也会有极大的影响。</p>
<p>Hive提供的格式有TEXT、SequenceFile、RCFile、ORC和Parquet等。</p>
<p>SequenceFile是一个二进制key&#x2F;value对结构的平面文件，在早期的Hadoop平台上被广泛用于MapReduce输出&#x2F;输出格式，以及作为数据存储格式。</p>
<p>Parquet是一种列式数据存储格式，可以兼容多种计算引擎，如MapRedcue和Spark等，对多层嵌套的数据结构提供了良好的性能支持，是目前Hive生产环境中数据存储的主流选择之一。</p>
<p>ORC优化是对RCFile的一种优化，它提供了一种高效的方式来存储Hive数据，同时也能够提高Hive的读取、写入和处理数据的性能，能够兼容多种计算引擎。事实上，在实际的生产环境中，ORC已经成为了Hive在数据存储上的主流选择之一。</p>
<p>我们使用同样数据及SQL语句，只是数据存储格式不同，得到如下执行时长：</p>
<table>
<thead>
<tr>
<th align="center">数据格式</th>
<th align="center">CPU时间</th>
<th align="center">用户等待耗时</th>
</tr>
</thead>
<tbody><tr>
<td align="center">TextFile</td>
<td align="center">33分</td>
<td align="center">171秒</td>
</tr>
<tr>
<td align="center">SequenceFile</td>
<td align="center">38分</td>
<td align="center">162秒</td>
</tr>
<tr>
<td align="center">Parquet</td>
<td align="center">2分22秒</td>
<td align="center">50秒</td>
</tr>
<tr>
<td align="center">ORC</td>
<td align="center">1分52秒</td>
<td align="center">56秒</td>
</tr>
</tbody></table>
<blockquote>
<p>注：CPU时间：表示运行程序所占用服务器CPU资源的时间。<br>用户等待耗时：记录的是用户从提交作业到返回结果期间用户等待的所有时间。</p>
</blockquote>
<p><strong>查询TextFile类型的数据表耗时33分钟， 查询ORC类型的表耗时1分52秒，时间得以极大缩短，可见不同的数据存储格式也能给HiveSQL性能带来极大的影响。</strong></p>
<h3 id="3-小文件过多优化"><a href="#3-小文件过多优化" class="headerlink" title="3. 小文件过多优化"></a>3. 小文件过多优化</h3><p>小文件如果过多，对 hive 来说，在进行查询时，每个小文件都会当成一个块，启动一个Map任务来完成，而一个Map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的Map数量是受限的。</p>
<p>所以我们有必要对小文件过多进行优化，关于小文件过多的解决的办法，我之前专门写了一篇文章讲解，具体可查看：</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2MzU2MDYzOA==&mid=2247483683&idx=1&sn=14b25010032bdf0d375080e48de36d7f&scene=21#wechat_redirect">解决hive小文件过多问题</a></p>
<h3 id="4-并行执行优化"><a href="#4-并行执行优化" class="headerlink" title="4. 并行执行优化"></a>4. 并行执行优化</h3><p>Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。如果有更多的阶段可以并行执行，那么job可能就越快完成。</p>
<p>通过设置参数hive.exec.parallel值为true，就可以开启并发执行。在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.parallel<span class="operator">=</span><span class="literal">true</span>; <span class="operator">/</span><span class="operator">/</span>打开任务并行执行</span><br><span class="line"><span class="keyword">set</span> hive.exec.parallel.thread.number<span class="operator">=</span><span class="number">16</span>; <span class="operator">/</span><span class="operator">/</span>同一个<span class="keyword">sql</span>允许最大并行度，默认为<span class="number">8</span>。</span><br></pre></td></tr></table></figure>

<p>当然得是在系统资源比较空闲的时候才有优势，否则没资源，并行也起不来。</p>
<h3 id="5-JVM优化"><a href="#5-JVM优化" class="headerlink" title="5. JVM优化"></a>5. JVM优化</h3><p>JVM重用是Hadoop调优参数的内容，其对Hive的性能具有非常大的影响，特别是对于很难避免小文件的场景或task特别多的场景，这类场景大多数执行时间都很短。</p>
<p>Hadoop的默认配置通常是使用派生JVM来执行map和Reduce任务的。这时JVM的启动过程可能会造成相当大的开销，尤其是执行的job包含有成百上千task任务的情况。JVM重用可以使得JVM实例在同一个job中重新使用N次。N的值可以在Hadoop的<code>mapred-site.xml</code>文件中进行配置。通常在10-20之间，具体多少需要根据具体业务场景测试得出。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.jvm.numtasks<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>How many tasks to run per jvm. If set to -1, there is</span><br><span class="line">  no limit. </span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>我们也可以在hive中设置</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span>  mapred.job.reuse.jvm.num.tasks<span class="operator">=</span><span class="number">10</span>; <span class="operator">/</span><span class="operator">/</span>这个设置来设置我们的jvm重用</span><br></pre></td></tr></table></figure>

<p>这个功能的缺点是，开启JVM重用将一直占用使用到的task插槽，以便进行重用，直到任务完成后才能释放。如果某个“不平衡的”job中有某几个reduce task执行的时间要比其他Reduce task消耗的时间多的多的话，那么保留的插槽就会一直空闲着却无法被其他的job使用，直到所有的task都结束了才会释放。</p>
<h3 id="6-推测执行优化"><a href="#6-推测执行优化" class="headerlink" title="6. 推测执行优化"></a>6. 推测执行优化</h3><p>在分布式集群环境下，因为程序Bug（包括Hadoop本身的bug），负载不均衡或者资源分布不均等原因，会造成同一个作业的多个任务之间运行速度不一致，有些任务的运行速度可能明显慢于其他任务（比如一个作业的某个任务进度只有50%，而其他所有任务已经运行完毕），则这些任务会拖慢作业的整体执行进度。为了避免这种情况发生，Hadoop采用了推测执行（Speculative Execution）机制，它根据一定的法则推测出“拖后腿”的任务，并为这样的任务启动一个备份任务，让该任务与原始任务同时处理同一份数据，并最终选用最先成功运行完成任务的计算结果作为最终结果。</p>
<p>设置开启推测执行参数：Hadoop的<code>mapred-site.xml</code>文件中进行配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some map tasks </span><br><span class="line">               may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some reduce tasks </span><br><span class="line">               may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>hive本身也提供了配置项来控制reduce-side的推测执行:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.mapred.reduce.tasks.speculative.execution<span class="operator">=</span><span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>关于调优这些推测执行变量，还很难给一个具体的建议。如果用户对于运行时的偏差非常敏感的话，那么可以将这些功能关闭掉。如果用户因为输入数据量很大而需要执行长时间的map或者Reduce task的话，那么启动推测执行造成的浪费是非常巨大大。</p>
<h4 id="最后-1"><a href="#最后-1" class="headerlink" title="最后"></a>最后</h4><p>代码优化原则：</p>
<ul>
<li>理透需求原则，这是优化的根本；</li>
<li>把握数据全链路原则，这是优化的脉络；</li>
<li>坚持代码的简洁原则，这让优化更加简单；</li>
<li>没有瓶颈时谈论优化，这是自寻烦恼。</li>
</ul>
<h2 id="十一、Hive大厂面试真题"><a href="#十一、Hive大厂面试真题" class="headerlink" title="十一、Hive大厂面试真题"></a>十一、Hive大厂面试真题</h2><h3 id="1-hive内部表和外部表的区别"><a href="#1-hive内部表和外部表的区别" class="headerlink" title="1. hive内部表和外部表的区别"></a>1. hive内部表和外部表的区别</h3><p>未被external修饰的是内部表，被external修饰的为外部表。</p>
<blockquote>
<p>本文首发于公众号【五分钟学大数据】，关注公众号，获取最新大数据技术文章</p>
</blockquote>
<p><strong>区别</strong>：</p>
<ol>
<li>内部表数据由Hive自身管理，外部表数据由HDFS管理；</li>
<li>内部表数据存储的位置是<code>hive.metastore.warehouse.dir</code>（默认：<code>/user/hive/warehouse</code>），外部表数据的存储位置由自己制定（如果没有LOCATION，Hive将在HDFS上的<code>/user/hive/warehouse</code>文件夹下以外部表的表名创建一个文件夹，并将属于这个表的数据存放在这里）；</li>
<li><strong>删除内部表会直接删除元数据（metadata）及存储数据；删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除</strong>。</li>
</ol>
<blockquote>
<p>本文首发于公众号【五分钟学大数据】</p>
</blockquote>
<h3 id="2-Hive有索引吗"><a href="#2-Hive有索引吗" class="headerlink" title="2. Hive有索引吗"></a>2. Hive有索引吗</h3><p>Hive支持索引（3.0版本之前），但是Hive的索引与关系型数据库中的索引并不相同，比如，Hive不支持主键或者外键。并且Hive索引提供的功能很有限，效率也并不高，因此Hive索引很少使用。</p>
<ul>
<li>索引适用的场景：</li>
</ul>
<p>适用于不更新的静态字段。以免总是重建索引数据。每次建立、更新数据后，都要重建索引以构建索引表。</p>
<ul>
<li>Hive索引的机制如下：</li>
</ul>
<p>hive在指定列上建立索引，会产生一张索引表（Hive的一张物理表），里面的字段包括：索引列的值、该值对应的HDFS文件路径、该值在文件中的偏移量。</p>
<p>Hive 0.8版本后引入bitmap索引处理器，这个处理器适用于去重后，值较少的列（例如，某字段的取值只可能是几个枚举值） 因为索引是用空间换时间，索引列的取值过多会导致建立bitmap索引表过大。</p>
<p><strong>注意</strong>：Hive中每次有数据时需要及时更新索引，相当于重建一个新表，否则会影响数据查询的效率和准确性，<strong>Hive官方文档已经明确表示Hive的索引不推荐被使用，在新版本的Hive中已经被废弃了</strong>。</p>
<p><strong>扩展</strong>：Hive是在0.7版本之后支持索引的，在0.8版本后引入bitmap索引处理器，在3.0版本开始移除索引的功能，取而代之的是2.3版本开始的物化视图，自动重写的物化视图替代了索引的功能。</p>
<h3 id="3-运维如何对hive进行调度"><a href="#3-运维如何对hive进行调度" class="headerlink" title="3. 运维如何对hive进行调度"></a>3. 运维如何对hive进行调度</h3><ol>
<li>将hive的sql定义在脚本当中；</li>
<li>使用azkaban或者oozie进行任务的调度；</li>
<li>监控任务调度页面。</li>
</ol>
<h3 id="4-ORC、Parquet等列式存储的优点"><a href="#4-ORC、Parquet等列式存储的优点" class="headerlink" title="4. ORC、Parquet等列式存储的优点"></a>4. ORC、Parquet等列式存储的优点</h3><p>ORC和Parquet都是高性能的存储方式，这两种存储格式总会带来存储和性能上的提升。</p>
<p><strong>Parquet</strong>:</p>
<ol>
<li>Parquet支持嵌套的数据模型，类似于Protocol Buffers，每一个数据模型的schema包含多个字段，每一个字段有三个属性：重复次数、数据类型和字段名。<br>重复次数可以是以下三种：required(只出现1次)，repeated(出现0次或多次)，optional(出现0次或1次)。每一个字段的数据类型可以分成两种：group(复杂类型)和primitive(基本类型)。</li>
<li>Parquet中没有Map、Array这样的复杂数据结构，但是可以通过repeated和group组合来实现的。</li>
<li>由于Parquet支持的数据模型比较松散，可能一条记录中存在比较深的嵌套关系，如果为每一条记录都维护一个类似的树状结可能会占用较大的存储空间，因此Dremel论文中提出了一种高效的对于嵌套数据格式的压缩算法：Striping&#x2F;Assembly算法。通过Striping&#x2F;Assembly算法，parquet可以使用较少的存储空间表示复杂的嵌套格式，并且通常Repetition level和Definition level都是较小的整数值，可以通过RLE算法对其进行压缩，进一步降低存储空间。</li>
<li>Parquet文件是以二进制方式存储的，是不可以直接读取和修改的，Parquet文件是自解析的，文件中包括该文件的数据和元数据。</li>
</ol>
<p><strong>ORC</strong>:</p>
<ol>
<li>ORC文件是自描述的，它的元数据使用Protocol Buffers序列化，并且文件中的数据尽可能的压缩以降低存储空间的消耗。</li>
<li>和Parquet类似，ORC文件也是以二进制方式存储的，所以是不可以直接读取，ORC文件也是自解析的，它包含许多的元数据，这些元数据都是同构ProtoBuffer进行序列化的。</li>
<li>ORC会尽可能合并多个离散的区间尽可能的减少I&#x2F;O次数。</li>
<li>ORC中使用了更加精确的索引信息，使得在读取数据时可以指定从任意一行开始读取，更细粒度的统计信息使得读取ORC文件跳过整个row group，ORC默认会对任何一块数据和索引信息使用ZLIB压缩，因此ORC文件占用的存储空间也更小。</li>
<li>在新版本的ORC中也加入了对Bloom Filter的支持，它可以进一 步提升谓词下推的效率，在Hive 1.2.0版本以后也加入了对此的支 持。</li>
</ol>
<h3 id="5-数据建模用的哪些模型？"><a href="#5-数据建模用的哪些模型？" class="headerlink" title="5. 数据建模用的哪些模型？"></a>5. 数据建模用的哪些模型？</h3><h5 id="1-星型模型"><a href="#1-星型模型" class="headerlink" title="1. 星型模型"></a>1. 星型模型</h5><div align=center><img src="星型模型.png"></div>

<p>星形模式(Star Schema)是最常用的维度建模方式。星型模式是以事实表为中心，所有的维度表直接连接在事实表上，像星星一样。星形模式的维度建模由一个事实表和一组维表成，且具有以下特点：</p>
<p>a. 维表只和事实表关联，维表之间没有关联；</p>
<p>b. 每个维表主键为单列，且该主键放置在事实表中，作为两边连接的外键；</p>
<p>c. 以事实表为核心，维表围绕核心呈星形分布。</p>
<h5 id="2-雪花模型"><a href="#2-雪花模型" class="headerlink" title="2. 雪花模型"></a>2. 雪花模型</h5><div align=center><img src="雪花模型.png"></div>

<p>雪花模式(Snowflake Schema)是对星形模式的扩展。<strong>雪花模式的维度表可以拥有其他维度表的</strong>，虽然这种模型相比星型更规范一些，但是由于这种模型不太容易理解，维护成本比较高，而且性能方面需要关联多层维表，性能比星型模型要低。</p>
<h5 id="3-星座模型"><a href="#3-星座模型" class="headerlink" title="3. 星座模型"></a>3. 星座模型</h5><div align=center><img src="星座模型.png"></div>

<p>星座模式是星型模式延伸而来，星型模式是基于一张事实表的，而<strong>星座模式是基于多张事实表的，而且共享维度信息</strong>。前面介绍的两种维度建模方法都是多维表对应单事实表，但在很多时候维度空间内的事实表不止一个，而一个维表也可能被多个事实表用到。在业务发展后期，绝大部分维度建模都采用的是星座模式。</p>
<p>数仓建模详细介绍可查看：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2MzU2MDYzOA==&mid=2247485022&idx=1&sn=92890bec74a7ee61ea1b2dbf89f19ada&scene=21#wechat_redirect">通俗易懂数仓建模</a></p>
<h3 id="6-为什么要对数据仓库分层？"><a href="#6-为什么要对数据仓库分层？" class="headerlink" title="6. 为什么要对数据仓库分层？"></a>6. 为什么要对数据仓库分层？</h3><ul>
<li><strong>用空间换时间</strong>，通过大量的预处理来提升应用系统的用户体验（效率），因此数据仓库会存在大量冗余的数据。</li>
<li>如果不分层的话，如果源业务系统的业务规则发生变化将会影响整个数据清洗过程，工作量巨大。</li>
<li><strong>通过数据分层管理可以简化数据清洗的过程</strong>，因为把原来一步的工作分到了多个步骤去完成，相当于把一个复杂的工作拆成了多个简单的工作，把一个大的黑盒变成了一个白盒，每一层的处理逻辑都相对简单和容易理解，这样我们比较容易保证每一个步骤的正确性，当数据发生错误的时候，往往我们只需要局部调整某个步骤即可。</li>
</ul>
<p>数据仓库详细介绍可查看：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2MzU2MDYzOA==&mid=2247484692&idx=1&sn=f624672e62ba6cd4cc69bdb6db28756a&scene=21#wechat_redirect">万字详解整个数据仓库建设体系</a></p>
<h3 id="7-使用过Hive解析JSON串吗"><a href="#7-使用过Hive解析JSON串吗" class="headerlink" title="7. 使用过Hive解析JSON串吗"></a>7. 使用过Hive解析JSON串吗</h3><p><strong>Hive处理json数据总体来说有两个方向的路走</strong>：</p>
<ol>
<li>将json以字符串的方式整个入Hive表，然后通过使用UDF函数解析已经导入到hive中的数据，比如使用<code>LATERAL VIEW json_tuple</code>的方法，获取所需要的列名。</li>
<li>在导入之前将json拆成各个字段，导入Hive表的数据是已经解析过的。这将需要使用第三方的 SerDe。</li>
</ol>
<p>详细介绍可查看：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2MzU2MDYzOA==&mid=2247485175&idx=1&sn=63f58dc2946678d4e50eb6e7bb3ff745&scene=21#wechat_redirect">Hive解析Json数组超全讲解</a></p>
<h3 id="8-sort-by-和-order-by-的区别"><a href="#8-sort-by-和-order-by-的区别" class="headerlink" title="8. sort by 和 order by 的区别"></a>8. sort by 和 order by 的区别</h3><p><strong>order by 会对输入做全局排序，因此只有一个reducer</strong>（多个reducer无法保证全局有序）只有一个reducer，会导致当输入规模较大时，需要较长的计算时间。</p>
<p>sort by不是全局排序，其在数据进入reducer前完成排序. 因此，如果用sort by进行排序，并且设置mapred.reduce.tasks&gt;1， 则<strong>sort by只保证每个reducer的输出有序，不保证全局有序</strong>。</p>
<h3 id="9-数据倾斜怎么解决"><a href="#9-数据倾斜怎么解决" class="headerlink" title="9. 数据倾斜怎么解决"></a>9. 数据倾斜怎么解决</h3><p>数据倾斜问题主要有以下几种：</p>
<ol>
<li>空值引发的数据倾斜</li>
<li>不同数据类型引发的数据倾斜</li>
<li>不可拆分大文件引发的数据倾斜</li>
<li>数据膨胀引发的数据倾斜</li>
<li>表连接时引发的数据倾斜</li>
<li>确实无法减少数据量引发的数据倾斜</li>
</ol>
<p>以上倾斜问题的具体解决方案可查看：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2MzU2MDYzOA==&mid=2247485154&idx=1&sn=cd7129544497c1a621e49dbc1d7ed5c3&scene=21#wechat_redirect">Hive千亿级数据倾斜解决方案</a></p>
<p><strong>注意</strong>：对于 left join 或者 right join 来说，不会对关联的字段自动去除null值，对于 inner join 来说，会对关联的字段自动去除null值。</p>
<p>小伙伴们在阅读时注意下，在上面的文章（Hive千亿级数据倾斜解决方案）中，有一处sql出现了上述问题（举例的时候原本是想使用left join的，结果手误写成了join）。此问题由公众号读者发现，感谢这位读者指正。</p>
<h3 id="10-Hive-小文件过多怎么解决"><a href="#10-Hive-小文件过多怎么解决" class="headerlink" title="10. Hive 小文件过多怎么解决"></a>10. Hive 小文件过多怎么解决</h3><h5 id="1-使用-hive-自带的-concatenate-命令，自动合并小文件"><a href="#1-使用-hive-自带的-concatenate-命令，自动合并小文件" class="headerlink" title="1. 使用 hive 自带的 concatenate 命令，自动合并小文件"></a>1. 使用 hive 自带的 concatenate 命令，自动合并小文件</h5><p>使用方法：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#对于非分区表</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> A concatenate;</span><br><span class="line"></span><br><span class="line">#对于分区表</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> B <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="number">20201224</span>) concatenate;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：<br>1、concatenate 命令只支持 RCFILE 和 ORC 文件类型。<br>2、使用concatenate命令合并小文件时不能指定合并后的文件数量，但可以多次执行该命令。<br>3、当多次使用concatenate后文件数量不在变化，这个跟参数 mapreduce.input.fileinputformat.split.minsize&#x3D;256mb 的设置有关，可设定每个文件的最小size。</p>
</blockquote>
<h5 id="2-调整参数减少Map数量"><a href="#2-调整参数减少Map数量" class="headerlink" title="2. 调整参数减少Map数量"></a>2. 调整参数减少Map数量</h5><p>设置map输入合并小文件的相关参数（执行Map前进行小文件合并）：</p>
<p>在mapper中将多个文件合成一个split作为输入（<code>CombineHiveInputFormat</code>底层是Hadoop的<code>CombineFileInputFormat</code>方法）：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.input.format<span class="operator">=</span>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; <span class="comment">-- 默认</span></span><br></pre></td></tr></table></figure>

<p>每个Map最大输入大小（这个值决定了合并后文件的数量）：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapred.max.split.size<span class="operator">=</span><span class="number">256000000</span>;   <span class="comment">-- 256M</span></span><br></pre></td></tr></table></figure>

<p>一个节点上split的至少大小（这个值决定了多个DataNode上的文件是否需要合并）：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapred.min.split.size.per.node<span class="operator">=</span><span class="number">100000000</span>;  <span class="comment">-- 100M</span></span><br></pre></td></tr></table></figure>

<p>一个交换机下split的至少大小(这个值决定了多个交换机上的文件是否需要合并)：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapred.min.split.size.per.rack<span class="operator">=</span><span class="number">100000000</span>;  <span class="comment">-- 100M</span></span><br></pre></td></tr></table></figure>

<h5 id="3-减少Reduce的数量"><a href="#3-减少Reduce的数量" class="headerlink" title="3. 减少Reduce的数量"></a>3. 减少Reduce的数量</h5><p>reduce 的个数决定了输出的文件的个数，所以可以调整reduce的个数控制hive表的文件数量。</p>
<p>hive中的分区函数 distribute by 正好是控制MR中partition分区的，可以通过设置reduce的数量，结合分区函数让数据均衡的进入每个reduce即可：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#设置reduce的数量有两种方式，第一种是直接设置reduce个数</span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">#第二种是设置每个reduce的大小，Hive会根据数据总大小猜测确定一个reduce个数</span><br><span class="line"><span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="number">5120000000</span>; <span class="comment">-- 默认是1G，设置为5G</span></span><br><span class="line"></span><br><span class="line">#执行以下语句，将数据均衡的分配到reduce中</span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">10</span>;</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> A <span class="keyword">partition</span>(dt)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> B</span><br><span class="line">distribute <span class="keyword">by</span> rand();</span><br></pre></td></tr></table></figure>

<p>对于上述语句解释：如设置reduce数量为10，使用 rand()， 随机生成一个数 <code>x % 10</code> ， 这样数据就会随机进入 reduce 中，防止出现有的文件过大或过小。</p>
<h5 id="4-使用hadoop的archive将小文件归档"><a href="#4-使用hadoop的archive将小文件归档" class="headerlink" title="4. 使用hadoop的archive将小文件归档"></a>4. 使用hadoop的archive将小文件归档</h5><p>Hadoop Archive简称HAR，是一个高效地将小文件放入HDFS块中的文件存档工具，它能够将多个小文件打包成一个HAR文件，这样在减少namenode内存使用的同时，仍然允许对文件进行透明的访问。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#用来控制归档是否可用</span><br><span class="line"><span class="keyword">set</span> hive.archive.enabled<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line">#通知Hive在创建归档时是否可以设置父目录</span><br><span class="line"><span class="keyword">set</span> hive.archive.har.parentdir.settable<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line">#控制需要归档文件的大小</span><br><span class="line"><span class="keyword">set</span> har.partfile.size<span class="operator">=</span><span class="number">1099511627776</span>;</span><br><span class="line"></span><br><span class="line">使用以下命令进行归档：</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> A ARCHIVE <span class="keyword">PARTITION</span>(dt<span class="operator">=</span><span class="string">&#x27;2021-05-07&#x27;</span>, hr<span class="operator">=</span><span class="string">&#x27;12&#x27;</span>);</span><br><span class="line"></span><br><span class="line">对已归档的分区恢复为原文件：</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> A UNARCHIVE <span class="keyword">PARTITION</span>(dt<span class="operator">=</span><span class="string">&#x27;2021-05-07&#x27;</span>, hr<span class="operator">=</span><span class="string">&#x27;12&#x27;</span>);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意:<br><strong>归档的分区可以查看不能 insert overwrite，必须先 unarchive</strong></p>
</blockquote>
<p>Hive 小文件问题具体可查看：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2MzU2MDYzOA==&mid=2247483683&idx=1&sn=14b25010032bdf0d375080e48de36d7f&chksm=ce77f7f2f9007ee49d773367f2d7abbf708a2e0e18a55794fcd797944ac73ccc88a41d253d6b&token=1679639512&lang=zh_CN&scene=21#wechat_redirect">解决hive小文件过多问题</a></p>
<h3 id="11-Hive优化有哪些"><a href="#11-Hive优化有哪些" class="headerlink" title="11. Hive优化有哪些"></a>11. Hive优化有哪些</h3><h5 id="1-数据存储及压缩："><a href="#1-数据存储及压缩：" class="headerlink" title="1. 数据存储及压缩："></a>1. 数据存储及压缩：</h5><p>针对hive中表的存储格式通常有orc和parquet，压缩格式一般使用snappy。相比与textfile格式表，orc占有更少的存储。因为hive底层使用MR计算架构，数据流是hdfs到磁盘再到hdfs，而且会有很多次，所以使用orc数据格式和snappy压缩策略可以降低IO读写，还能降低网络传输量，这样在一定程度上可以节省存储，还能提升hql任务执行效率；</p>
<h5 id="2-通过调参优化："><a href="#2-通过调参优化：" class="headerlink" title="2. 通过调参优化："></a>2. 通过调参优化：</h5><p>并行执行，调节parallel参数；</p>
<p>调节jvm参数，重用jvm；</p>
<p>设置map、reduce的参数；开启strict mode模式；</p>
<p>关闭推测执行设置。</p>
<h5 id="3-有效地减小数据集将大表拆分成子表；结合使用外部表和分区表。"><a href="#3-有效地减小数据集将大表拆分成子表；结合使用外部表和分区表。" class="headerlink" title="3. 有效地减小数据集将大表拆分成子表；结合使用外部表和分区表。"></a>3. 有效地减小数据集将大表拆分成子表；结合使用外部表和分区表。</h5><h5 id="4-SQL优化"><a href="#4-SQL优化" class="headerlink" title="4. SQL优化"></a>4. SQL优化</h5><ul>
<li>大表对大表：尽量减少数据集，可以通过分区表，避免扫描全表或者全字段；</li>
<li>大表对小表：设置自动识别小表，将小表放入内存中去执行。</li>
</ul>
<p>Hive优化详细剖析可查看：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2MzU2MDYzOA==&mid=2247485060&idx=1&sn=d2938aca9680dc45a64c02db29ecd252&scene=21#wechat_redirect">Hive企业级性能优化</a></p>
<h2 id="附：九个最易出错的SQL讲解"><a href="#附：九个最易出错的SQL讲解" class="headerlink" title="附：九个最易出错的SQL讲解"></a>附：九个最易出错的SQL讲解</h2><p><strong>阅读本节小建议：本文适合细嚼慢咽，不要一目十行，不然会错过很多有价值的细节。</strong></p>
<p>在进行数仓搭建和数据分析时最常用的就是 sql，其语法简洁明了，易于理解，目前大数据领域的几大主流框架全部都支持sql语法，包括 hive，spark，flink等，所以sql在大数据领域有着不可替代的作用，需要我们重点掌握。</p>
<p>在使用sql时如果不熟悉或不仔细，那么在进行查询分析时极容易出错，接下来我们就来看下几个容易出错的sql语句及使用注意事项。</p>
<h4 id="1-decimal"><a href="#1-decimal" class="headerlink" title="1. decimal"></a>1. decimal</h4><p>hive 除了支持 int,double,string等常用类型，也支持 decimal 类型，用于在数据库中存储精确的数值，常用在表示金额的字段上</p>
<p><strong>注意事项：</strong></p>
<p>如：decimal(11,2) 代表最多有11位数字，其中后2位是小数，整数部分是9位；<br>如果<strong>整数部分超过9位，则这个字段就会变成null，如果整数部分不超过9位，则原字段显示</strong>；<br>如果<strong>小数部分不足2位，则后面用0补齐两位，如果小数部分超过两位，则超出部分四舍五入</strong>；<br>也可直接写 decimal，后面不指定位数，默认是 decimal(10,0) 整数10位，没有小数</p>
<h4 id="2-location"><a href="#2-location" class="headerlink" title="2. location"></a>2. location</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">表创建的时候可以用 location 指定一个文件或者文件夹</span><br><span class="line"><span class="keyword">create</span>  <span class="keyword">table</span> stu(id <span class="type">int</span> ,name string)  location <span class="string">&#x27;/user/stu2&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><strong>注意事项：</strong></p>
<p>创建表时使用location， 当<strong>指定文件夹时，hive会加载文件夹下的所有文件，当表中无分区时，这个文件夹下不能再有文件夹，否则报错。</strong><br>当表是分区表时，比如 partitioned by (day string)， 则这个文件夹下的每一个文件夹就是一个分区，且文件夹名为 day&#x3D;20201123 这种格式，然后使用：<strong>msck  repair  table  score</strong>; 修复表结构，成功之后即可看到数据已经全部加载到表当中去了</p>
<h4 id="3-load-data-和-load-data-local"><a href="#3-load-data-和-load-data-local" class="headerlink" title="3. load data 和 load data local"></a>3. load data 和 load data local</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">从hdfs上加载文件</span><br><span class="line">load data inpath <span class="string">&#x27;/hivedatas/techer.csv&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> techer;</span><br><span class="line"></span><br><span class="line">从本地系统加载文件</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/user/test/techer.csv&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> techer;</span><br></pre></td></tr></table></figure>

<p><strong>注意事项：</strong></p>
<ol>
<li>使用 load data local 表示<strong>从本地文件系统加载，文件会拷贝到hdfs上</strong></li>
<li>使用 load data 表示<strong>从hdfs文件系统加载，文件会直接移动到hive相关目录下</strong>，注意不是拷贝过去，因为hive认为hdfs文件已经有3副本了，没必要再次拷贝了</li>
<li>如果表是分区表，load 时不指定分区会报错</li>
<li>如果加载相同文件名的文件，会被自动重命名</li>
</ol>
<h4 id="4-drop-和-truncate"><a href="#4-drop-和-truncate" class="headerlink" title="4. drop 和 truncate"></a>4. drop 和 truncate</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">删除表操作</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> score1;</span><br><span class="line"></span><br><span class="line">清空表操作</span><br><span class="line"><span class="keyword">truncate</span> <span class="keyword">table</span> score2;</span><br></pre></td></tr></table></figure>

<p><strong>注意事项：</strong></p>
<p>如果 <strong>hdfs 开启了回收站，drop 删除的表数据是可以从回收站恢复的</strong>，表结构恢复不了，需要自己重新创建；<strong>truncate 清空的表是不进回收站的，所以无法恢复truncate清空的表。</strong><br>所以 truncate 一定慎用，一旦清空除物理恢复外将无力回天</p>
<h4 id="5-join-连接"><a href="#5-join-连接" class="headerlink" title="5. join 连接"></a>5. join 连接</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INNER</span> <span class="keyword">JOIN</span> 内连接：只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> techer t [<span class="keyword">inner</span>] <span class="keyword">join</span> course c <span class="keyword">on</span> t.t_id <span class="operator">=</span> c.t_id; <span class="comment">-- inner 可省略</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> 左外连接：左边所有数据会被返回，右边符合条件的被返回</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> techer t <span class="keyword">left</span> <span class="keyword">join</span> course c <span class="keyword">on</span> t.t_id <span class="operator">=</span> c.t_id; <span class="comment">-- outer可省略</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RIGHT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> 右外连接：右边所有数据会被返回，左边符合条件的被返回、</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> techer t <span class="keyword">right</span> <span class="keyword">join</span> course c <span class="keyword">on</span> t.t_id <span class="operator">=</span> c.t_id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">FULL</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> 满外(全外)连接: 将会返回所有表中符合条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用<span class="keyword">NULL</span>值替代。</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> techer t <span class="keyword">FULL</span> <span class="keyword">JOIN</span> course c <span class="keyword">ON</span> t.t_id <span class="operator">=</span> c.t_id ;</span><br></pre></td></tr></table></figure>

<p><strong>注意事项：</strong></p>
<ol>
<li>hive2版本已经支持不等值连接，就是 <strong>join on条件后面可以使用大于小于符号;并且也支持 join on 条件后跟or</strong> (早前版本 on 后只支持 &#x3D; 和 and，不支持 &gt; &lt; 和 or)</li>
<li>如hive执行引擎使用MapReduce，一个join就会启动一个job，一条sql语句中如有多个join，则会启动多个job</li>
</ol>
<p><strong>注意</strong>：表之间用逗号(,)连接和 inner join 是一样的，例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> tableA.id, tableB.name <span class="keyword">from</span> tableA , tableB <span class="keyword">where</span> tableA.id<span class="operator">=</span>tableB.id;   </span><br><span class="line">和   </span><br><span class="line"><span class="keyword">select</span> tableA.id, tableB.name <span class="keyword">from</span> tableA <span class="keyword">join</span> tableB <span class="keyword">on</span> tableA.id<span class="operator">=</span>tableB.id;   </span><br></pre></td></tr></table></figure>

<p><strong>它们的执行效率没有区别，只是书写方式不同</strong>，用逗号是sql 89标准，join 是sql 92标准。用逗号连接后面过滤条件用 where ，用 join 连接后面过滤条件是 on。</p>
<h4 id="6-left-semi-join"><a href="#6-left-semi-join" class="headerlink" title="6. left semi join"></a>6. left semi join</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">为什么把这个单独拿出来说，因为它和其他的 <span class="keyword">join</span> 语句不太一样，</span><br><span class="line">这个语句的作用和 <span class="keyword">in</span><span class="operator">/</span><span class="keyword">exists</span> 作用是一样的，是 <span class="keyword">in</span><span class="operator">/</span><span class="keyword">exists</span> 更高效的实现</span><br><span class="line"><span class="keyword">SELECT</span> A.<span class="operator">*</span> <span class="keyword">FROM</span> A <span class="keyword">where</span> id <span class="keyword">in</span> (<span class="keyword">select</span> id <span class="keyword">from</span> B)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> A.<span class="operator">*</span> <span class="keyword">FROM</span> A <span class="keyword">left</span> semi <span class="keyword">join</span> B <span class="keyword">ON</span> A.id<span class="operator">=</span>B.id</span><br><span class="line"></span><br><span class="line">上述两个 <span class="keyword">sql</span> 语句执行结果完全一样，只不过第二个执行效率高</span><br></pre></td></tr></table></figure>

<p><strong>注意事项：</strong></p>
<ol>
<li>left semi join 的限制是：join 子句中右边的表<strong>只能在 on 子句中设置过滤条件</strong>，在 where 子句、select 子句或其他地方过滤都不行。</li>
<li>left semi join 中 on 后面的过滤条件<strong>只能是等于号</strong>，不能是其他的。</li>
<li>left semi join 是只传递表的 join key 给 map 阶段，因此left semi join 中最后 select 的<strong>结果只许出现左表</strong>。</li>
<li>因为 left semi join 是 in(keySet) 的关系，遇到<strong>右表重复记录，左表会跳过</strong></li>
</ol>
<h4 id="7-聚合函数中-null-值"><a href="#7-聚合函数中-null-值" class="headerlink" title="7. 聚合函数中 null 值"></a>7. 聚合函数中 null 值</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive支持 <span class="built_in">count</span>(),<span class="built_in">max</span>(),<span class="built_in">min</span>(),<span class="built_in">sum</span>(),<span class="built_in">avg</span>() 等常用的聚合函数</span><br></pre></td></tr></table></figure>

<p><strong>注意事项：</strong></p>
<p><strong>聚合操作时要注意 null 值</strong>：</p>
<p>count(*) 包含 null 值，统计所有行数；<br>count(id) 不包含id为 null 的值；<br>min <strong>求最小值是不包含 null</strong>，除非所有值都是 null；<br>avg <strong>求平均值也是不包含 null</strong>。</p>
<p><strong>以上需要特别注意，null 值最容易导致算出错误的结果</strong></p>
<h4 id="8-运算符中-null-值"><a href="#8-运算符中-null-值" class="headerlink" title="8. 运算符中 null 值"></a>8. 运算符中 null 值</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive 中支持常用的算术运算符(<span class="operator">+</span>,<span class="operator">-</span>,<span class="operator">*</span>,<span class="operator">/</span>)  </span><br><span class="line">比较运算符(<span class="operator">&gt;</span>, <span class="operator">&lt;</span>, <span class="operator">=</span>)</span><br><span class="line">逻辑运算符(<span class="keyword">in</span>, <span class="keyword">not</span> <span class="keyword">in</span>)</span><br><span class="line"></span><br><span class="line">以上运算符计算时要特别注意 <span class="keyword">null</span> 值</span><br></pre></td></tr></table></figure>

<p><strong>注意事项：</strong></p>
<ol>
<li><strong>每行中的列字段相加或相减，如果含有 null 值，则结果为 null</strong><br>例：有一张商品表（product）</li>
</ol>
<table>
<thead>
<tr>
<th align="left">id</th>
<th align="left">price</th>
<th align="left">dis_amount</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left">100</td>
<td align="left">20</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">120</td>
<td align="left">null</td>
</tr>
</tbody></table>
<p>各字段含义：id (商品id)、price (价格)、dis_amount (优惠金额)</p>
<p>我想算<strong>每个商品优惠后实际的价格</strong>，sql如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id, price <span class="operator">-</span> dis_amount <span class="keyword">as</span> real_amount <span class="keyword">from</span> product;</span><br></pre></td></tr></table></figure>

<p>得到结果如下：</p>
<table>
<thead>
<tr>
<th align="left">id</th>
<th align="left">real_amount</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left">80</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">null</td>
</tr>
</tbody></table>
<p>id&#x3D;2的商品价格为 null，结果是错误的。</p>
<p>我们可以<strong>对 null 值进行处理</strong>，sql如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id, price <span class="operator">-</span> <span class="built_in">coalesce</span>(dis_amount,<span class="number">0</span>) <span class="keyword">as</span> real_amount <span class="keyword">from</span> product;</span><br><span class="line"></span><br><span class="line">使用 coalesce 函数进行 <span class="keyword">null</span> 值处理下，得到的结果就是准确的</span><br><span class="line"></span><br><span class="line">coalesce 函数是返回第一个不为空的值</span><br><span class="line">如上<span class="keyword">sql</span>：如果dis_amount不为空，则返回dis_amount，如果为空，则返回<span class="number">0</span></span><br></pre></td></tr></table></figure>

<ol>
<li><strong>小于是不包含 null 值</strong>，如 id &lt; 10；是不包含 id 为 null 值的。</li>
<li><strong>not in 是不包含 null 值的</strong>，如 city not in (‘北京’,’上海’)，这个条件得出的结果是 city 中不包含 北京，上海和 null 的城市。</li>
</ol>
<h4 id="9-and-和-or"><a href="#9-and-和-or" class="headerlink" title="9. and 和 or"></a>9. and 和 or</h4><p>在sql语句的过滤条件或运算中，如果有多个条件或多个运算，我们都会考虑优先级，如乘除优先级高于加减，乘除或者加减它们之间优先级平等，谁在前就先算谁。那 and 和 or 呢，看似 and 和 or 优先级平等，谁在前先算谁，但是，<strong>and 的优先级高于 or</strong>。</p>
<p><strong>注意事项：</strong></p>
<p>例：<br>还是一张商品表（product）</p>
<table>
<thead>
<tr>
<th align="left">id</th>
<th align="left">classify</th>
<th align="left">price</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left">电器</td>
<td align="left">70</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">电器</td>
<td align="left">130</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left">电器</td>
<td align="left">80</td>
</tr>
<tr>
<td align="left">4</td>
<td align="left">家具</td>
<td align="left">150</td>
</tr>
<tr>
<td align="left">5</td>
<td align="left">家具</td>
<td align="left">60</td>
</tr>
<tr>
<td align="left">6</td>
<td align="left">食品</td>
<td align="left">120</td>
</tr>
</tbody></table>
<p>我想要统计下电器或者家具这两类中价格大于100的商品，sql如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> product <span class="keyword">where</span> classify <span class="operator">=</span> <span class="string">&#x27;电器&#x27;</span> <span class="keyword">or</span> classify <span class="operator">=</span> <span class="string">&#x27;家具&#x27;</span> <span class="keyword">and</span> price<span class="operator">&gt;</span><span class="number">100</span></span><br></pre></td></tr></table></figure>

<p>得到结果</p>
<table>
<thead>
<tr>
<th align="left">id</th>
<th align="left">classify</th>
<th align="left">price</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left">电器</td>
<td align="left">70</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">电器</td>
<td align="left">130</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left">电器</td>
<td align="left">80</td>
</tr>
<tr>
<td align="left">4</td>
<td align="left">家具</td>
<td align="left">150</td>
</tr>
</tbody></table>
<p>结果是错误的，把所有的电器类型都查询出来了，原因就是 and 优先级高于 or，上面的sql语句实际执行的是，先找出 classify &#x3D; ‘家具’ and price&gt;100 的，然后在找出 classify &#x3D; ‘电器’ 的</p>
<p>正确的 sql 就是加个括号，先计算括号里面的：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> product <span class="keyword">where</span> (classify <span class="operator">=</span> <span class="string">&#x27;电器&#x27;</span> <span class="keyword">or</span> classify <span class="operator">=</span> <span class="string">&#x27;家具&#x27;</span>) <span class="keyword">and</span> price<span class="operator">&gt;</span><span class="number">100</span></span><br></pre></td></tr></table></figure>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">WangXun</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://wangxukun.top/2021/10/27/Software/Hive入门-Hive知识体系/">https://wangxukun.top/2021/10/27/Software/Hive入门-Hive知识体系/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hive/">Hive</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2021/10/30/Software/Hive%E5%85%A5%E9%97%A8-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%EF%BC%88Scala%EF%BC%89/"><i class="fa fa-chevron-left">  </i><span>Hive入门-自定义函数（Scala）</span></a></div><div class="next-post pull-right"><a href="/2021/10/24/Software/Hive%E5%85%A5%E9%97%A8-%E5%9B%9B%E4%B8%AAby%E8%AF%A6%E8%A7%A3/"><span>Hive入门-四个by详解</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'aaf2844e0aeef4917c17',
  clientSecret: '10b96d24dffda7d3b4544778cf620f81990b676d',
  repo: 'blog-issue',
  owner: 'w749',
  admin: 'w749',
  id: md5(decodeURI(location.pathname)),
  language: 'en'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(/img/top-img.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2019 - 2022 By WangXun</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/lib/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.1"></script><script src="/js/fancybox.js?version=1.9.1"></script><script src="/js/sidebar.js?version=1.9.1"></script><script src="/js/copy.js?version=1.9.1"></script><script src="/js/fireworks.js?version=1.9.1"></script><script src="/js/transition.js?version=1.9.1"></script><script src="/js/scroll.js?version=1.9.1"></script><script src="/js/head.js?version=1.9.1"></script><script src="/js/search/algolia.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>