<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Logstash简单应用"><meta name="keywords" content="ETL"><meta name="author" content="WangXun"><meta name="copyright" content="WangXun"><title>Logstash简单应用 | Wake</title><link rel="shortcut icon" href="/img/favicon-blank.svg"><link rel="stylesheet" href="/css/index.css?version=1.9.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"HSM2EINL2X","apiKey":"6f1478b12150efd917d5ecfcddfb8b8b","indexName":"wangxun","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '6.0.0'
} </script><meta name="generator" content="Hexo 6.0.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Logstash%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">Logstash工作原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.</span> <span class="toc-text">执行模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8"><span class="toc-number">1.2.</span> <span class="toc-text">简单应用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Logstash%E5%92%8CFlume%E7%9B%B8%E6%AF%94"><span class="toc-number">2.</span> <span class="toc-text">Logstash和Flume相比</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.jpg"></div><div class="author-info__name text-center">WangXun</div><div class="author-info__description text-center"></div><div class="follow-button"><a target="_blank" rel="noopener" href="https://github.com/w749">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">71</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">20</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">6</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/top-img.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Wake</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">Logstash简单应用</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-04-08</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Software/">Software</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">1.8k</span><span class="post-meta__separator">|</span><span>Reading time: 6 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p><strong>Elasticsearch</strong>是当前主流的分布式大数据存储和搜索引擎，可以为用户提供强大的全文本检索能力，广泛应用于日志检索，全站搜索等领域。<strong>Logstash</strong>作为Elasicsearch常用的实时数据采集引擎，可以采集来自不同数据源的数据，并对数据进行处理后输出到多种输出源，是Elastic Stack 的重要组成部分。</p>
<span id="more"></span>

<h3 id="Logstash工作原理"><a href="#Logstash工作原理" class="headerlink" title="Logstash工作原理"></a><strong>Logstash工作原理</strong></h3><p><strong>处理过程</strong></p>
<p><img src="https://main.qcloudimg.com/raw/7367005a46890c48d27e8518a14a1772.png"></p>
<p>如上图，Logstash的数据处理过程主要包括：Inputs, Filters, Outputs 三部分， 另外在Inputs和Outputs中可以使用Codecs对数据格式进行处理。这四个部分均以插件形式存在，用户通过定义pipeline配置文件，设置需要使用的input，filter，output, codec插件，以实现特定的数据采集，数据处理，数据输出等功能</p>
<p>（1）Inputs：用于从数据源获取数据，常见的插件如file, syslog, redis, beats 等[<a target="_blank" rel="noopener" href="https://www.elastic.co/guide/en/logstash/current/input-plugins.html">详细参考</a>]<br>（2）Filters：用于处理数据如格式转换，数据派生等，常见的插件如grok, mutate, drop, clone, geoip等[<a target="_blank" rel="noopener" href="https://www.elastic.co/guide/en/logstash/current/filter-plugins.html">详细参考</a>]<br>（3）Outputs：用于数据输出，常见的插件如elastcisearch，file, graphite, statsd等[<a target="_blank" rel="noopener" href="https://www.elastic.co/guide/en/logstash/current/output-plugins.html">详细参考</a>]<br>（4）Codecs：Codecs不是一个单独的流程，而是在输入和输出等插件中用于数据转换的模块，用于对数据进行编码处理，常见的插件如json，multiline[<a target="_blank" rel="noopener" href="https://www.elastic.co/guide/en/logstash/current/codec-plugins.html">详细参考</a>]</p>
<h4 id="执行模型"><a href="#执行模型" class="headerlink" title="执行模型"></a><strong>执行模型</strong></h4><p>（1）每个Input启动一个线程，从对应数据源获取数据<br>（2）Input会将数据写入一个队列：默认为内存中的有界队列（意外停止会导致数据丢失）。为了防止数丢失Logstash提供了两个特性：<br><a target="_blank" rel="noopener" href="https://www.elastic.co/guide/en/logstash/current/persistent-queues.html">Persistent Queues</a>：通过磁盘上的queue来防止数据丢失<br><a target="_blank" rel="noopener" href="https://www.elastic.co/guide/en/logstash/current/dead-letter-queues.html">Dead Letter Queues</a>：保存无法处理的event（仅支持Elasticsearch作为输出源）<br>（3）Logstash会有多个pipeline worker, 每一个pipeline worker会从队列中取一批数据，然后执行filter和output（worker数目及每次处理的数据量均由配置确定）</p>
<h4 id="简单应用"><a href="#简单应用" class="headerlink" title="简单应用"></a><strong>简单应用</strong></h4><p>首先是Logstash的配置文件，也可以不用配置，不会对数据采集和传输产生很大影响，当需要精细化的参数调整时再配置指定的参数即可。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xpack.management.enabled: <span class="literal">false</span></span><br><span class="line">xpack.monitoring.elasticsearch.hosts: [<span class="string">&quot;node1:9200&quot;</span>,<span class="string">&quot;node2:9201&quot;</span>]</span><br><span class="line">xpack.monitoring.enabled: <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>接下来就是配置数据传输的conf文件，需要制定inputs、filter和outputs三个模块。首先是从文件收集数据，filter解析后传入ElasticSearch。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  file &#123;</span><br><span class="line">    path =&gt; [<span class="string">&quot;/usr/share/logstash/data/file/CouponProduct.csv&quot;</span>]  <span class="comment"># 必须使用绝对路径</span></span><br><span class="line">    <span class="comment"># sincedb记录现在有一个与之关联的最后活动时间戳。如果在最近N天内没有在跟踪文件中检测到任何更改，则它的sincedb跟踪记录将过期，并且不会被持久保存。默认14天</span></span><br><span class="line">    sincedb_clean_after =&gt; <span class="string">&quot;2 weeks&quot;</span></span><br><span class="line">    sincedb_path =&gt; <span class="string">&quot;/usr/share/logstash/data/file/sincedb&quot;</span>  <span class="comment"># sincedb存储地址</span></span><br><span class="line">    start_position =&gt; <span class="string">&quot;beginning&quot;</span>  <span class="comment"># 选择Logstash最初开始读取文件的位置:开始或结束。默认行为将文件视为实时流（end），因此从末尾开始。</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">filter&#123;</span><br><span class="line">  csv &#123;</span><br><span class="line">    separator =&gt; <span class="string">&quot;,&quot;</span>  <span class="comment"># 分隔符，默认是逗号</span></span><br><span class="line">    <span class="comment"># quote_char =&gt; &quot;\&quot;&quot;  # 定义用于引用CSV字段的字符，默认是双引号</span></span><br><span class="line">    columns =&gt; [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;code&quot;</span>, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;enname&quot;</span>, <span class="string">&quot;points&quot;</span>, <span class="string">&quot;creater&quot;</span>, <span class="string">&quot;updater&quot;</span>, <span class="string">&quot;money&quot;</span>, <span class="string">&quot;createtime&quot;</span>, <span class="string">&quot;updatetime&quot;</span>]  <span class="comment"># 指定列名</span></span><br><span class="line">    autodetect_column_names =&gt; <span class="literal">false</span>  <span class="comment"># 是否检测列名，默认为false</span></span><br><span class="line">    skip_header =&gt; <span class="literal">false</span>  <span class="comment"># 是否跳过第一行，和autodetect_column_names一起设置，全为true或false</span></span><br><span class="line">    autogenerate_column_names =&gt; <span class="literal">false</span>  <span class="comment"># 是否设置默认的列名，默认为true</span></span><br><span class="line">    convert =&gt; &#123;  <span class="comment"># 指定数据类型</span></span><br><span class="line">      <span class="string">&quot;money&quot;</span> =&gt; <span class="string">&quot;integer&quot;</span></span><br><span class="line">      <span class="string">&quot;createtime&quot;</span> =&gt; <span class="string">&quot;date&quot;</span></span><br><span class="line">      <span class="string">&quot;updatetime&quot;</span> =&gt; <span class="string">&quot;date&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    skip_empty_columns =&gt; <span class="literal">false</span>  <span class="comment"># 跳过空列，默认false</span></span><br><span class="line">    skip_empty_rows =&gt; <span class="literal">false</span>  <span class="comment"># 跳过空行，默认false</span></span><br><span class="line">  &#125;</span><br><span class="line">  mutate &#123;</span><br><span class="line">    add_field =&gt; &#123;<span class="string">&quot;insert_time&quot;</span> =&gt; <span class="string">&quot;%&#123;@timestamp&#125;&quot;</span>&#125;  <span class="comment"># 新增字段，%&#123;已有字段&#125;可以引用现有字段</span></span><br><span class="line">    remove_field =&gt; [<span class="string">&quot;message&quot;</span>,<span class="string">&quot;@version&quot;</span>,<span class="string">&quot;updater&quot;</span>,<span class="string">&quot;host&quot;</span>,<span class="string">&quot;@timestamp&quot;</span>]  <span class="comment"># 删除字段</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">  stdout&#123;</span><br><span class="line">  &#125;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; [<span class="string">&quot;node1:9200&quot;</span>,<span class="string">&quot;node2:9201&quot;</span>]  <span class="comment"># 输出到ES，和logstash.yml保持一致</span></span><br><span class="line">    index =&gt; <span class="string">&quot;coupon_product&quot;</span>  <span class="comment"># 索引名称</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以下是传输从filebeat收集的数据，对数据内容使用grok解析，再对filebeat传过来的log.file.path和host.name使用ruby代码进行解析并传入数据。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  beats &#123;</span><br><span class="line">    port =&gt; 5044  <span class="comment"># 指定filebeat的端口</span></span><br><span class="line">    host =&gt; logstash  <span class="comment"># 指定filebeat的主机</span></span><br><span class="line">    add_hostname =&gt; <span class="literal">true</span>  <span class="comment"># 将主机名添加到数据中，默认为false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">filter &#123;</span><br><span class="line">  grok &#123;  <span class="comment"># 使用正则表达式解析日志</span></span><br><span class="line">    match =&gt; &#123;<span class="string">&quot;message&quot;</span> =&gt; <span class="string">&quot;%&#123;IP:ip&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;&quot;</span>&#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ruby &#123;  <span class="comment"># 运行ruby代码，解析filebeat传过来的log.file.path和host.name</span></span><br><span class="line">    code =&gt; <span class="string">&quot;</span></span><br><span class="line"><span class="string">      path = event.get(&#x27;log&#x27;)[&#x27;file&#x27;][&#x27;path&#x27;]</span></span><br><span class="line"><span class="string">      hostname = event.get(&#x27;host&#x27;)[&#x27;name&#x27;]</span></span><br><span class="line"><span class="string">      event.set(&#x27;path&#x27;, path)</span></span><br><span class="line"><span class="string">      event.set(&#x27;hostname&#x27;, hostname)</span></span><br><span class="line"><span class="string">    &quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">  mutate &#123;</span><br><span class="line">    add_field =&gt; &#123;<span class="string">&quot;insert_time&quot;</span> =&gt; <span class="string">&quot;%&#123;@timestamp&#125;&quot;</span>&#125;</span><br><span class="line">    remove_field =&gt; [<span class="string">&quot;ecs&quot;</span>,<span class="string">&quot;host&quot;</span>,<span class="string">&quot;@timestamp&quot;</span>,<span class="string">&quot;agent&quot;</span>,<span class="string">&quot;log&quot;</span>,<span class="string">&quot;@version&quot;</span>,<span class="string">&quot;input&quot;</span>,<span class="string">&quot;tags&quot;</span>,<span class="string">&quot;message&quot;</span>]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">  stdout&#123;</span><br><span class="line">  &#125;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; [<span class="string">&quot;node1:9200&quot;</span>,<span class="string">&quot;node2:9201&quot;</span>]  <span class="comment"># 输出到ES，和logstash.yml保持一致</span></span><br><span class="line">    index =&gt; <span class="string">&quot;filebeat_logstash&quot;</span>  <span class="comment"># 索引名称</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>关于一个Logstash进程的运行则需要使用bin目录下的logstash命令加-f参数制定配置文件进行。当我们修改配置文件之后需要杀死进程重新启动Logstash才可以更新处理流程，–config.reload.automatic参数可以使Logstash自动嗅探配置文件的变化并对此进程的收集和处理进行纠正，默认嗅探时间是15s。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logstash -f ./config/filebeat.conf --config.reload.automatic</span><br></pre></td></tr></table></figure>

<h3 id="Logstash和Flume相比"><a href="#Logstash和Flume相比" class="headerlink" title="Logstash和Flume相比"></a><strong>Logstash和Flume相比</strong></h3><ul>
<li>Logstash比较偏重于字段的预处理，在异常情况下可能会出现数据丢失，只是在运维日志场景下，一般认为这个可能不重要；而Flume偏重数据的传输，几乎没有数据的预处理，仅仅是数据的产生，封装成event然后传输；传输的时候flume比logstash多考虑了一些可靠性。因为数据会持久化在channel中，数据只有存储在下一个存储位置（可能是最终的存储位置，如HDFS；也可能是下一个Flume节点的channel），数据才会从当前的channel中删除。这个过程是通过事务来控制的，这样就保证了数据的可靠性。</li>
<li>Logstash有几十个插件，配置比较灵活；flume强调用户自定义开发，开发难度相对较高。</li>
<li>Logstash的input和filter还有output之间都存在buffer，进行缓冲；Flume直接使用channel做持久化。</li>
<li>Logstash性能以及资源消耗比较严重，且不支持缓存。</li>
<li>综上所述，Logstash偏重于与ELK Stack结合使用，当然也可以output到kafka再做后续使用，侧重点是数据的预处理；而Flume虽然开发难度较高，基本不存在数据预处理，但在生产环境中比较安全，有分布式和channel的双重保障，侧重点是数据的传输。两者根据不同的使用环境做不同的选择。</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">WangXun</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://wangxukun.top/2021/04/08/Software/Logstash简单应用/">https://wangxukun.top/2021/04/08/Software/Logstash简单应用/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ETL/">ETL</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2021/04/11/Software/Dockerfile%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8/"><i class="fa fa-chevron-left">  </i><span>Dockerfile简单应用</span></a></div><div class="next-post pull-right"><a href="/2021/03/31/Software/Docker%20WordPress%E7%9A%84Nginx%E5%BA%94%E7%94%A8/"><span>Docker WordPress的Nginx应用</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'aaf2844e0aeef4917c17',
  clientSecret: '10b96d24dffda7d3b4544778cf620f81990b676d',
  repo: 'blog-issue',
  owner: 'w749',
  admin: 'w749',
  id: md5(decodeURI(location.pathname)),
  language: 'en'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(/img/top-img.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2019 - 2022 By WangXun</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/lib/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.1"></script><script src="/js/fancybox.js?version=1.9.1"></script><script src="/js/sidebar.js?version=1.9.1"></script><script src="/js/copy.js?version=1.9.1"></script><script src="/js/fireworks.js?version=1.9.1"></script><script src="/js/transition.js?version=1.9.1"></script><script src="/js/scroll.js?version=1.9.1"></script><script src="/js/head.js?version=1.9.1"></script><script src="/js/search/algolia.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>